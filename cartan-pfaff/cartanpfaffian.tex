%!TEX TS-program = xelatex
%!TEX encoding = UTF-8 Unicode
\documentclass[leqno,11pt]{book}
\usepackage{geometry}
\usepackage[center]{caption}
\usepackage{lmodern}
\geometry{a4paper}
%\usepackage[adobe-utopia,uppercase=upright,greeklowercase=upright]{mathdesign}
%\usepackage{indentfirst}
%\usepackage[parfill]{parskip}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amscd}
\usepackage{sectsty}
\usepackage{mathtools}
\mathtoolsset{mathic}
\usepackage{enumerate}
\usepackage{makeidx}

\usepackage{fontspec}
\usepackage{xunicode}
\usepackage{xltxtra}
\defaultfontfeatures{Mapping=tex-text}


%\setromanfont{Adobe Garamond Pro}

\makeindex

\nohang
\partfont{\mdseries\scshape\centering}
\chapterfont{\mdseries\scshape\centering}
\sectionfont{\mdseries\scshape\centering}
\subsectionfont{\bfseries\centering}

%\numberwithin{equation}{chapter}
%\usepackage{epstopdf}
\usepackage[numbib,nottoc]{tocbibind}
%\usepackage{overcite}
\usepackage[pdfborder={0 0 0}]{hyperref}
%\usepackage[perpage,para,symbol]{footmisc}
\usepackage[british]{babel}
%\usepackage{slashed}

\usepackage{perpage}
\MakePerPage[2]{footnote}

%\usepackage{fancyhdr}
%\pagestyle{fancy}
%\fancyhead{}
%\fancyhead[LE,RO]{\thepage}
%\fancyhead[RE]{{\rightmark}}
%\fancyhead[LO]{{\leftmark}}
%\fancyfoot{}


\renewcommand{\sectionmark}[1]
{\markright{\itshape {#1}}}

\makeatletter
\def\cleardoublepage{\clearpage\if@twoside \ifodd\c@page\else
\hbox{}
\vspace*{\fill}
\begin{center}
%This page is intentionally blank.
\end{center}
\vspace{\fill}
\thispagestyle{empty}
\newpage
\if@twocolumn\hbox{}\newpage\fi\fi\fi}
\makeatother

%\renewcommand{\chaptermark}[1]{\markboth{\thechapter.\ \ #1}{}}

\title{On the integration of systems of equations\\in total differentials\\
\emph{\&}\\
Differential systems in involution
}
\author{by Élie Cartan\\
\\
Translation by Ziyang Hu\\
\\
\\
Translated from the original French\\
\\
\emph{Sur l'intégration des systèmes d'équations}\\ 
\emph{aux différentielles totales}, 1901\\
\\
and\\
\\
\emph{Les systèmes différentiels en involution}, 1904
}
%\date{}                                         % Activate to display a given date or no date

\newcommand{\pd}{\partial}
\newcommand{\rs}{\mathbb{R}}

\DeclareMathOperator{\inp}{\lrcorner}


\newtheoremstyle{shape0}% name
  {9pt}%      Space above
  {9pt}%      Space below
  {}%         Body font
  {}%         Indent amount (empty = no indent, \parindent = para indent)
  {\itshape}% Thm head font
  {.}%        Punctuation after thm head
  {.5em}%     Space after thm head: " " = normal interword space;
        %       \newline = linebreak
  {}%         Thm head spec (can be left empty, meaning `normal')


\newtheoremstyle{shape1}% name
  {9pt}%      Space above
  {9pt}%      Space below
  {\itshape}%         Body font
  {\parindent}%         Indent amount (empty = no indent, \parindent = para indent)
  {\bfseries}% Thm head font
  {.}%        Punctuation after thm head
  {.5em}%     Space after thm head: " " = normal interword space;
        %       \newline = linebreak
  {}%         Thm head spec (can be left empty, meaning `normal')


\newtheoremstyle{shapesmall}% name
  {9pt}%      Space above
  {9pt}%      Space below
  {\small}%         Body font
  {\parindent}%         Indent amount (empty = no indent, \parindent = para indent)
  {\small\itshape}% Thm head font
  {.}%        Punctuation after thm head
  {.5em}%     Space after thm head: " " = normal interword space;
        %       \newline = linebreak
  {}%         Thm head spec (can be left empty, meaning `normal')

\newtheoremstyle{justsmall}% name
  {9pt}%      Space above
  {9pt}%      Space below
  {\small}%         Body font
  {\parindent}%         Indent amount (empty = no indent, \parindent = para indent)
  {}% Thm head font
  {}%        Punctuation after thm head
  {}%     Space after thm head: " " = normal interword space;
        %       \newline = linebreak
  {}%         Thm head spec (can be left empty, meaning `normal')


\newtheoremstyle{shapesc}% name
  {9pt}%      Space above
  {9pt}%      Space below
  {\itshape}%         Body font
  {\parindent}%         Indent amount (empty = no indent, \parindent = para indent)
  {\scshape}% Thm head font
  {.}%        Punctuation after thm head
  {.5em}%     Space after thm head: " " = normal interword space;
        %       \newline = linebreak
  {}%         Thm head spec (can be left empty, meaning `normal')

\newtheoremstyle{shape2}% name
  {9pt}%      Space above
  {9pt}%      Space below
  {}%         Body font
  {}%         Indent amount (empty = no indent, \parindent = para indent)
  {\itshape}% Thm head font
  {.}%        Punctuation after thm head
  {.5em}%     Space after thm head: " " = normal interword space;
        %       \newline = linebreak
  {}%         Thm head spec (can be left empty, meaning `normal')


\setlength{\parindent}{15pt}

\theoremstyle{shape1}
\newtheorem*{thm*}{\hspace{15pt}Theorem}
\newtheorem{thm}{Theorem}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prin}[thm]{Principle}
\newtheorem{expr}[thm]{Experiment}
\newtheorem*{dfn*}{\hspace{15pt}Definition}
\newtheorem*{concl*}{\hspace{15pt}Conclusion}
\theoremstyle{shapesmall}
\newtheorem*{ex}{Example}
\newtheorem*{exs}{Examples}
\newtheorem*{rmk}{Remark}


%\theoremstyle{shape2}
%\newtheorem{ex}[thm]{Example}
%\theoremstyle{definition}

\renewcommand{\bfdefault}{b}

\setcounter{secnumdepth}{5}
\renewcommand\theparagraph{\arabic{paragraph}}

\newenvironment{jsmall}{\vspace{9pt}\small}{\vspace{0pt}}

\makeatletter
\let\old@phi\phi
\let\old@varphi\varphi
\let\old@epsilon\epsilon
\let\old@varepsilon\varepsilon
\let\phi\old@varphi
\let\varphi\old@phi
\let\epsilon\old@varepsilon
\let\varepsilon\old@epsilon
\makeatother


\renewcommand{\theequation}{\arabic{equation}}
\renewcommand{\thefigure}{\arabic{figure}}
\renewcommand{\thefootnote}{(\fnsymbol{footnote})}

\renewcommand{\qedsymbol}{\textsc{q.e.d.}}
\renewcommand{\thesection}{\roman{section}.}
\renewcommand{\thesubsection}{\Roman{subsection}.}

\newcommand{\fsref}[1]{\textsection\textbf{\ref{sec:#1}}}
\newcommand{\str}{^{\star}}
\newcommand{\rvec}[1]{\vec{\mathbf{#1}}}
\newcommand{\ivec}{\rvec{I}}
\newcommand{\jvec}{\rvec{J}}
\newcommand{\kvec}{\rvec{K}}
\newcommand{\vp}{\varpi}
\newcommand{\somespace}{\vspace{9pt}}


\begin{document}


%\maketitle

%\newpage

\chapter*{On the integration of\\systems of equations\\in total differentials \footnote{\emph{Annales École Normale}, 3rd series, 18, 1901, p. 241–311.}}
\label{sec:integr-syst-equat}


The problem of the existence of integrals of a given system of $s$ equations in total differentials of $r$ variables, when the system is not completely integrable, was not the subject of extensive research until the article of Biermann \emph{Ueber $n$ simultane Differentialgleichungen der Form $\sum X_{\mu}dx_{\mu}=0$} published in 1885 in volume 30 of \emph{Schlöm.~Zeitschrift}. There he investigated only the maximum number of independent variables that we should to take for there to exist a family of integral varieties filling up space. He then found that this maximum number, \emph{when these coefficients are generic}, is equal to the integer quotient of the total number $r$ of variables by the sum of the number of equations $s$ and one. Moreover, the remainder of this division indicates the number of functions in the independent variables that we can take arbitrarily without the problem ceasing to be solvable. After this article, not much was done on this subject except presenting the proofs of these results under other forms, without ever arriving at perfect rigour, and almost nothing is done on the case where the coefficients of the differential system are not generic.

We can arrive at precise and general results by taking into consideration the bilinear covariants of the left hand sides of the equations of the given system; the bilinear covariants, introduced by Frobenius and Darboux, has already been very fecund in the study of a single Pfaffian equation. In short, in considering the given equations, we express, using a geometric language, that each tangent at a given point $A$ to an integral variety $M$ passing through this point is contained in a certain $r-s$ dimensional flat variety $(P)$ associated with this point. But if we introduce the bilinear covariants, we find not only that every flat variety of dimensions $1$, $2$, $\dots$ tangent to an integral variety is contained in $(P)$, but, furthermore, any two straight lines in this flat variety $(T)$ satisfy certain bilinear relations with respect to their direction parameters. Or, if we represent a straight line based on $A$ by a point in a $r-1$ dimensional space $R$, \emph{the image of a tangent to $M$ must be contained in a flat variety $(H)$ of $R$, and furthermore the straight line joining the images of two tangents to the same integral variety $M$ must belong to a certain number of linear complexes associated to $A$.}

In summary, we associate to each point $A$ of the space not only a flat variety $(H)$, but also a set of linear complexes in this flat variety. It is clear that the nature of these linear complexes must influence the existence and the degree of indeterminacy of the integral varieties.

By calling the set of a point $A$ and a $p$ dimensional variety passing through this point the name $E_{p}$, and by agreeing to say that $E_{p}$ is \emph{integral} whenever its image in $R$ is completely contained in $(H)$ and, furthermore, contains only the straight lines belonging to the linear complexes corresponding to $A$, we see that the necessary and sufficient condition for a variety to be integral is that all of its elements are integral.

If we then try to make a $m$ dimensional integral variety pass through a known $m-1$ dimensional integral variety, we find that this is possible whenever through any integral element $E_{m-1}$ there passes an integral element $E_{m}$. The solution is given by a Kowalewski system, and it is unique if through an arbitrary $E_{m-1}$ there passes only one $E_{m}$.

Granted this, we are led to define an integer $n$ in the following manner:

Through an arbitrary point $A$, there passes at least one integral element $E_{1}$;

Through an arbitrary integral element $E_{1}$, there passes at least one integral element $E_{2}$, etc.;

Through an arbitrary integral element $E_{n-1}$, there pases at least one integral element $E_{n}$;

Finally, through an arbitrary integral element $E_{n}$, there does not pass any integral element $E_{n+1}$.

The integer $n$ thus defined is called the \emph{genre} of the system.

From this we can draw precise conclusions on the existence of integrals of the given system. For this, suppose that, in a general manner, the integral elements $E_{i+1}$ passing through an arbitrary integral element $E_{i}$ depend on $r_{i+1}$ parameters (if this element is unique, we agree to give $r_{i+1}$ the value zero). Then we have here a system of geometrical conditions determining the $n$ dimensional integrals completely:

\emph{Given an arbitrary point $\mu_{0}$, an arbitrary variety $\mu_{r-r_{1}}$ passing through this point, an arbitrary variety $\mu_{r-r_{2}}$ passing through $\mu_{r-r_{1}}$, etc., an arbitrary variety $\mu_{r-r_{n}}$ passing through $\mu_{r-r_{n-1}}$, there exists one and only one integral variety $M_{n}$ passing through $\mu_{0}$ having in common with $\mu_{r-r_{1}}$ a $1$ dimensional variety, $\dots$, with $\mu_{r-r_{i}}$ a $i$ dimensional variety and contained in $\mu_{r-r_{n}}$.}

By translating this statement into analytic language and specialising it to the case where we can obtain all the integral varieties once and only once, we can show that the general $n$ dimensional integral is determined, in a unique manner, by a system of
\begin{alignat*}{10}
  &s_{n}&&\text{ arbitrary functions of }&&n&&\text{ arguments,}\\
  &s_{n-1}&&\text{ arbitrary functions of }&&n-1&&\text{ arguments,}\\
  &\dots&&&&\dots\\
  &s_{1}&&\text{ arbitrary functions of }&&1&&\text{ arguments,}
\intertext{and}
  &s&&\text{ arbitrary constants,}
\end{alignat*}
by setting
\begin{alignat*}{10}
  &s_{n}&&=r_{n},\\
  &s_{n-1}&&=r_{n-1}&&-r_{n}&&-1,\\
  &&&\dots\\
  &s_{1}&&=r_{1}&&-r_{2}&&-1,\\
  &s&&=r&&-r_{1}&&-1.
\end{alignat*}

Furthermore, these integers $s$ are all non-negative and \emph{they are in increasing order, or at least they cannot decrease from $s_{n}$ to $s$.}

We can also give the word \emph{arbitrary} that appears in these statements a precise definition.

We hence see the important role played by these integers $s$ and the simple manner in which they depend on the flat variety $(H)$ and the system of linear complexes which we talke about above.

In particular, if the coefficients of the given equations are not subject to any specialisation, which is the case studied by Biermann, the genre $n$ is the integer quotient of $r$ by $s+1$, and if we denote the remainder by $\sigma$, we have
\[
s_{n}=\sigma,\qquad s_{n-1}=s_{n-2}=\dots=s_{1}=s,
\]
such that the general integral depends on $\sigma$ arbitrary functions of $n$ arguments, $s$ arbitrary functions of $n-1$ arguments, etc., $s$ arbitrary constants. This is evidently the result found by Biermann with a lot more precision.

The differential systems for which the integers $s_{n}$ are zero enjoy particularly more interesting properties. We call them \emph{systems of the first kind}.

In a general manner, the integration can be simplified if several of the numbers $s$ are zero. If $s_{\nu}$ is the smallest index that this happens, we have
\[
s_{\nu}=s_{\nu+1}=\dots=s_{n}=0.
\]
For these systems, through an arbitrary integral element $E_{\nu-1}$ there passes one and only one integral element $E_{n}$. Similarly, it suffices to specify the varieties $\mu_{0}$, $\mu_{r-r_{1}}$, $\dots$, $\mu_{r-r_{\nu-1}}$ which we have talked about above to \emph{determine} the integral $M_{n}$ and \emph{the search of this integral amounts to that of a system of genre $\nu$.} It suffices to make an arbitrary but determined variety $\mu_{r-r_{\nu}-1}$ pass through $\mu_{r-r_{\nu-1}}$, and through this variety passes a family of varieties $\mu_{r-r_{\nu}}$ depending on $r_{\nu}=n-\nu$ parameters and filling all of the space. To each of there corresponds an integral variety $M_{\nu}$. The locus of these varieties $M_{\nu}$, when we vary the $n-\nu$ parameters they depend on, is the variety $M_{n}$ we search for. In short, we are lead to a system of $r-r_{\nu}$ variables of genre $\nu$, but whose coefficients depend on $n-\nu$ arbitrary constants. In the case where $\nu$ is equal to $1$, this is the Lie-Mayer method for integrating completely integrable systems. We can call $\nu$ the \emph{true genre} of the system.

In another train of ideas, there is another case where integration can be simplified, i.e., the case where there passes through each point $A$ a \emph{characteristic} element, by which we mean an integral element $E_{p}$ such that all elements formed with $E_{p}$ and a linear integral element are integral, or, as we can say, $E_{p}$ is associated to any linear integral element. We can then show that the system of equations in total differentials defining the characteristics is \emph{completely integrable}. In other words, there exists a family of $p$ dimensional varieties admitting at each of their points a corresponding characteristic element $E_{p}$. These varieties, which we call \emph{characteristics}, depend on $r-p$ parameters, and there passes one and only one of them through each point of the space. For the differential system of genre $n$ where there exists characteristic elements $E_{p}$, every non-singular integral variety $M_{n}$ is generated by characteristic varieties depending on $n-p$ parameters, and if two integral varieties $M_{n}$ and $M_{n}'$ have a point in common, they have in common the characteristic variety based on the point.

Finally if we take the $r-p$ parameters that the characteristics depend on and any other generic $p$ functions as the new variables, they system can be made into a form that it contains only the first $r-p$ variables. Furthermore, the search for the $r-p$ variables, in other words the integration of the characteristic system, can in general be simplified by taking into account the properties of the linear complexes associated with the given system.

In particular, if we have a system of genre $n$ of first kind for which $s_{1}$ is equal to $1$, which is the case of one single equation, there is always characteristic varieties of $n-\nu+1$ dimensions, $\nu$ denoting the true genre of the system. Once these characteristics are found by operations whose order decreases by two each time, we only have to integrate a system in $r-n+\nu-1$ variables of genre $\nu-1$.

There also exists simple theorems in the case where $s_{1}$ is equal to $2$, but the study of these theorems would lead us to the theory of the \emph{classification} of systems in total differentials.

It is hardly necessary to remark the links among all these theories and the theory of systems of partial differential equations. We will content ourselves to indicate the agreement of the results found by the general degree of indeterminacy of a Pfaffian system and those found by Delassus \footnote{\emph{Extension du théorème de Cauchy aux systèmes les plus généraux d'équations aux dérivées partielles} [\emph{Ann.~de l'Éc.~Norm.} (3), vol.~\textsc{xiii}, p.~421--467].} on the degree of indeterminacy of a general integral of an involutive system of partial differential equations. However, although Delassus has made the system under a particular form, by further differentiating the variables depending on unknown functions completely, we see that in this case there is no difference between the two kinds of variables, and the origin of the numbers $s$, $s_{1}$, $\dots$, $s_{n}$ shows their invariance under all change of variables of the dependent and independent variables.

The first two sections of this article introduce integral elements, with linear complexes that we have already talked about. Section III treats the problem consisting of making an integral variety $M_{m+1}$ pass through an integral variety $M_{m}$. Sections IV and V give some theorems, arithmetic in character, on the genre $n$ and the numbers $r_{i}$ and $s_{i}$. Section VI contains the exposition of the Cauchy problem and the degree of indeterminacy of the general integral of a system of genre $n$. Section VII is denoted to systems of the first kind and the generalised Lie-Mayer method. Finally section VIII is concerned with systems admitting characteristics in the sense of the word given above, and gives some indications on the search for these characteristics.

These researches can be extended in various directions, and the problem of the \emph{classification} of the differential systems can already, as we see, be tackled in the form of a preliminary problem, which is \emph{the search for system of linear complexes of genre $n$}. Another very important question is the study of \emph{singular} integral varieties. It is not difficult to define them, but what is interesting is the study of the new differential systems defining them. As for the original classification problem, we can without much difficulty show a certain number of interesting results, but I will not pursue this point.


\section{}
\label{sec:1}

Consider a system of equations in total differentials of $r$ variables $x_{1}$, $x_{2}$, $\dots$, $x_{r}$,
\begin{equation}
  \label{eq:1}
  \left\{
    \begin{alignedat}{3}
      \omega&\equiv& a_{1}dx_{1}+a_{2}dx_{2}+\dots+a_{r}dx_{r}&{}={}0,\\
      \vp&\equiv& b_{1}dx_{1}+b_{2}dx_{2}+\dots+b_{r}dx_{r}&=0,\\
      &\dots\\
      \chi&\equiv& l_{1}dx_{1}+l_{2}dx_{2}+\dots+l_{r}dx_{r}&=0,
    \end{alignedat}
  \right.
\end{equation}
the coefficients $a$, $b$, $\dots$, $l$ being functions of the variables $x$. We can regard a certain number $n$ of the variables $x$ as independent and the other $r-n$ as functions of them. Then the system \eqref{eq:1} which establishes linear relations among the total differentials of the $r-n$ functions and the $n$ independent variables is equivalent as a whole to a system of (linear) equations in partial derivatives which the $r-n$ functions must satisfy \footnote{Furthermore, we know that every system of equations in partial derivatives can be transformed into a system of equations in total differentials by regarding some of the partial derivatives of the unknown functions as new dependent variables, as necessary.}. Employing a geometrical language, we can say that the equations that define the $r-n$ dependent variables as functions of the $n$ independent variables represent a \emph{$n$-dimensional variety $M_{n}$} in a $r$ dimensional space, and the system \eqref{eq:1} can be regarded as establishing the conditions which must be satisfied by the differentials of the coordinates $x_{1}$, $\dots$, $x_{r}$ at a point of the variety under an arbitrary displacement on this variety. But if we observe that these differentials (or their ratios, which are the only things coming into play) are none other than the \emph{direction parameters} of the \emph{tangent} to the variety under the displacement considered, we can say that the system \eqref{eq:1} expresses that \emph{tangents to a variety $M_{n}$ at any point of the space passing by the point satisfy certain conditions depending only on the point considered}, and the form of the equations \eqref{eq:1} shows that these tangents must lie in a certain flat variety \footnote{A flat variety is, as we know, defined by linear equations. A straight line is a \emph{one} dimensional flat variety.} determined by the point.

To integrate the system \eqref{eq:1}, where we suppose the number of independent variables is equal to $n$, is therefore to resolve the following problem:

\somespace

\emph{To each point of the space we attach a flat variety \footnote{The dimension of this plane variety is, naturally, the same for all points of the space. It is equal to the difference between $r$ and the number of equations \eqref{eq:1}.} passing by the point. Determine an $n$-dimensional variety $M_{n}$ such that at each of its points all tangents to this variety lie within the flat variety corresponding to this point.}

\somespace

Every variety $M_{n}$ satisfying this condition will be called an \emph{integral} variety. This condition, thus stated, which the integral manifolds satisfy, is \emph{independent} of the dimension $n$ of the varieties.

Let us call the set of a point and a straight line passing through this point a \emph{linear element}, and furthermore, let us say that the set of a point of a variety and a tangent at this point to this variety constitutes a linear element of this variety. Let us also call linear elements satisfying equations \eqref{eq:1} (where $dx_{1}$, $dx_{2}$, $\dots$, $dx_{r}$ are regarded as direction parameters of the straight line of the element) \emph{linear integral elements}. We can then state the following proposition:

\somespace

\emph{For a variety to be integral, it is necessary and sufficient that all of its linear elements are integral.}

\section{}
\label{sec:2}

As well as the linear elements, we are going to consider what we will call \emph{$2$, $3$, $\dots$ dimensional elements}. In general, we call \emph{the set of a point and a $p$-dimensional flat variety passing through the point} a \emph{$p$-dimensional element} and we denote such an element by the general symbol $E_{p}$. We say that the element $E_{p}$ contains the element $E_{q}$ $(p>q)$ if the two elements are at the same point and if the flat variety of the first element contains the flat variety of the second entirely. In particular, a linear element will be denoted by the symbol $E_{1}$.

We call $p$-dimensional elements whose linear elements belong to a variety $M$, or more simply the elements formed by the linear elements of $M$, the \emph{elements $E_{p}$ of a variety $M$}. If the variety $M$ is $n$ dimensional, it admits elements of $2$, $3$, $\dots$, $n$ dimensions, but it does not admit $n+1$ dimensional element. At each point it admits only one $n$ dimensional element, which is formed by the set of linear elements at this point.

Every element $E_{p}$ of a \emph{integral} variety clearly enjoys the property that it contains only \emph{integral} linear elements, \emph{but it also satisfies other conditions which can be established independently of any particular integral variety}.

To derive these conditions, imagine that the coordinates of a point of a integral variety $M_{n}$ are expressed by means of $n$ parameters $u$, $v$, $\dots$, and consider two displacements on this variety, the first obtained by varying only the parameter $u$ and keeping all the others constant, and the second by varying only the parameter $v$. Let us denote by the symbols $d$ and $\delta$ the differentials relative to these two displacements. We evidently have, according to \eqref{eq:1},
\begin{align*}
  \omega_{d}&\equiv a_{1}dx_{1}+a_{2}dx_{2}+\dots+a_{r}dx_{r}=0,\\
  \omega_{\delta}&\equiv a_{1}\delta x_{1}+a_{2}\delta x_{2}+\dots+a_{r}\delta x_{r}=0,
\end{align*}
and then
\[
\omega'\equiv\delta\omega_{d}-d\omega_{\delta}=0.
\]

Forming this expression and remarking that the symbols $d$ and $\delta$ \emph{commute} $(d\delta=\delta d)$, and finally do the same for all the equations of the system \eqref{eq:1}, we arrive at the following system:
\begin{equation}
  \label{eq:2}
  \left\{
    \begin{aligned}
      \omega'&\equiv\sum_{i,k}\left(\frac{\pd a_{i}}{\pd x_{k}}-\frac{\pd a_{k}}{\pd x_{i}}\right)(dx_{i}\delta x_{k}-dx_{k}\delta x_{i})=0,\\
      &\dots\\
      \chi'&\equiv\sum_{i,k}\left(\frac{\pd l_{i}}{\pd x_{k}}-\frac{\pd l_{k}}{\pd x_{i}}\right)(dx_{i}\delta x_{k}-dx_{k}\delta x_{i})=0.
    \end{aligned}
  \right.
\end{equation}

\emph{The system \eqref{eq:2} is satisfied by every pair of displacements on the integral variety}, or by the set of a point on the variety and two tangents at this point, or generically, \emph{by two linear integral elements at the same point belonging to the same integral variety}.

Let us call an element \emph{formed by linear integral elements such that any two linear elements satisfy the system \eqref{eq:2}} the $2$, $3$, $\dots$ dimensional \emph{integral} elements. We then have the following proposition:

\somespace

\emph{Every $1$, $2$, $\dots$ dimensional element of any integral variety is integral.}

\somespace

To simplify the language, we will agree to say that two linear integral elements at the same point satisfying the system \eqref{eq:2} are \emph{associated} \footnote{Two linear elements associated to a third one are not necessarily associated themselves.}. Then an \emph{integral} element of dimension $2$, $3$, $\dots$ is \emph{an element formed by linear integral elements whose every two elements are associated}. According to the linear form of the equations \eqref{eq:2}, for an element $E_{p}$ to be integral, it \emph{suffices} that $p$ independent linear elements \footnote{We say that $p$ linear elements are \emph{independent} when they do not belong to the same $p-1$ dimensional element.} of $E_{p}$ are integral and any two of them are associated. (Furthermore every element $E_{p}$ can be defined by $p$ independent linear elements defined at the same point.)

The expressions $\omega'$, $\vp'$, $\dots$, $\chi'$, which are the left hand sides of the equations \eqref{eq:2}, are called the \emph{bilinear covariants} \footnote{Their introduction into the Pfaffian problem is due to Frobenius [\emph{Ueber das Pfaff'sche Problem}, \emph{J.~de Crelle}, 1.~\textsc{lxxxii}; 1877] and Darboux [\emph{Sur le problème de Pfaff} (\emph{Bull.~Sc.~Math.}, 2nd series, vol.~\textsc{vi}; 1882)].} of the Pfaffian expressions $\omega$, $\vp$, $\dots$, $\chi$. According to the manner that they are obtained and conforming to their names, we see that they are relative covariants under any change of variables.

We can give the system \eqref{eq:2} a geometric interpretation. Let us consider the different linear integral elements defined on a given point $A$ of the space and let us project them unto a $r-1$ dimensional flat variety $(P)$ not passing through $A$, the point of view we take being from the point $A$ itself. Then each element is defined by the \emph{mark} of its straight line on the flat variety projected unto, that is to say by a point on this variety $(P)$. With our notations, the quantities $dx_{1}$, $dx_{2}$, $\dots$, $dx_{r}$ are the homogeneous coordinates of this point in $(P)$. To say that a linear element is integral is to say that the coordinates of its projection satisfy the equations \eqref{eq:1}, i.e., are contained in a certain flat variety $(Q)$ within $(P)$. If we now take two associated linear integral element and their projections on $(P)$, the quantities $dx_{i}\delta x_{k}-dx_{k}\delta x_{i}$ are precisely the Plücker coordinates of the straight line joining these two projections. The first of the equations \eqref{eq:2} expresses a linear and homogeneous relation between these coordinates, i.e., expresses that this line belongs to a certain linear complex, and this is true for all other equations of \eqref{eq:2}.

In summary, \emph{to say that two linear elements defined at the same point $A$ are integral and associated is to say that by projecting them onto a $p-1$ dimensional flat variety $(P)$, the line joining the marks of these two elements are entirely contained in a certain flat variety $(Q)$ and, moreover, belongs to a certain number of linear complexes as well.}

And that \emph{to say that an element $E_{p}$ defined on $A$ is integral is to say that the flat variety, that is, the mark of this element on $(P)$, is situated completely within $(Q)$ and, furthermore, each of the straight lines of this variety belongs to a certain number of linear complexes.}

To summarise, at each point $A$ the given system we attach, in an arbitrarily chosen $\sigma-1$ dimensional flat variety $(P)$ not passing through $A$, a flat variety $(Q)$ and a set of linear complexes in this variety $(Q)$.

If we apply a change of variables, the elements defined on a point $A$ are linked homographically to the corresponding elements defined on the corresponding point $A'$ and \emph{the set of linear complexes corresponding to $A$ also undergoes a simple homographic transformation \footnote{It is obvious that, if we simply change the flat variety projected unto, we obtain two systems of complexes equivalent under a homographic transformation, since they are the \emph{projections} of each other. If we replace the equations \eqref{eq:1} by others that form an equivalent system, it is also obvious that neither $(Q)$ nor the set of linear complexes in $(Q)$ is changed.}.}

From this very simple remark it already follows an important consequence that, if two systems of equations in total differentials (of the same number of variables) do not correspond to points of flat varieties $(Q)$ and linear complexes that are deducible from each other by a homographic transformation, then it is imposible to reduce one of the given systems to the other by a change of variables. More precisely, if we denote the variables of the second system in total differentials by $y_{1}$, $y_{2}$, $\dots$, $y_{r}$ and the systems analogous to \eqref{eq:1} and \eqref{eq:2} by \eqref{eq:1}$'$ and \eqref{eq:2}$'$, we aim to find the conditions under which we can pass from the system [\eqref{eq:1}, \eqref{eq:2}] to the system [\eqref{eq:1}$'$, \eqref{eq:2}$'$] by a linear transformation acting on $dx_{1}$, $\dots$, $dx_{r}$ as well as $\delta x_{1}$, $\dots$, $\delta x_{r}$.

Three cases can arise. If this is not possible for any systems of values of $x$ and $y$, then no change of variables can transform one of the given systems to the other. If this is possible subject to the condition that certain algebraic relations linking $x$ and $y$ hold, then every change of variables effecting the transformations we look for, \emph{if it exists}, must respect these relations. Finally, if this is possible regardless of the values of $x$ and $y$, then we can say no more about the required change of variables, \emph{if it exists}.

We also notice, without needing to emphasise, that the classification of systems of equations in total differentials requires the preliminary classifications of all systems of linear complexes, where we do not regard two systems of complexes deducible from each other by a homographic transformation as distinct. This is, in other words, the search for the \emph{types} of the systems of linear complexes.

To apply the preceding to an example, let us consider the system
\begin{equation}
  \label{eq:3}
  \left\{
    \begin{aligned}
      \omega&=dz-p\,dx-q\,dy=0,\\
      \vp&=dp-u\,dq-a\,dx-b\,dy=0,
    \end{aligned}
  \right.
\end{equation}
where the variables are $x$, $y$, $z$, $p$, $q$, $u$ and $a$ and $b$ denote two given functions of these six variables. The integration of this system, considered as of two independent variables $x$ and $y$ becomes the integration of a second order partial differential equations admitting a system of first order characteristics and, with the usual notations, this equation is obtain by eliminating $u$ from the two relations
\begin{align*}
  r-us-a&=0,\\
  s-ut-b&=0.
\end{align*}

Here the flat variety $(Q)$ is three dimensional, since the homogeneous coordinates of one of its points are defined when we specify $dx$, $dy$, $dq$, $du$. We can therefore regard $(Q)$ as ordinary space. Here there are \emph{two} linear complexes. In space, a system of two linear complexes is always reducible to one of the following three by a homographic transformation:
\begin{align}
  \label{eq:ag}\tag{$\alpha$}
  p_{12}&=p_{34}=0,\\
  \label{eq:bg}\tag{$\beta$}
  p_{12}&=p_{13}+p_{24}=0,\\
  \label{eq:gg}\tag{$\gamma$}
  p_{12}&=p_{13}=0,  
\end{align}
$p_{ik}$ being the Plücker coordinates of the straight line. The case \eqref{eq:ag} gives the set of straight lines meeting two straight lines not within the same plane. The case \eqref{eq:bg} gives the set of tangents to a quadric fixed with respect to different points of a fixed generatrix of this quadric. The case \eqref{eq:gg} gives the set of straight lines situated in a fixed plane and the lines all originate from a fixed point of the plane.

To each of these cases there corresponds a type of second order equation of the indicated form. To the case \eqref{eq:ag} corresponds the equations whose two second order characteristic systems are distinct. To the case \eqref{eq:bg} correspond the equations with coinciding characteristics, obtained by expressing that the equation
\[
r+2us+u^{2}t+2\phi(u,x,y,z,p,q)=0
\]
admits a double root for $u$, the function $\phi$ being \emph{generic}. Finally to the case \eqref{eq:gg} correspond those equations that in the last equation the function $\phi$ satisfy a certain equation in second order derivatives, which was the subject of research of Goursat. Their interest lies in the fact that we can integrate them by systems of ordinary differential equations, as we will see in section \textsc{viii}.


\section{}
\label{sec:3}

Having settled with these preliminary notions, we are now going to be concerned with what can be called the \emph{preliminary Cauchy problem}. The problem that we name thus is the following:

\somespace

\emph{Given a $p$ dimensional integral variety $M_{p}$ of a system of equations in total differentials, extend $M_{p}$ into a $p+1$ dimensional integral variety $M_{p+1}$.}

\somespace

An obvious observation is that whenever the problem is solvable, through each element $E_{p}$ of $M_{p}$ there passes at least one \emph{integral} element $E_{p+1}$, namely the element $E_{p+1}$ of $M_{p+1}$. We therefore immediately arrive at our first necessary condition.

\emph{For the Cauchy problem to be solvable, it is necessary that through each element $E_{p}$ of the given integral variety $M_{p}$ there passes at least one integral element $E_{p+1}$.} 

Without investigating if this condition is sufficient, which it is not, we are going to concern ourselves with a particular case, but a case that nonetheless presents a great generality. \emph{We will suppose, in the following, that the given system is such that through each integral element $E_{p}$ in the space there passes at least one integral element $E_{p+1}$.} In other words, the property that elements $E_{p}$ of $M_{p}$ satisfy is supposed to hold for all integral elements $E_{p}$ of the space.

With this hypothesis, \emph{the Cauchy problem is always solvable}. However, before carrying out the proof of this proposition, it will be useful for us to present several geometrical remarks on the integral elements $E_{p+1}$ containing a given integral element $E_{p}$. If we define the element $E_{p}$ by means of $p$ independent linear elements $\epsilon^{(1)}$, $\epsilon^{(2)}$, $\dots$, $\epsilon^{(p)}$, we can define an element $E_{p+1}$ containing $E_{p}$ by means of a new linear element $\epsilon$ independent of the previous $p$ elements. We will have the elements $E_{p+1}$ we look for by expressing that $\epsilon$ is an \emph{integral} linear element and it is \emph{associated} to each of the linear elements $\epsilon^{(1)}$, $\epsilon^{(2)}$, $\dots$, $\epsilon^{(p)}$. It follows from this that \emph{the locus of the integral elements $E_{p+1}$ containing an integral element $E_{p}$ is a flat element} (not necessarily integral), since if $\epsilon$ and $\epsilon'$ provide two distinct solutions $E_{p+1}$ and $E'_{p+1}$, the $p+2$ linear elements $\epsilon^{(1)}$, $\epsilon^{(2)}$, $\dots$, $\epsilon^{(p)}$, $\epsilon$, $\epsilon'$ determine an element $E_{p+2}$ and every linear element of $E_{p+2}$ is integral and associated with $\epsilon^{(1)}$, $\epsilon^{(2)}$, $\dots$, $\epsilon^{(p)}$. In other words, all the elements $E_{p+1}$ contained in $E_{p+2}$ and containing $E_{p}$ are integral.

Analytically, the elements $E_{p+1}$ containing $E_{p}$ depend on $r-p$ homogeneous parameters \footnote{For example, if the equations of $E_{p}$ are
\[
P_{1}=P_{2}=\dots=P_{r-p}=0,
\]
where the $P$s are linear forms in $dx_{1}$, $\dots$, $dx_{r}$, the equations of $E_{p+1}$ are
\[
\frac{P_{1}}{\lambda_{1}}=\frac{P_{2}}{\lambda_{2}}=\dots=\frac{P_{r-p}}{\lambda_{r-p}}.
\]}. The equations expressing that $E_{p+1}$ is integral are \emph{linear} with respect to these parameters.

Suppose that, for an \emph{arbitrary} element $E_{p}$, these equations reduce to $r-p-s-1$ independent ones, $s$ being zero or positive. Then through each arbitrary integral element $E_{p}$ there will pass at least an integral element $E_{p+1}$. There will pass one and only one if $s$ is zero, and an infinite number of elements depending on $s$ arbitrary constants if $s$ is positive. We say in these two cases that there passes $\infty^{s}$ elements. The locus of all these elements is an element $E_{p+s+1}$.

It is possible that for a particular integral element $E_{p}$ there is yet greater indetermination: we say in this case that the integral element $E_{p}$ is \emph{singular}. An integral variety $M_{p}$ whose elements $E_{p}$ are all singular will be called a \emph{singular} integral variety.

We now arrive at the solution of the Cauchy problem. We are going to prove the following theorem:

\somespace

\emph{Given a non-singular integral variety $M_{p}$, there always passes through this variety at least one integral variety $M_{p+1}$. There passes one and only one if each non-singular element $E_{p}$ belongs to one and only one integral element $E_{p+1}$. There passes an infinite number of varieties depending on $s$ arbitrary functions of $p+1$ arguments if each non-singular integral element $E_{p}$ belongs to $\infty^{s}$ integral elements $E_{p+1}$.}

\somespace

To make it more precise, take a particular non-singular element $E_{p}^{0}$ of $M_{p}$. Let $(x_{1}^{0},x_{2}^{0},\dots,x_{r}^{0})$ be the coordinates of the point where this element is based at. Suppose that the variety $M_{p}$ is \emph{analytic}, that is to say in a neighbourhood of the point $(x_{i}^{0})$, $r-p$ of the coordinates $x$, which we take to be $x_{p+1}$, $\dots$, $x_{r}$, are expressed as holomorphic functions in $x_{1}-x_{1}^{0}$, $x_{2}-x_{2}^{0}$, $\dots$, $x_{p}-x_{p}^{0}$. Then the $r-p$ equations of the element $E_{p}^{0}$ can be solved with respect to $dx_{p+1}$, $\dots$, $dx_{r}$. Take a particular integral element $E_{p+1}^{0}$ passing through $E_{p}^{0}$. The $r-p-1$ linear equations defining it can be solved with respect to $r-p-1$ of the differentials $dx_{p+1}$, $\dots$, $dx_{r}$, which we take to be $dx_{p+2}$, $\dots$, $dx_{r}$. If an integral variety $M_{p+1}$ admits the element $E_{p+1}^{0}$, this signifies that $x_{p+2}$, $\dots$, $x_{r}$ are expressed as holomorphic functions in $x_{1}$, $\dots$, $x_{p+1}$ in a neighbourhood of the point considered. For convenience of the following exposition, we are going to change the notations by continuing to use $x_{1}$, $x_{2}$, $\dots$, $x_{p}$ but replacing $x_{p+1}$ by $x$ and the other variables $x_{p+2}$, $\dots$, $x_{r}$ by $z_{1}$, $z_{2}$, $\dots$, $z_{m}$ $(m=r-p-1)$.

With these notations the equations of the variety $M_{p}$ are
\begin{equation}
  \label{eq:4}
  \left\{
    \begin{aligned}
      x&=\phi(x_{1},x_{2},\dots,x_{p}),\\
      z_{1}&=\phi_{1}(x_{1},x_{2},\dots,x_{p}),\\
      &\dots\\
      z_{m}&=\phi_{m}(x_{1},x_{2},\dots,x_{p}),
    \end{aligned}
  \right.
\end{equation}
and the variety $M_{p+1}$ we look for can be defined by specifying $z_{1}$, $z_{2}$, $\dots$, $z_{m}$ as holomorphic functions of $x$, $x_{1}$, $\dots$, $x_{p}$ in a neighbourhood of $x_{0}$, $x_{1}^{0}$, $\dots$, $x_{p}^{0}$.

Now let us effect a change of variables conserving the variables $x_{1}$, $x_{2}$, $\dots$, $x_{p}$; $z_{1}$, $\dots$, $z_{m}$ and taking the new variable $x$ to be the quantity $x-\phi$, which obvious does not change any conventions that we have made previously. This implies in the formulae \eqref{eq:4} we suppose $\phi\equiv 0$ and $x^{0}=0$.

To complete the statement of these preliminary conventions, we suppose that the coefficients $a$, $b$, $\dots$, $l$ of system \eqref{eq:1} are holomorphic in a neighbourhood of $(x^{0},x_{1}^{0}$, $\dots$, $z_{m}^{0})$.

The variety $M_{p+1}$ we search for is defined by $m$ functions $z_{1}$, $z_{2}$, $\dots$, $z_{m}$ of the $p+1$ variables $x$, $x_{1}$, $\dots$, $x_{p}$, holomorphic in the neighbourhood of $(0,x_{1}^{0},\dots, x^{0}_{p})$ and subject to be reduced to $m$ previously given functions $\phi_{1}$, $\phi_{2}$, $\dots$, $\phi_{m}$ in $x_{1}$, $x_{2}$, $\dots$, $x_{p}$ for $x=0$.

The equations determining these functions reduce to the equations \eqref{eq:1} by replacing $dz_{1}$, $\dots$, $dz_{m}$ by their values and identifying the relevant quantities, but \emph{we are going to substitute the system thus obtained by another system containing a bigger number of equations expressing simply that the elements $E_{p+1}$ of the variety $M_{p+1}$ are integral.} 

For this, observe that each element $E_{p+1}$ of $M_{p+1}$ can be defined by $p+1$ independent linear elements, namely those that we obtain by varying only one of the independent variables $x$, $x_{1}$, $\dots$, $x_{p}$. These $p+1$ elements that we will call $\epsilon^{(1)}$, $\dots$, $\epsilon^{(p)}$ are defined by
\begin{gather}
  \label{eq:eg}\tag{$\epsilon$}
  \frac{dx}{1}=\frac{dx_{1}}{0}=\dots=\frac{dx_{p}}{0}=\frac{dz_{1}}{\frac{\pd z_{1}}{\pd x}}=\dots=\frac{dz_{m}}{\frac{\pd z_{m}}{\pd x}},\\
  \label{eq:e1g}\tag{$\epsilon^{(1)}$}
  \frac{dx}{0}=\frac{dx_{1}}{1}=\dots=\frac{dx_{p}}{0}=\frac{dz_{1}}{\frac{\pd z_{1}}{\pd x_{1}}}=\dots=\frac{dz_{m}}{\frac{\pd z_{m}}{\pd x_{1}}},\\
  \label{eq:epg}\tag{$\epsilon^{(p)}$}
  \frac{dx}{0}=\frac{dx_{1}}{0}=\dots=\frac{dx_{p}}{1}=\frac{dz_{1}}{\frac{\pd z_{1}}{\pd x_{p}}}=\dots=\frac{dz_{m}}{\frac{\pd z_{m}}{\pd x_{p}}}.
\end{gather}

We will divide the equations expressing that $E_{p+1}$ is integral into two groups. In the first group we express that the element $E_{p}$ defined by $\epsilon^{(1)}$, $\epsilon^{(2)}$, $\dots$, $\epsilon^{(p)}$ is integral, and in the second group we express that $\epsilon$ is integral and associated with $\epsilon^{(1)}$, $\epsilon^{(2)}$, $\dots$, $\epsilon^{(p)}$.

If one of the equations of the system is
\[
\omega\equiv a\,dx+a_{1}dx_{1}+\dots+a_{p}dx_{p}+b_{1}dz_{1}+\dots+b_{m}dz_{m}=0,
\]
we will set
\begin{align*}
  \Omega&\equiv a+b_{1}\frac{\pd z_{1}}{\pd x}+\dots+b_{m}\frac{\pd z_{m}}{\pd x},\\
  \Omega_{i}&\equiv a_{i}+b_{1}\frac{\pd z_{1}}{\pd x_{i}}+\dots+b_{m}\frac{\pd z_{m}}{\pd x_{i}},\qquad (i=1,2,\dots,p).
\end{align*}

With these notations, the equations of the first group are, as it is easy to see,
\begin{equation}
  \label{eq:I}\tag{I}
  \left\{
    \begin{aligned}
      \Omega_{i}&=0,\qquad\frac{\pd\Omega_{i}}{\pd x_{j}}-\frac{\pd\Omega_{j}}{\pd x_{i}}=0\qquad (i,j=1,2,\dots,p),\\
      &\dots
    \end{aligned}
  \right.
\end{equation}
and those of the second group are, for example,
\begin{equation}
  \label{eq:II}\tag{II}
  \left\{
    \begin{aligned}
      \Omega&=0,\qquad\frac{\pd\Omega}{\pd x_{i}}-\frac{\pd\Omega_{i}}{\pd x}=0\qquad (i=1,2,\dots,p),\\
      &\dots
    \end{aligned}
  \right.
\end{equation}
the dots are from the other equations $\vp=0$, $\dots$, $\chi=0$ of the given system. The symbol $\frac{\pd f}{\pd x_{i}}$ denotes the derivation with respect to $x_{i}$, regarding $z_{1}$, $z_{2}$, $\dots$, $z_{m}$ as functions of $x_{i}$.

The equations \eqref{eq:I} do not contain $\frac{\pd z_{1}}{\pd x}$, $\dots$, $\frac{\pd z_{m}}{\pd x}$ and those in the second group are \emph{linear} with respect to these quantities. We can simplify them further by using the equations \eqref{eq:I}.

Let us now consider the hypotheses we already made. When the element $E_{p}$ defined by $\epsilon^{(1)}$, $\epsilon^{(2)}$, $\dots$, $\epsilon^{(p)}$ is integral, the equations $\phi$ must satisfy for $E_{p+1}$ to be integral are compatible. This signifies that, \emph{when the equations are satisfied, the equations \eqref{eq:II}, considered as equations linear in $\frac{\pd z_{1}}{\pd x}$, $\dots$, $\frac{\pd z_{m}}{\pd x}$ are algebraically compatible}. More precisely, they reduce to $m-s$ linearly independent equations. In particular, by hypothesis, this is true for the system of values $(0,x_{1}^{0}, \dots, x_{m}^{0})$. To fix ideas, we suppose that these $m-s$ equations are, for the initial values, solvable with respect to
\[
\frac{\pd z_{1}}{\pd x},\qquad\frac{\pd z_{2}}{\pd x},\qquad\dots\qquad\frac{\pd z_{m-s}}{\pd x},
\]
and let us write them as
\begin{equation}
  \label{eq:II'}\tag{II$'$}
  \left\{
    \begin{aligned}
      \frac{\pd z_{1}}{\pd x}&=\Phi_{1}\left(x,x_{i},z_{k},\frac{\pd z_{k}}{\pd x_{j}},\frac{\pd z_{m-s+1}}{\pd x},\dots,\frac{\pd z_{m}}{\pd x}\right),\\
      &\dots,\\
      \frac{\pd z_{m-s}}{\pd x}&=\Phi_{m-s}\left(x,x_{i},z_{k},\dots,\frac{\pd z_{m}}{\pd x}\right),
    \end{aligned}
  \right.
\end{equation}
the $\Phi$s being holomorphic in their arguments in a neighbourhood of their initial values (and linear with respect to $\frac{\pd z_{m-s+1}}{\pd x}$, $\dots$, $\frac{\pd z_{m}}{\pd x}$).

Granted this, instead of satisfying the set of equations \eqref{eq:I} and \eqref{eq:II}, we satisfy only the equations \eqref{eq:II'}, recalling that the equations \eqref{eq:I} and \eqref{eq:II'} imply the equations \eqref{eq:II} algebraically.

We are now going to find a solution of the equations \eqref{eq:II'} satisfying the following conditions: $z_{1}$, $\dots$, $z_{m}$ are holomorphic functions of $x$, $x_{1}$, $\dots$, $x_{p}$ in a neighbourhood of $(0,x_{1}^{0}, \dots, x_{p}^{0})$ and on $x=0$ reduce to the $m$ given functions $\phi_{1}$, $\dots$, $\phi_{m}$ in $x_{1}$, $\dots$, $x_{p}$.

The system \eqref{eq:II'} is a Kowalewski system. According to the work on these systems, there exists one and only one solution, holomorphic in a neighbourhood of $(0,x_{1}^{0},\dots,x_{p}^{0})$, such that $z_{m-s+1}$, $\dots$, $z_{m}$ are arbitrarily given (holomorphic) functions and that $z_{1}$, $\dots$, $z_{s}$ reduce to $s$ given functions of $x_{1}$, $\dots$, $x_{p}$ on $x=0$. 

\emph{Granted this, we take}
\begin{align*}
  z_{m-s+1}&=f_{m-s+1}(x,x_{1},\dots,x_{p}),\\
  &\dots\\
  z_{m}&=f_{m}(x,x_{1},\dots,x_{p})
\end{align*}
\emph{the $s$ functions $f$ being subject to the single condition that they reduce to the $s$ given functions $\phi_{m-s+1}$, $\dots$, $\phi_{m}$ on $x=0$. These $s$ functions chosen, the system \eqref{eq:II'} admite a single solution satisfying the stated conditions.}

Furthermore, we see that we can always arrange them in a manner that for $x=0$, $x_{i}=x_{i}^{0}$, the $s$ quantities $\frac{\pd z_{m-s+1}}{\pd x}$, $\dots$, $\frac{\pd z_{m}}{\pd x}$ take arbitrarily fixed values, that is to say \emph{for the variety $M_{p+1}$ thus determined to admit at will the integral elements $E_{p+1}$ passing through $E_{p}^{0}$.}

The original problem is not yet solved, since even if it is clear that the integral varieties we search for can only be found among the varieties just determined by Kowalewski's theorem, it does not follow that these varieties are really \emph{integral}. In other words, we still have to prove that these varieties satisfy the equations \eqref{eq:I} and \eqref{eq:II}. To this end, \emph{we are going to show that, if a variety $M_{p+1}$ determined as above satisfy the equations \eqref{eq:I} and \eqref{eq:II} for a certain value of $x$, it also satisfy them for an infinitesimally near value $x+\delta x$.}

If this is proved, as for $x=0$ the equations \eqref{eq:I} express that the variety $M_{p}$ which $M_{p+1}$ reduces to is integral, which is none other than our hypothesis, and that the equations \eqref{eq:II'} are assumed to be verified for the variety $M_{p+1}$, and hence the equations \eqref{eq:II} as well, it follows that the equations \eqref{eq:I} and \eqref{eq:II} are satisfied for all values of $x$.

Now suppose for a certain value of $x$ the equations \eqref{eq:I} and \eqref{eq:II} are satisfied. We have then, in particular, for this value of $x$,
\[
\Omega=0,\qquad\Omega_{i}=0,\qquad\frac{\pd\Omega_{i}}{\pd x}-\frac{\pd \Omega}{\pd x_{i}}=0.
\]

But if $\Omega$ is zero, the same is true for its derivative $\frac{\pd\Omega}{\pd x_{i}}$ taken with respect to the variable $x_{i}$ \emph{independent of $x$}. Therefore $\frac{\pd \Omega_{i}}{\pd x}$ is zero for the value of $x$ considered. To say that $\Omega_{i}$ and $\frac{\pd \Omega_{i}}{\pd x}$ vanish for the value $x$ is the same as saying that $\Omega_{i}$ vanishes for the infinitesimally close value $x+\delta x$. Similarly, this is true of $\frac{\pd\Omega_{i}}{\pd x_{j}}$ and analogous quantities on $x+\delta x$. Therefore, \emph{on $x+\delta x$, the equations \eqref{eq:I} are satisfied.} By hypothesis, the equations \eqref{eq:II'} are satisfied as well, and as a consequence the equations \eqref{eq:II} which are equivalent to \eqref{eq:II'} if we take into considerations \eqref{eq:I} are satisfied. Therefore, \emph{on $x+\delta x$, all of the equations \eqref{eq:I} and \eqref{eq:II} are satisfied.}

The theorem is hence demonstrated. We will give it the name \emph{Cauchy's theorem}, by analogy with a well known theorem in the theory of first order partial differential equations, which is a particular case of this.

As an application we apply this theorem to the system \eqref{eq:3}. We see that each linear integral element at an arbitrarily given point can be represented by a point in ordinary space and an integral element $E_{2}$ is represented by a straight line which, in the general case, is subject to meet two fixed lines not lying in the same plane. It follows from this in an obvious way that, through every integral element, there passes one and only one two dimensional integral element (through a point in ordinary space there passes one and only one straight line meeting two fixed lines.) Therefore through every non singular integral variety $M_{1}$ there passes one and only one integral variety $M_{2}$. The singular linear elements are here those that are represented by the different points on two fixed straight lines. The singular integral varieties $M_{1}$ can hence be divided into two distinct series, and they are none other than what we call the \emph{characteristics} in the theory of second order equations.

Let us return to the general case. An integral variety $M_{1}$ of the system \eqref{eq:3} is obtained, by example, by taking $x$, $y$, $z$, $p$, $q$ to be five functions of the same variable parameter subject to the equation
\[
dz-p\,dx-q\,dy=0,
\]
and by determining $u$ by the equation
\[
p'-uq'-ax'-by'=0.
\]
In geometrical language, we thus obtain in the space $(x,y,z)$ the set of a curve and a developable surface circumscribing this curve, and Cauchy's theorem shows that \emph{second order partial differential equations equivalent to the system \eqref{eq:3} always admit one and only one integral surface in the space $(x,y,z)$ passing through an arbitrarily given curve and circumscribing along this curve an arbitrarily given developable surface.}

\section{}
\label{sec:4}

Cauchy's theorem makes the importance of the following property of the system \eqref{eq:1} evident, which is that each integral element $E_{p}$ belongs to at least one integral element $E_{p+1}$. This justifies the following definition:

\emph{We say that a system of total differential equations is of \textsc{genre} $n$ if the integral elements with respect to the system satisfy the following conditions:}

\emph{Through an arbitrary point it passes at least one integral element $E_{1}$, through an arbitrary integral element $E_{1}$ there passes at least one integral element $E_{2}$, etc.;}

\emph{Through an arbitrary integral element $E_{n-1}$ there passes at least one integral element $E_{n}$;}
\emph{But through an arbitrary  integral element $E_{n}$ there does not pass any integral element $E_{n+1}$.}

More precisely, we assume that there passes
\[
\begin{matrix*}[l]
  \text{through an arbitrary point }&\infty^{r_{1}} &\text{integral elements } E_{1},\\
  \text{through an arbitrary integral element } E_{1}&\infty^{r_{2}}&\text{integral elements }E_{2},\\
  \hdotsfor{3}\\
  \text{through an arbitrary integral element } E_{n-1}&\infty^{r_{n}}&\text{integral elements }E_{n},
\end{matrix*}
\]
some of the numbers $r_{1}$, $r_{2}$, $\dots$, $r_{n}$ may be zero, and we continue to denote by $r$ the number of variables, which is to say that there are $\infty^{r}$ points.

We also sometimes say that the system, \emph{considered as of $i\le n$ independent variables}, is \emph{in involution}.

A system of genre \emph{zero} necessarily entails that
\[
dx_{1}=dx_{2}=\dots=dx_{r}=0,
\]
and we can leave such systems aside.

According to the preceding and Cauchy's theorem, we see immediately the following property of a system of genre $n$:

\emph{A system of genre $n$ always admits at least one integral variety $M_{1}$ passing through an arbitrary point, an integral variety $M_{2}$ passing through an arbitrary integral variety $M_{1}$, etc., an integral variety $M_{n}$ passing through an arbitrary integral variety $M_{n-1}$.}

We will agree to say that an integral element $E_{n}$ is \emph{singular} if it belongs to at least one integral element $E_{n+1}$, an integral element $E_{n-1}$ is singular if it belongs to more than $\infty^{r_{n}}$ integral elements $E_{n}$, or if the $\infty^{r_{n}}$ integral elements that it belongs to are all singular, etc., and finally a point is singular if it belongs to more than $\infty^{r_{1}}$ integral elements $E_{1}$, or if the $\infty^{r_{1}}$ linear elements that based on it are all singular.

The conditions a singular integral element must satisfy are \emph{equality} conditions, and hence we can see clearly that we can always, in an infinite number of ways, find a series of integral elements 
\[
E_{0},\qquad E_{1},\qquad E_{2},\qquad \dots,\qquad E_{n},
\]
where $E_{0}$ denotes a point belonging to all the following elements in the series and none of the following elements are singular. Then we can claim the existence of an integral variety $M_{1}$ passing through the point $E_{0}$ and admitting the element $E_{1}$, of an integral variety $M_{2}$ passing through $M_{1}$ and admitting the element $E_{2}$, $\dots$, of an integral variety passing through $M_{n-1}$ and admitting the element $E_{n}$, \emph{but finally we can claim that through $M_{n}$ there passes no integral variety $M_{n+1}$}, since the element $E_{n}$ does not belong to any integral element $E_{n+1}$.

Therefore, \emph{a system of genre $n$ does not admit integral varieties $M_{n+1}$ passing through an ordinary integral variety.}

These propositions make the importance of the \emph{genre} of a system of equations in total differentials evident.

\section{}
\label{sec:5}

The numbers $r$, $r_{1}$, $r_{2}$, $\dots$, $r_{n}$ play a big role in the study of the indeterminacy of the most general $n$ dimensional general integral variety. Before beginning this study, let us prove some remarkable properties of these numbers.

We are first going to prove the following theorem:

\somespace

\emph{In the series}
\[
r,\qquad r_{1},\qquad r_{2},\qquad\dots,\qquad r_{n},
\]
\emph{each number is greater than the following by at least one.}

\somespace

Indeed, first the linear elements defined on a point in the space depend on $r-1$ parameters. But these are not necessarily all integral, therefore
\[
r-1\ge r_{1}.
\]

In a generic manner, take a non-singular integral element $E_{p-1}$. By hypothesis, this element belongs to $\infty^{r_{p}}$ integral elements $E_{p}$, where at least one of them is non-singular. Each of them can be defined by a linear (integral) element independent of $E_{p-1}$, which gives us $r_{p}+1$ linear elements
\[
\epsilon, \qquad\epsilon_{1},\qquad\epsilon_{2},\qquad\dots,\qquad\epsilon_{r_{p}}
\]
independent among themselves and of $E_{p-1}$. We can suppose, for example, that the integral element $(E_{p-1},\epsilon)$ is not singular. This element, in turn, belongs to $\infty^{r_{p+1}}$ integral elements $E_{p+1}$, each of which is defined by means of a linear element independent of $(E_{p-1},\epsilon)$, but which is necessarily expressed in terms of $E_{p-1}$, $\epsilon$, $\epsilon_{1}$, $\dots$, $\epsilon_{r_{p}}$. It is therefore necessary that we can find $r_{p+1}+1$ such independent elements. Therefore we have
\[
r_{p}\ge r_{p+1}+1.
\]
\qed

It follows from this that each of the numbers
\[
r,\quad r_{1}+1,\quad r_{2}+2,\quad\dots,\quad r_{i}+i,\quad\dots,\quad r_{n-1}+n-1,\quad r_{n}+n
\]
is at least equal to $n$, since these numbers cannot increase and the last one is at least equal to $n$.

Here is a second proposition:

\somespace

\emph{Through every non-singular element $E_{p-1}$ there passes $\infty^{r_{p}+r_{p+1}-1}$ integral elements $E_{p+1}$ $(p\le n-1)$.}

\somespace

Indeed, take a non-singular integral element $E_{p-1}$. Let
\[
\epsilon,\qquad\epsilon_{1},\qquad\epsilon_{2},\qquad\dots,\qquad\epsilon_{r_{p}}
\]
be $r_{p}+1$ linear elements independent among themselves and of $E_{p-1}$ which define $r_{p}+1$ independent integral elements $E_{p}$. Suppose, to fix ideas, that the element $(E_{p-1},\epsilon_{1})$ that we will denote by $E_{p}^{0}$ is not singular. Also suppose, as always possible, that one of the integral elements $E_{p+1}$ passing through $E_{p}^{0}$ is $(E_{p-1},\epsilon,\epsilon_{1})$. Let $E_{p+1}^{0}$ be this element. Every integral element $E_{p+1}$ passing through $E_{p-1}$ is obtained by adjoining two linear elements $\epsilon'$, $\epsilon''$ depending on $\epsilon$, $\epsilon_{1}$, $\dots$, $\epsilon_{r_{p}}$. In general, there will exist only one combination element linear in $\epsilon'$ and $\epsilon''$ and depending on $(\epsilon_{1},\dots,\epsilon_{r_{p}})$ (since this is so for the particular element $E_{p+1}^{0}$). Therefore we see that every integral element $E_{p+1}$ passing through $E_{p-1}$ can be obtained in only one manner by taking a linear element $\epsilon'$ depending on $\epsilon_{1}$, $\epsilon_{2}$, $\dots$, $\epsilon_{r_{p}}$, and by making the element $E_{p+1}$ to pass through the element $E_{p}$ thus obtained in the most general manner. But $\epsilon'$ depends on $r_{p}-1$ parameters, and hence it is the same for $E_{p}$. Moreover, through $E_{p}$ passes exactly $\infty^{r_{p+1}}$ integral elements $E_{p+1}$ (since for the particular non singular element $E_{p}^{0}$, this is the case). Therefore $E_{p+1}$ depends on
\[
r_{p}-1+r_{p+1}
\]
parameters.

The proof proceeds in the same manner for $p=1$.

We are going to prove in the same way that if $p\le n-2$, \emph{through a non-singular integral element $E_{p-1}$ there passes $\infty^{r_{p}-2+r_{p+1}-1+r_{p+2}}$ integral elements $E_{p+2}$.}

Let us continue to use the same notations. Denote by $E_{p}^{0}$ a non-singular integral element passing through $E_{p-1}$ and let it be $(E_{p-1},\epsilon_{2})$, by $E_{p+1}^{0}$ a non-singular integral element passing through $E_{p}^{0}$ and let it be $(E_{p-1},\epsilon_{1},\epsilon_{2})$, and by $E_{p+2}^{0}$ an integral element passing through $E_{p+1}^{0}$ and let it be $(E_{p-1},\epsilon,\epsilon_{1},\epsilon_{2})$. Then every integral element $E_{p+2}$ can be obtained \emph{in only one manner} by adjoining to $E_{p-1}$ an linear element $\epsilon'$ depending on $(\epsilon_{2},\epsilon_{3},\dots,\epsilon_{r_{p}})$ and making an integral element $E_{p+2}$ to pass the element $E_{p}$ thus obtained: the particular integral element $E_{p+1}^{0}$ indeed contains only one integral element $E_{p}$ satisfying this condition, namely $E_{p}^{0}$. But the element $\epsilon'$ depends on $r_{p}-2$ parameters, and hence this is true for $E_{p}$ as well. Moreover, through $E_{p}$ which is not singular (since, in particular, $E_{p}^{0}$ is not) there passes $\infty^{r_{p+1}+r_{p+2}-1}$ integral elements $E_{p+2}$. Therefore the number of parameters $E_{p+2}$ depends on is equal to
\[
(r_{p}-2)+(r_{p+1}-1)+r_{p+2}.
\]
\qed

We see how the theorem generalises step by step. Generally, \emph{if $p\le n-i$, through a non-singular integral element $E_{p-1}$ there passes integral elements $E_{p+i}$ depending on}
\[
(r_{p}-i)+(r_{p+1}-(i-1))+\dots+(r_{p+i-1}-1)+r_{p+i}=r_{p}+\dots+r_{p+i}-\frac{i(i+1)}{2}
\]
\emph{arbitrary constants.}

Of course, the locus of all these elements is not, in general, a flat element, except when $i$ is zero.

In particular, through a non-singular point of space there passes an infinite number of integral elements $E_{n}$ depending on
\[
r_{1}+r_{2}+\dots+r_{n}-\frac{n(n-1)}{2}
\]
arbitrary constants. If $n=r$, then $r_{1}=n-1$, $\dots$, $r_{n}=0$, and there is only one integral element $E_{n}$.

Finally, here is the last very important theorem on the series of numbers $r$:

\somespace

\emph{In the series of positive or zero integers}
\[
r-r_{1}-1,\qquad r_{1}-r_{2}-1,\qquad \dots,\qquad r_{n-1}-r_{n}-1,
\]
\emph{each number is greater than or equal to the following number.}

\somespace

The fact that the numbers considered are positive or zero results from the first theorem proved on the series
\[
r,\qquad r_{1},\qquad \dots,\qquad r_{n}.
\]

To prove the theorem stated, consider a non-singular integral element $E_{p-1}$. It is possible to find a non-singular integral element $E_{p}^{0}$ passing through $E_{p-1}$, and in turn a non-singular integral element $E_{p+1}^{0}$ passing through $E_{p}^{0}$, and finally an integral element $E_{p+2}^{0}$ through $E_{p+1}^{0}$. (We suppose that $p\le n-2$). Let $\epsilon$, $\epsilon_{1}$, $\epsilon_{2}$ be three linear elements independent of $E_{p-1}$ which define $E_{p+2}^{0}$. These three elements are therefore integral, associated with $E_{p-1}$ and associated among themselves. But there exists $r_{p}+1$ independent linear integral elements associated with $E_{p-1}$. We can therefore denote them by
\[
\epsilon,\qquad\epsilon_{1},\qquad\epsilon_{2},\qquad\dots,\qquad\epsilon_{r_{p}}.
\]

Let us find all the integral elements $E_{p+2}$ containing $E_{p-1}$. Each of them will contain at least a linear element $\epsilon''$ which is linear in
\[
\epsilon_{2},\qquad\epsilon_{3},\qquad\dots,\qquad\epsilon_{r_{p}},
\]
and in general, it will contain only one (as $E_{p+2}^{0}$). Similarly it will contain one, and in general only one linear element $\epsilon'$ linear in
\[
\epsilon_{1},\qquad\epsilon_{3},\qquad\dots,\qquad\epsilon_{r_{p}},
\]
and finally one and only one $\epsilon'''$ linear in
\[
\epsilon,\qquad\epsilon_{3},\qquad\dots,\qquad\epsilon_{r_{p}}.
\]

We see that, in general, an element $E_{p+2}$ we search for will be \emph{defined} by three linear elements $\epsilon'$, $\epsilon''$, $\epsilon'''$. Each of them depends on $r_{p}-2$ parameters, which gives a total of
\[
3(r_{p}-2)
\]
parameters. For the element to be integral, it is necessary and sufficient that these three elements are associated among themselves. But an arbitrary element $\epsilon$ linear in $\epsilon$, $\epsilon_{1}$, $\dots$, $\epsilon_{r_{p}}$, is associated to $r_{p+1}+1$ other independent elements of the same form. In other words, to express that an arbitrary element linear in $\epsilon$, $\dots$, $\epsilon_{r_{p}}$ depending on $r_{p}$ parameters is associated to a particular element of the same form, it is necessary that these $r_{p}$ parameters satisfy $r_{p}-r_{p+1}-1$ relations. Coming back to our three elements $\epsilon'$, $\epsilon''$, $\epsilon'''$, we therefore see that, for every two of them to be associated, there must be \emph{at most} $r_{p}-r_{p+1}-1$ relations among these parameters, which gives in total \emph{at most}
\[
3(r_{p}-r_{p+1}-1)
\]
relations. As there are
\[
3(r_{p}-2)
\]
parameters, we see that  \emph{the integral elements $E_{p+2}$ passing through a non-singular integral element $E_{p-1}$ depend on \textsc{at least}}
\[
3(r_{p}-2)-3(r_{p}-r_{p+1}-1)=3r_{p+1}-3
\]
\emph{parameters.}

Or, according to a preceding theorem, this number of parameters is equal to
\[
r_{p}+r_{p+1}+r_{p+2}-3,
\]
we therefore have
\[
r_{p}+r_{p+1}+r_{p+2}-3\ge 3 r_{p+1}-3,
\]
i.e.,
\[
r_{p}-r_{p+1}\ge r_{p+1}-r_{p+2}.
\]
\qed

This proof also holds if $p$ is equal to $1$.

We can complete this theorem by the following remark:

\somespace

\emph{If $n$ is the genre of the system, we have}
\[
r_{n-1}-r_{n}-1\ge r_{n}.
\]

Indeed, let $E_{n-2}$ be a non-singular integral element. Let us denote by $(E_{n-2},\epsilon)$ or $E_{n-1}^{0}$ a non-singular integral element passing through $E_{n-2}$, and by $(E_{n-2},\epsilon,\epsilon_{1})$ or $E_{n}^{0}$ a non-singular integral element passing through $E_{n-1}^{0}$. We can find $r_{n-1}+1$ independent linear integral elements associated to $E_{n-2}$, and as $\epsilon$ and $\epsilon_{1}$ are already two among them, we can denote them by
\[
\epsilon,\qquad\epsilon_{1},\qquad\epsilon_{2},\qquad\dots,\qquad\epsilon_{r_{n-1}}.
\]

Through $E_{n-1}^{0}$ there passes exactly $\infty^{r_{n}}$ integral elements $E_{n}$. We can therefore suppose that they reduce to
\[
(E_{n-2},\epsilon,\epsilon_{1}),\qquad(E_{n-2},\epsilon,\epsilon_{2}),\qquad\dots,\qquad(E_{n-2},\epsilon,\epsilon_{r_{n}+1}).
\]

Now take the integral element $(E_{n-2},\epsilon_{1})$. It also belongs to (at least) $\infty^{r_{n}}$ integral elements $E_{n}$. We can obtain each of them by means of a linear element formed with
\[
\epsilon,\qquad\epsilon_{1},\qquad\epsilon_{2},\qquad\dots,\qquad\epsilon_{r_{n-1}},
\]
which is associated to $\epsilon_{1}$. But if we take those which are formed with
\[
\epsilon,\qquad\epsilon_{1},\qquad\dots,\qquad\epsilon_{r_{n}+1},
\]
\emph{there is only $\epsilon$}, otherwise, for example if there is $\epsilon_{2}$, the element
\[
(E_{n-2},\epsilon,\epsilon_{1},\epsilon_{2})
\]
\emph{will be integral}, which contradicts the hypothesis since it passes through the \emph{non-singular} element $E_{n}^{0}$. Therefore there exists at least $r_{n}$ independent linear elements that can be formed with
\[
\epsilon_{r_{n}+2},\qquad\dots,\qquad\epsilon_{r_{n-1}},
\]
and we necessarily have \footnote{The proof does not hold if $n=1$. But the theorem still holds and it is trivial to give the proof.}
\[
r_{n-1}-r_{n}-1\ge r_{n}.
\]
\qed

\emph{From these several theorems it follows the series of inequalities}
\begin{equation}
  \label{eq:5}
  r-r_{1}-1\ge r_{1}-r_{2}-1\ge \dots\ge r_{n-1}-r_{n}-1\ge r_{n}.
\end{equation}

The numbers in this series play a very big role. We denote them by
\[
s,\qquad s_{1},\qquad s_{2},\qquad \dots,\qquad s_{n}
\]
by setting
\begin{equation}
  \label{eq:6}
  \left\{
    \begin{alignedat}{3}
      &s&&=r-r_{1}-1,\\
      &s_{1}&&=r_{1}-r_{2}-1,\\
      &&&\dots\\
      &s_{n-1}&&=r_{n-1}-r_{n}-1,\\
      &s_{n}&&=r_{n}.
    \end{alignedat}
  \right.
\end{equation}

A particularly interesting case is that in the series of $s$ there is a term that is zero. Suppose that $s_{\nu}$ $(\nu<n)$ is the first one with this property. Then we necessarily have, according to the inequality \eqref{eq:5},
\[
s_{\nu}=s_{\nu+1}=\dots=s_{n}=0.
\]

The following considerations allow us to derive this result using another method and at the same time lead us to new and important properties of these systems.

Consider a non-singular integral element $E_{\nu-1}$. Let $(E_{\nu-1},\epsilon)$ be a non-singular integral element containing $E_{\nu-1}$, $\epsilon$ denoting a linear integral element independent of $E_{\nu-1}$ and associated with $E_{\nu-1}$. Through this element $(E_{\nu-1},\epsilon)$ there passes $\infty^{r_{\nu+1}}$ integral elements of $\nu+1$ dimensions, that is to say, as $s_{\nu}=0$ and $r_{\nu+1}$ is equal to $r_{\nu}-1$, we can find $r_{\nu}$ and only $r_{\nu}$ linear integral elements independent among themselves and with $(E_{\nu},\epsilon)$ and associated with $E_{\nu-1}$ and $\epsilon$. Let them be
\[
\epsilon_{1},\qquad \epsilon_{2},\qquad \dots,\qquad\epsilon_{r_{\nu}}.
\]
But we cannot find more than $r_{\nu}+1$ linear intergal elements that are independent among themselves and of $E_{\nu-1}$ and associated to $E_{\nu-1}$. Therefore \emph{every integral element associated to $E_{\nu-1}$ is formed linearly with}
\[
E_{\nu-1},\qquad\epsilon,\qquad\epsilon_{1},\qquad\dots,\qquad\epsilon_{r_{\nu}}.
\]

It follows from this that any two of these elements are associated, for example, $\epsilon_{1}$ and $\epsilon_{2}$, since the integral element $(E_{\nu-1},\epsilon_{1})$ belonging to at least $\infty^{r_{\nu}+1}=\infty^{r_{\nu-1}}$ integral elements of $\nu+1$ dimensions is associated with \emph{at least} $r_{\nu}$ linear integral elements independent among themselves and of $(E_{\nu-1},\epsilon_{1})$, and as there are \emph{at most} $r_{\nu}$ having this property, namely
\[
\epsilon,\qquad\epsilon_{2},\qquad\dots,\qquad\epsilon_{r_{\nu}}.
\]
we see that in particular $(E_{\nu-1},\epsilon_{1})$ is associated with $\epsilon_{2}$. We see that, moreover, the element $(E_{\nu-1},\epsilon_{1})$ belongs to \emph{exactly} $\infty^{r_{\nu+1}}$ integral elements of $\nu+1$ dimensions.

Now take a $\nu+1$ dimensional integral element passing through $E_{\nu-1}$ and let it be $(E_{\nu-1},\epsilon_{1},\epsilon_{2})$. We see that, just as before, it belongs to \emph{exactly} $\infty^{r_{\nu}-2}$ integral elements of $\nu+2$ dimensions, we therefore have
\[
r_{\nu+2}=r_{\nu}-2,
\]
and so on: a $\nu-1+r_{\nu}$ dimensional element passing through $E_{\nu-1}$, which we denote by $(E_{\nu-1},\epsilon_{1},\epsilon_{2},\dots,\epsilon_{r_{\nu}})$, belongs to exactly $1=\infty^{r_{\nu}-r_{\nu}}$ integral elements of $\nu$ dimensions, and hence there passes through $E_{\nu-1}$ one and only one integral elements of $\nu+r_{\nu}$ dimensions, namely $(E_{\nu-1},\epsilon,\epsilon_{1},\dots,\epsilon_{r_{\nu}})$, and through this element there does not pass any $\nu+r_{\nu}+1$ dimensional integral element. It follows from this that all integral elements passing through $E_{\nu-1}$ are non-singular elements.

In summary, \emph{if we have}
\[
s_{\nu}=r_{\nu}-r_{\nu+1}-1=0,
\]
\emph{then the genre of the system is}
\[
n=\nu+r_{\nu}
\]
\emph{and there passes through a non-singular integral element $E_{\nu-1}$ one and only one integral element $E_{n}$. The locus of the integral elements passing through $E_{\nu-1}$ is the element $E_{n}$, and moreover we have the equalities}
\[
r_{\nu}=r_{\nu+1}+1=r_{\nu+2}+2=\dots=n-\nu,
\]
\emph{which entails}
\[
s_{\nu}=s_{\nu+1}=\dots=s_{n-1}=s_{n}=0.
\]

In particular, if $\nu$ is equal to $1$, any two linear integral elements based on a non-singular point are associated. An integral element is simply an element formed with the linear integral elements.

To end this section, we are going to determine the numbers $r$, $r_{1}$, $\dots$, $r_{n}$ for a system of $h$ total differential equations in $r$ variables, \emph{by supposing that the coefficients are not subject to any specialisation.}

First, we have, manifestly,
\[
r_{1}=r-(h+1).
\]
Suppose in a generic manner that the genre $n$ is greater than $p$ and we know $r_{p}$. If $E_{p-1}$ denote an arbitrary integral element, every linear integral element associated with $E_{p-1}$ can be formed linearly with $E_{p-1}$ and the $r_{p}+1$ other linear elements
\[
\epsilon,\qquad\epsilon_{1},\qquad\epsilon_{2},\qquad\dots,\qquad\epsilon_{r_{p}}.
\]

Let us find how many integral elements $E_{p+1}$ pass through the integral element $(E_{p-1},\epsilon)$. For this, we must adjoin to $\epsilon$ a linear element $\epsilon'$ that can be formed with
\[
\epsilon_{1},\qquad\epsilon_{2},\qquad\dots,\qquad\epsilon_{r_{p}},
\]
and which is associated to $\epsilon$. But this element $\epsilon'$ depends on $r_{p}-1$ parameters, and we need $h$ equations to express that this element is associated with $\epsilon$. We therefore have, if $r_{p}-1\ge h$,
\[
r_{p+1}=r_{p}-1-h,
\]
and if $r_{p}-1<h$, there is no $p+1$ dimensional integral element. Therefore we see that \emph{we go from a number $r$ to the following number by subtracting $h+1$}, and this we do this as many times as possible
\begin{align*}
  r_{1}&=r-(h+1),\\
  r_{2}&=r-2(h+1),\\
  &\dots
\end{align*}
and, the genre $n$ is the integer quotient of $r$ divided by $h+1$ and $r_{n}$ is equal to the remainder $k$ from this division,
\[
r_{n}=r-n(h+1)=k.
\]

\emph{The genre of a system whose coefficients are not specialised is therefore equal to the integer quotient of the number of variables by the numbers equations plus one.}

The series of numbers $s$ is in this case
\[
s=s_{1}=\dots=s_{n-1}=h,\qquad s_{n}=k.
\]

In particular, if there is only one equation, the genre is half of the number of variables: it is $n$ if there are $2n$ or $2n+1$ variables. In the first case, an integral variety $M_{n-1}$ belongs to one and only one integral variety $M_{n}$. This is a well known result.

\section{}
\label{sec:6}

We are now going to find a system of conditions \emph{determining} all integral varieties $M_{n}$ subject to these conditions, where $n$ denote the \emph{genre} of the system of equations in total differentials \eqref{eq:1}.

Let us first make the obvious remark that all the results proved until now continue to hold if we adjoin to the equations \eqref{eq:1} a certain number of \emph{algebraic} equations
\begin{equation}
  \label{eq:1'}\tag{1$'$}
  \left\{
    \begin{aligned}
      f_{1}(x_{1},x_{2},\dots,x_{r})&=0,\\
      &\dots\\
      f_{h}(x_{1},x_{2},\dots,x_{r})&=0.      
    \end{aligned}
  \right.
\end{equation}

Indeed, it suffices to adjoin to the equations \eqref{eq:1} those that are obtained by taking the total differentials of the equations \eqref{eq:1'} and in the new system consider only the points of the space that satisfy the equations \eqref{eq:1'}, which we name \emph{integral points}.

Let us find what changes the genre and the integers $r_{i}$ undergo when we thus adjoin $h$ \emph{arbitrary} algebraic equations. We obtain, in sum, a new system of equations in total differentials whose integral varieties are those of the integral varieties of the old system subject to be completely contained in the arbitrary variety $\mu$ represented by the equations \eqref{eq:1'}. It is first obvious that the number $r$ is reduced by $h$ units. In other words there are no more than $\infty^{r-h}$ points to consider. \emph{We assume that these points are not all singular} (with respect to the old system), otherwise the variety $\mu$ will be said to be \emph{non-arbitrary}.

Take now a \emph{non-singular} point $E_{0}$ of $\mu$. There passes through this point $\infty^{r_{1}}$ integral elements $E_{1}$, that is to say we can find $r_{1}+1$ independent linear elements
\[
\epsilon,\qquad\epsilon_{1},\qquad\epsilon_{2},\qquad\dots,\qquad\epsilon_{r_{1}}.
\]
On the other hand, the element $e_{r-h}$ which are the locus of the linear elements of $\mu$ also contains $r-h$ independent linear elements. If we have
\[
r_{1}+1+r-h\le r,
\]
we will suppose that $e_{r-h}$ does not contain any linear integral element, which is the general case. Then the second system is of genre zero,
\[
r'=r-h,\qquad r_{1}-h<0.
\]

If, on the contrary,
\[
r_{1}+1+r-h>r,
\]
then $e_{r-h}$ contains \emph{at least} $r_{1}+1-h$ linear integral elements. We will suppose that, which is obviously the general case, $e_{r-h}$ contains exactly $r_{1}+1-h$ linear integral elements. We then have
\[
r'=r-h,\qquad r'_{1}=r_{1}-h.
\]

We will furthermore suppose that the $\infty^{r_{1}-h}$ linear integral elements of $e_{r-h}$ \emph{are not all singular}.

Let $\epsilon$ be a non-singular linear integral element of $e_{r-h}$. Through $\epsilon$ there passes $\infty^{r_{2}}$ integral elements $E_{2}$ of the system \eqref{eq:1}, that is to say there exists $r_{2}+1$ independent linear integral elements associated with $\epsilon$, which we will call
\[
\epsilon_{1},\qquad\epsilon_{2},\qquad\dots,\qquad\epsilon_{r_{2}+1}.
\]
On the other hand, $e_{r-h}$ contains, besides $\epsilon$, $r-h-1$ linear independent elements. If we have
\[
(r_{2}+2)+(r-h-1)\le r,
\]
i.e.,
\[
r_{2}<h,
\]
then $e_{r-h}$ does not in general contain integral element $E_{2}$, which we assume. In this case, we therefore have
\[
r_{2}<h,\qquad n'=1,\qquad r'=r-h,\qquad r'_{1}=r_{1}-h.
\]
But if $r_{2}\ge h$, $e_{r-h}$ contains \emph{at least} $r_{2}+1-h$ independent linear integral elements associated to $\epsilon$. We suppose that, which is obviously the general case, that $e_{r-h}$ contains \emph{exactly} $r_{2}+1-h$ of them, that is to say through $\epsilon$ there passes $\infty^{r_{2}-h}$ integral elements contained in $e_{r-h}$. We suppose that, moreover, at least one of them is non-singular. We then have
\[
r'=r-h,\qquad r'_{1}=r_{1}-h,\qquad r'_{2}=r_{2}-h,\qquad n\ge 2.
\]

We see how we can continue this and what are the properties that we must assume the variety $\mu$ to have for it to be justified the name \emph{arbitrary}. \emph{In this case, if $r_{m}$ denote the last number $r$ larger or equal than $h$, the genre becomes equal to $m$ and we have}
\[
r'=r-h,\qquad r'_{1}=r_{1}-h,\qquad \dots,\qquad r'_{m}=r_{m}-h.
\]

It is clear that the conditions a variety must satisfy for it to fail to be arbitrary are \emph{equality} conditions. In particular, we can find on an arbitrary variety a non-singular point $E_{0}$, an integral element $E^{0}_{1}$ based at $E_{0}$, a non-singular integral element $E_{2}^{0}$ containing $E_{1}^{0}$, $\dots$, a non-singular integral element $E_{m}^{0}$ containing $E_{m-1}^{0}$, but through $E_{m}^{0}$ there does not pass any integral element $E_{m+1}$ belonging to the variety and the number of integral elements $E_{i}$ belonging to $\mu$ passing through the integral element $E_{i-1}^{0}$ must be exactly $\infty^{r_{i}-h}$.

This being established, we are going to consider a non-singular point $\mu_{0}$. Let us make an arbitrary $r-r_{1}$ dimensional variety $\mu_{r-r_{1}}$ pass through this point, an arbitrary $r-r_{2}$ dimensional variety pass through $\mu_{r-r_{1}}$ , etc., an arbitrary $r-r_{n}$ dimensional variety pass through $\mu_{r-r_{n-1}}$ \footnote{This is always possible. Indeed, consider a non-singular integral element $E_{1}^{0}$ based at $E_{0}$, a non-singular integral element $(E_{1}^{0},\epsilon_{1})$, or $E_{2}^{0}$, containing $E_{1}^{0}$, $\dots$, a non-singular integral element $(E^{0}_{n-1},\epsilon_{n-1})$ or $E^{0}_{n}$ containing $E^{0}_{n-1}$. Let us then denote by $e_{r-r_{1}}$ an element formed with $E_{1}^{0}$ and the $(r-r_{1}-1)$ other non-integral linear elements, by $e_{r-r_{2}}$ an element formed with $e_{r-r_{1}}$, $\epsilon_{1}$ and the $r_{1}-r_{2}-1$ other linear elements that are non-integral or not associated to $E_{1}^{0}$, $\dots$, by $e_{r-r_{n}}$ an element formed with $e_{r-r_{n-1}}$, $\epsilon_{n-1}$ and the $r_{n-r}-r_{n}-1$ other linear elements that are non-integral or not associated with $E_{n-1}^{0}$. It suffices to take $\mu_{r-r_{1}}$ to be a variety admitting the element $\epsilon_{r-r_{1}}$, take $\mu_{r-r_{2}}$ a variety admitting the element $e_{r-r_{2}}$, etc.}. To each of these varieties corresponds a certain system of equations in total differentials. For the variety $\mu_{r-r_{1}}$, we have $h=r_{1}$, such that
\[
n'=1,\qquad r'=r-r_{1},\qquad r'_{1}=0,
\]
for $\mu_{r-r_{2}}$, we have $h=r_{2}$ and then
\[
n''=2,\qquad r''=r-r_{2},\qquad r''_{1}=r_{1}-r_{2},\qquad r''_{2}=0,
\]
and so on.

From this it follows that the given system admits one and only one integral variety $M_{1}$ passing through $\mu_{0}$ and contained in $\mu_{r-r_{1}}$ (since the system that gives the integral varieties contained in $\mu_{r-r_{1}}$ is of genre $1$ and $r_{1}'$ is zero). Moreover this variety is not singular, since it admits (\emph{see} note) a non-singular linear element.

Similarly the integral varieties contained in $\mu_{r-r_{2}}$, being given by a system of genre $2$ with $r_{2}'=0$ and $M_{1}$ being a non-singular integral variety of the system, it follows that, according to Cauchy's theorem, there exists one and only one integral variety $M_{2}$ passing through $M_{1}$ and contained in $\mu_{r-r_{2}}$. Moreover this variety is not singular.

We can continue step by step until an integral variety $M_{n-1}$ contained in $\mu_{r-r_{n-1}}$. Then there exists one and only one integral variety $M_{n}$ contained in $\mu_{r-r_{n}}$, and this variety is not singular. Then, finally, there does not exist any integral variety $M_{n+1}$ passing through $M_{n}$.

In summary, applying Cauchy's theorem multiple times, we arrive at the following result:

\somespace

\emph{Given}
\begin{alignat*}{8}
  &\text{\emph{an arbitrary point} }&&\mu_{0},\\
  &\text{\emph{an arbitrary variety} }&&\mu_{r-r_{1}}&&\text{\emph{ passing through} }&&\mu_{0},\\
  &\text{\emph{an arbitrary variety} }&&\mu_{r-r_{2}}&&\text{\emph{ passing through} }&&\mu_{r-r_{1}},\\
  &&&\dots&&&&\dots\\
  &\text{\emph{an arbitrary variety} }&&\mu_{r-r_{n}}&&\text{\emph{ passing through} }&&\mu_{r-r_{n-1}},
\end{alignat*}
\emph{there exists one and only one integral variety $M_{n}$ passing through $\mu_{0}$,}
\begin{alignat*}{8}
  &\text{\emph{having in common with } }&&\mu_{r-r_{1}}&&\text{\emph{ a variety} }&&M_{1},\\  
  &\text{\emph{having in common with } }&&\mu_{r-r_{2}}&&\text{\emph{ a variety} }&&M_{2},\\  
  &&&\dots&&&&\dots\\
  &\text{\emph{having in common with } }&&\mu_{r-r_{n-1}}&&\text{\emph{ a variety} }&&M_{n-1},\\
  &\text{\emph{and contained entirely in } }&&\mu_{r-r_{n}}.&&
\end{alignat*}
\emph{Moreover, through this variety $M_{n}$ there does not pass any integral variety $M_{n+1}$ \footnote{The statement continue to hold if the genre is \emph{greater} than $n$, but then the last part, according to which there does not pass through $M_{n}$ any integral variety $M_{+1}$, must be removed.}.}

\somespace

The problem consisting of finding $M_{n}$ according to the conditions stated will be called the \emph{Cauchy problem}. The \emph{general integral} will be the set of the integral varieties $M_{n}$ that can be obtained by the preceding procedure.

We will now try to formulate the Cauchy problem in an \emph{analytic way}, or rather, by conforming to the preceding statement of the problem, we are going to determine the general integral $M_{n}$ \emph{by a set of analytic conditions which makes its degree of indeterminacy evident}. For this, we start from a non-singular point $E_{0}$ and we denote by $\epsilon_{1}$ a non-singular integral element based on this point, by $(\epsilon_{1},\epsilon_{2})$ a non-singular integral element $E_{2}$ passing through $\epsilon_{1}$, $\dots$, by $(E_{n-1},\epsilon_{n})$ a non-singular integral element $E_{n}$ passing through $E_{n-1}$, such that
\[
\epsilon_{1},\qquad\epsilon_{2},\qquad\dots,\qquad\epsilon_{n}
\]
are $n$ independent linear integral elements that are associated among themselves.

The element $E_{n}$ can be defined by a system $(\Sigma)$ of $r-n$ independent linear equations in $dx_{1}$, $dx_{2}$, $\dots$, $dx_{r}$. We assume that the indices are chosen in a manner that these equations are solvable with respect to $dx_{n+1}$, $\dots$, $dx_{r}$. The element $E_{n-1}$ will be in turn defined by the system $(\Sigma)$ adjoined with a linear equation in $dx_{1}$, $dx_{2}$, $\dots$, $dx_{n}$. Let us suppose that it is solvable with respect to $dx_{n}$. We write it as
\begin{equation}
  \label{eq:En1}\tag{$E_{n-1}$}
  dx_{n}=\alpha_{n,1}dx_{1}+\dots+\alpha_{n,n-2}dx_{n-2}+\alpha_{n,n-1}dx_{n-1}.
\end{equation}
Similarly, we have $E_{n-2}$ by adjoining to the preceding equations an equation linear in $dx_{1}$, $\dots$, $dx_{n-1}$ solvable, for example, with respect to $dx_{n-1}$. We write it as
\begin{equation}
  \label{eq:En2}\tag{$E_{n-2}$}
  dx_{n-1}=\alpha_{n-1,1}dx_{1}+\dots+\alpha_{n-1,n-2}dx_{n-2},
\end{equation}
and so on, until we arrive at the element $E_{1}$ that we obtain by adjoining to the equations defining $E_{2}$ a linear equation in $dx_{2}$, $dx_{1}$, solvable, for example, with respect to $dx_{2}$. We write it as
\begin{equation}
  \label{eq:E1}\tag{$E_{1}$}
  dx_{2}=\alpha_{2,1}dx_{1}.
\end{equation}

Let us now denote by $(P_{0})$ the flat variety that is the locus of the linear integral elements passing by the point $E_{0}$. It obviously contains $E_{n}$ and it is $(r_{1}+1)$ dimensional. It is therefore defined by $r-r_{1}-1=s$ linear equations solvable with respect to $s$ of the differentials $dx_{n+1}$, $\dots$, $dx_{r}$. We denote these $s$ differentials by
\[
dz_{1},\qquad dz_{2},\qquad \dots,\qquad dz_{s}.
\]
Note that these $s$ equations are non other than the given equations \eqref{eq:1} themselves. Let us denote by $(P_{1})$ the flat variety that is the locus of linear elements associated to $E_{1}$. It is evidently contained in $(P_{0})$ and it contains $E_{n}$. Moreover it is $r_{2}+2$ dimensional. It is therefore defined by $r-r_{2}-2=s+s_{1}$ equations among we find the $s$ equations of $(P_{0})$. We therefore obtain them by adjoining to these $s$ equations $s_{1}$ other that are solvable to $s_{1}$ of the differentials other than $dz_{1}$, $\dots$, $dz_{s}$; $dx_{1}$,$\dots$, $dx_{n}$. By changing our notation, let us write these differentials as
\[
dz_{1}^{(1)},\qquad dz_{2}^{(1)},\qquad \dots,\qquad dz_{s_{1}}^{(1)}.
\]
Similarly the flat variety $(P_{2})$ which is the locus of the linear integral elements associated with $E_{2}$ is obtained by adjoining to the $s+s_{1}$ equations of $(P_{1})$ $s_{2}$ other equations solvable with respect to
\[
dz_{1}^{(2)},\qquad dz_{2}^{(2)},\qquad \dots,\qquad dz_{s_{2}}^{(2)},
\]
the $z^{(2)}$ being $s_{2}$ variables other than $x_{1}$, $\dots$, $x_{n}$, $z$ and $z^{(1)}$. And so on. The flat variety $(P_{n-1})$ which is the locus of linear integral elements associated with $E_{n-1}$ introduces $s_{n-1}$ variables
\[
z_{1}^{(n-1)},\qquad\dots,\qquad z_{s_{n-1}}^{(n-1)},
\]
and finally, the element $E_{n}$ will be defined by adjoining to the equations defining $(P_{n-1})$ $r-s-s_{1}-\dots-s_{n-1}=r_{n}=s_{n}$ new equations solvable with respect to $s_{n}$ variables other than $x_{1}$, $\dots$, $x_{n}$, $z$, $z^{(1)}$, $\dots$, $z^{(n-1)}$ which we denote by
\[
z_{1}^{(n)},\qquad z_{2}^{(n)},\qquad \dots,\qquad z_{s_{n}}^{(n)}.
\]

We can summarise the equations defining $(P_{0})$, $(P_{1})$, $\dots$, $(P_{n-1})$, $E_{n}$, $E_{n-1}$, $\dots$, $E_{1}$ in the following table:
{\scriptsize
  \[
  (E_{1})
  \left\{
    \begin{gathered}  
      (E_{n-2})
      \left\{
        \begin{gathered}  
          (E_{n-1})
          \left\{
            \begin{gathered}  
              (E_{n})
              \left\{
                \begin{gathered}  
                  (P_{n-1})
                  \left\{
                    \begin{gathered}
                      (P_{1})
                      \left\{
                        \begin{gathered}
                          (P_{0})\\
                          \,
                        \end{gathered}
                      \right.\\
                      \,\\
                      \,
                    \end{gathered}
                  \right.\\
                  \,
                \end{gathered}
              \right.\\
              \,
            \end{gathered}
          \right.\\
          \,
        \end{gathered}
      \right.\\
      \,\\
      \,
    \end{gathered}
  \right.
  \begin{alignedat}{4}
    &dz&&=[dz^{(1)},dz^{(2)},\dots,dz^{(n)},dx],\\
    &dz^{(1)}&&=[dz^{(2)},\dots,dz^{(n)},dx],\\
    &&&\dots\\
    &dz^{(n-1)}&&=[dz^{(n)},dx],\\
    &dz^{(n)}&&=[dx],\\
    &dx_{n}&&=\alpha_{n,1}dx_{1}+\alpha_{n,2}dx_{2}+\dots+\alpha_{n,n-1}dx_{n-1},\\
    &dx_{n-1}&&=\alpha_{n-1,1}dx_{1}+\alpha_{n,2}dx_{2}+\dots+\alpha_{n-1,n-2}dx_{n-2},\\
    &&&\dots\\
    &dx_{2}&&=\alpha_{2,1}dx_{1}.
  \end{alignedat}
  \]
}

The first line expresses that each of the differentials $dz_{1}$, $dz_{2}$, $\dots$, $dz_{s}$ is expressed in linear combinations of the differentials $dz_{1}^{(1)}$, $\dots$, $dx_{n}$.

With these conventions, we will make the following coordinate transformation. Without changing the variables $z$, $z^{(1)}$, $\dots$, $z^{(n)}$, we take, as new variables,
\begin{align*}
  x'_{1}&=x_{1},\\
  x'_{2}&=x_{2}-\alpha_{21}x_{1},\\
  x'_{3}&=x_{3}-\alpha_{31}x_{1}-\alpha_{32}x_{2},\\
  &\dots\\
  x'_{n}&=x_{n}-\alpha_{n1}x_{1}-\alpha_{n2}x_{2}-\dots-\alpha_{n,n-1}x_{n-1}.
\end{align*}
\emph{In other words we assume the coefficients $\alpha_{ij}$ to be all zero.}

We denote by (after this coordinate transformation has been applied)
\[
a_{1},\quad\dots,\quad a_{n};\quad c_{1},\quad\dots,\quad c_{s};\quad c_{1}^{(1)},\quad \dots,\quad c_{s_{1}}^{(1)},\quad \dots,\quad c_{1}^{(n)},\quad \dots,\quad c_{s_{n}}^{(n)}
\]
the coordinates of the point $E_{0}$.

Finally note that every integral variety $M_{n}$ admitting the element $E_{n}$ can be defined by $r-n$ equations solvable respect to $z$, $z^{(1)}$, $\dots$, $z^{(n)}$ (according to the form of equations of $E_{n}$ itself). This is also true for all the integral varieties $M_{n}$ admitting an element sufficient close to $E_{n}$. We can therefore take $x_{1}$, $x_{2}$, $\dots$, $x_{n}$ as independent variables for these varieties.

This granted, to be sure that we obtain \emph{arbitrary} varieties $\mu_{r-r_{1}}$, $\mu_{r-r_{2}}$, $\dots$, let us find an element $e_{r-r_{1}}$ admitting only a single linear integral element $E_{1}$ and passing through $E_{0}$, that is to say \emph{cutting the element $(P_{0})$ following $E_{1}$}, an element $e_{r-r_{2}}$ admitting only a single two dimensional element containing $E_{1}$ which we call $E_{2}$, and passing through $e_{r-r_{1}}$, that is to say \emph{cutting the element $(P_{1})$ following $E_{2}$}, etc., an element $e_{r-r_{n}}$ admitting only one integral element containing $E_{n-1}$ which we call $E_{n}$ and passing through $e_{r-r_{n-1}}$, that is to say \emph{cutting the element $(P_{n-1})$ following $E_{n}$}. Every variety $\mu_{r-r_{i}}$ admitting the element $e_{r-r_{i}}$ \emph{or a sufficiently close element} will obviously satisfy the conditions imposed on \emph{arbitrary} varieties. We just need to find the elements $e_{r-r_{n}}$, $e_{r-r_{n-1}}$, $\dots$, $e_{r-r_{1}}$ enjoying these properties stated just now. It suffices to take $e_{r-r_{n}}$ to be the system
\[
dz^{(n)}=[dx],
\] 
$e_{r-r_{n-1}}$ to be the system obtained by adjoining to the preceding equations the following
\begin{alignat*}{3}
  &dz^{(n-1)}&&=[dz^{(n)},dx],\\
  &dx_{n}&&=0,
\end{alignat*}
$e_{r-r_{n-2}}$ the system obtained by adjoining to the preceding the equation
\begin{alignat*}{3}
  &dz^{(n-2)}&&=[dz^{n-1},dz^{(n)},dx],\\
  &dx_{n-1}&&=0,
\end{alignat*}
and so on. The square brackets on the right hand sides denote the same linear combinations as in the equations defining $(P_{0})$, $(P_{1})$, $\dots$, $(P_{n-1})$, $E_{n}$.

After this, we are justified to define $\mu_{r-r_{n}}$ by the equations
\begin{equation}
  \label{eq:An}\tag{$A_{n}$}
  \left\{
    \begin{aligned}
      z_{1}^{(n)}&=\phi_{1}^{(n)}(x_{1},x_{2},\dots,x_{n}),\\
      &\dots\\
      z_{s_{n}}^{(n)}&=\phi_{s_{n}}^{(n)}(x_{1},x_{2},\dots,x_{n}),      
    \end{aligned}
  \right.
\end{equation}
to define $\mu_{r-r_{n-1}}$ by the preceding equations and the following
\begin{gather}
  \label{eq:An1}\tag{$A_{n-1}$}
  \left\{
    \begin{aligned}
      z_{1}^{(n-1)}&=\phi_{1}^{(n-1)}(x_{1},x_{2},\dots,x_{n-1}),\\
      &\dots\\
      z_{s_{n-1}}^{(n-1)}&=\phi_{s_{n-1}}^{(n-1)}(x_{1},x_{2},\dots,x_{n-1}),      
    \end{aligned}
  \right.\\
  \label{eq:Bn}\tag{$B_{n}$}
  x_{n}=a_{n},
\end{gather}
and so on, and define $\mu_{r-r_{1}}$ by the equations already written and
\begin{gather}
  \label{eq:A1}\tag{$A_{1}$}
  \left\{
    \begin{aligned}
      z_{1}^{(1)}&=\phi_{1}^{(1)}(x_{1}),\\
      &\dots\\
      z_{s_{1}}^{(1)}&=\phi_{s_{1}}^{(1)}(x_{1}),      
    \end{aligned}
  \right.\\
  \label{eq:B2}\tag{$B_{2}$}
  x_{2}=a_{2},
\end{gather}
and finally the point $\mu$ by all the equations already written and 
\begin{gather}
  \label{eq:A0}\tag{$A_{0}$}
  \left\{
    \begin{aligned}
      z_{1}&=\phi_{1},\\
      z_{2}&=\phi_{2},\\
      &\dots\\
      z_{s}&=\phi_{s},      
    \end{aligned}
  \right.\phantom{\}}\\
  \label{eq:B1}\tag{$B_{1}$}
  x_{1}=a_{1}.
\end{gather}

In these formulae, \emph{the quantities $\phi_{1}$, $\phi_{2}$, $\dots$, $\phi_{s}$ are arbitrary constants sufficiently close to $c_{1}$, $c_{2}$, $\dots$, $c_{s}$. As for the functions $\phi^{(1)}$, $\phi^{(2)}$, $\dots$, $\phi^{(n)}$, they are arbitrary holomorphic functions in a neighbourhood of}
\[
x_{1}=a_{1},\qquad x_{2}=a_{2},\qquad \dots,\qquad x_{n}=a_{n}
\]
\emph{such that for this system of values the functions and their first order partial derivatives take sufficiently close values of certain fixed values.}

With these hypotheses there exists one and only one integral variety $M_{n}$ passing through $\mu_{0}$  and having in common with $\mu_{r-r_{1}}$ a one dimensional variety, with $\mu_{r-r_{2}}$ a two dimensional variety, etc., with $\mu_{r-r_{n-1}}$ a $n-1$ dimensional variety, and finally contained entirely in $\mu_{r-r_{n}}$. This variety is on the other hand defined by
\[
r-n=s_{n}+s_{n-1}+\dots+s
\]
functions $z^{(n)}$, $z^{(n-1)}$, $\dots$, $z$ of the independent variables $x_{1}$, $x_{2}$, $\dots$, $x_{n}$. To say that $M_{n}$ is contained in $\mu_{r-r_{n}}$ is to say that the first $s_{n}$ functions $z_{1}^{(n)}$, $\dots$, $z_{s_{n}}^{(n)}$ are equal to the given functions $\phi_{1}^{(n)}$, $\dots$, $\phi_{s_{n}}^{(n)}$. If, on the other hand, $M_{n}$ has in common with $\mu_{r-r_{n-1}}$ a $n-1$ dimensional variety, this variety can only be obtained by making $x_{n}=a_{n}$ in the expressions of the functions $z$, $z^{(1)}$, $\dots$. It is therefore necessary that for $x_{n}=a_{n}$, the $s_{n-1}$ functions $z_{1}^{(n-1)}$, $\dots$, $z_{s_{n-1}}^{(n-1)}$ reduce to given functions $\phi_{1}^{(n-1)}$, $\dots$, $\phi_{s_{n-1}}^{(n-1)}$. And so on.

It follows from this that \emph{under the conditions indicated, the system \eqref{eq:1}, considered as defining $z_{1}$, $\dots$, $z_{s_{n}}^{(n)}$ as functions of $x_{1}$, $\dots$, $x_{n}$, admits one and only one solution for which the unknown functions are holomorphic in a neighbourhood of $x_{1}=a_{1}$, $\dots$, $x_{n}=a_{n}$ such that the $s_{n}$ functions $z^{(n)}$ are identical to various functions:}
\begin{alignat*}{6}
  z^{(n)}_{1}&\text{ \emph{to the arbitrary function} }&&\phi_{1}^{(n)}(x_{1},\dots, x_{n}),\\
  \dots&&&\dots\\
  z^{(n)}_{s_{n}}&\text{ \emph{to the arbitrary function} }&&\phi_{s_{n}}^{(n)}(x_{1},\dots, x_{n}),
\intertext{\emph{the $s_{n-1}$ functions $z^{(n-1)}$ reduce on $x_{n}=a_{n}$ to}}
  z_{1}^{(n-1)}&\text{ \emph{to the arbitrary function} }&&\phi_{1}^{(n-1)}(x_{1},\dots,x_{n-1}),\\
  \dots&&&\dots\\
  z_{s_{n-1}}^{(n-1)}&\text{ \emph{to the arbitrary function} }&&\phi_{s_{n-1}}^{(n-1)}(x_{1},\dots,x_{n-1}),
\intertext{\emph{and so on. The $s_{1}$ functions $z^{(1)}$ reduce on $x_{2}=a_{2}$, $\dots$, $x_{n}=a_{n}$}}
  z_{1}^{(1)}&\text{ \emph{to the arbitrary function} }&&\phi_{1}^{(1)}(x_{1}),\\
  \dots&&&\dots\\
  z_{s_{1}}^{(1)}&\text{ \emph{to the arbitrary function} }&&\phi_{s_{1}}^{(1)}(x_{1}),
\intertext{\emph{and finally the $s$ functions $z$ reduce for $x_{1}=a_{1}$, $\dots$, $x_{n}=a_{n}$}}
  z_{1}&\text{ \emph{to the arbitrary constant} }&&\phi_{1},\\
  \dots&&&\dots\\
  z_{s}&\text{ \emph{to the arbitrary constant} }&&\phi_{s}.
\end{alignat*}

It is clear, on the other hand, that \emph{every integral variety $M_{n}$ admitting an element near the previously defined particular element $E_{n}$, or $(\epsilon_{1},\dots,\epsilon_{n})$, can be obtained by the preceding procedure, the functions and the constants $\phi$ being well-determined in a unique manner.}

We can therefore say that \emph{every integral variety $M_{n}$ admitting a $n$ dimensional integral element sufficiently close to a given non-singular integral element is completely defined by the set of}
\begin{alignat*}{10}
  &s_{n}&&\text{ \emph{arbitrary functions of} }&&n&&\text{ \emph{arguments} }&&x_{1},x_{2},\dots,x_{n},\\
  &s_{n-1}&&\text{ \emph{arbitrary functions of} }&&n-1&&\text{ \emph{arguments} }&&x_{1},x_{2},\dots,x_{n-1},\\
  &\dots&&&&\dots&&&&\dots\\
  &s_{1}&&\text{ \emph{arbitrary functions of} }&&1&&\text{ \emph{argument} }&&x_{1},\\
  &s&&\text{ \emph{arbitrary constants} },
\end{alignat*}
\emph{with the condition that for certain given values of the independent variables, the arbitrary elements and their first order derivatives take values sufficiently close to certain fixed constants.}

It is in this sense that we say an integral variety $M_{n}$ depends on $s$ arbitrary constants, $s_{1}$ arbitrary functions of one argument, etc., $s_{n}$ arbitrary functions of $n$ arguments.

We can say that \emph{the numbers in the series}
\begin{equation}
  \label{eq:S}\tag{S}
  s,\quad s_{1},\quad s_{2},\quad \dots,\quad s_{n}
\end{equation}
\emph{measure the indeterminacy of the integral variety $M_{n}$}. The geometric origin of these numbers shows that \emph{the measure of indeterminacy does not change if we apply any change of variables}, since this amounts to simply apply a homographic transformation on the integral elements based on a point, which obviously does not change the values of the numbers $r$ and hence the numbers $s$.

Let us recall the property of the series \eqref{eq:S} expressed by the inequalities
\[
s\ge s_{1}\ge s_{2}\ge \dots \ge s_{n-1}\ge s_{n},
\]
and also the values of $r$ in terms of $s$:
\begin{alignat*}{4}
  &r_{n}&&=s_{n},\\
  &r_{n-1}&&=s_{n}+s_{n-1}+1,\\
  &r_{n-2}&&=s_{n}+s_{n-1}+s_{n-2}+2,\\
  &&&\dots\\
  &r_{1}&&=s_{n}+s_{n-1}+\dots+s_{1}+n-1,\\
  &r&&=s_{n}+s_{n-1}+\dots+s+n,
\end{alignat*}

As a particular case, if we take a system of $h$ equations in total differentials in $r$ variables with generic coefficients, we have seen that the genre $n$ is equal to the integer quotient of $r$ by $h+1$, and by denoting the remainder by $k$, we have
\[
s=s_{1}=\dots=s_{n-1}=h,\qquad s_{n}=k.
\]

We therefore have the following theorem:

\somespace

\emph{The general integral $M_{n}$ of a system of $h$ equations in total differentials whose coefficients are arbitrary functions where $n$ denote the integer quotient of $r$ by $h+1$ and $k$ the remainder depends on}
\begin{alignat*}{10}
  &k&&\text{ \emph{arbitrary functions of} }&&n&&\text{ \emph{arguments} },\\
  &h&&\text{ \emph{arbitrary functions of} }&&n-1&&\text{ \emph{arguments} },\\
  &h&&\text{ \emph{arbitrary functions of} }&&n-2&&\text{ \emph{arguments} },\\
  &\dots&&&&\dots\\
  &h&&\text{ \emph{arbitrary functions of} }&&1&&\text{ \emph{arguments} },
\end{alignat*}
\emph{and on $h$ arbitrary constants.}

\somespace

This is the result found by Biermann with much more precision. \emph{We can add that there are in general no $n+1$ dimensional integral.}

If $h$ is equal to $1$ and $r$ is even, which is consequently equal to $2n$, there is no arbitrary function of $n$ arguments. If $r$ is odd, and hence equal to $2n+1$, there is one arbitrary function of $n$ arguments.

Let us return to the general case. The results stated continue to hold, \emph{even if the genre is greater than $n$}, if we take $r_{n}$ to the be value of $s_{n}$ and $r_{i}-r_{i+1}-1$ to be the values of the other $s_{i}$. \emph{It suffices that the given system, considered as in $n$ independent variables, to be in involution.} But if the genre is greater than $n$, $s_{n}$ may be \emph{greater} than $s_{n-1}$.

The preceding results are simple if $s_{n}$ is zero. Then the general integral depends only on arbitrary functions of at most $n-1$ arguments.

The analytic search for the integral $M_{n}$ amounts to the integration of $n$ successive Kowalewski systems. The first gives the $s$ functions of $x_{1}$ which $z_{1}$, $z_{2}$, $\dots$, $z_{s}$ reduce to when we set
\[
x_{2}=a_{2}, \qquad \dots,\qquad x_{n}=a_{n},
\]
this is a system of ordinary differential equations that we obtain by replacing in the given system of equations $z^{(1)}$ by $\phi^{(1)}(x_{1})$, $z^{(2)}$ by $\phi^{(2)}(x_{1},a_{2})$, $\dots$, $z^{(n)}$ by $\phi^{(n)}(x_{1},a_{2},\dots,a_{n})$.

The second Kowalewski system gives the $s+s_{1}$ functions of $x_{1}$, $x_{2}$ which $z_{1}$, $\dots$, $z_{s}$, $z_{1}^{(1)}$, $\dots$, $z_{s_{1}}^{(1)}$ reduce to when we set
\[
x_{3}=a_{3},\qquad \dots,\qquad x_{n}=a_{n},
\]
these functions reduce to the known functions of $x_{1}$ on $x_{2}=a_{2}$. And so on. The last system gives the $s+s_{1}+\dots+s_{n-1}$ functions of $x_{1}$, $x_{2}$, $\dots$, $x_{n-1}$ which $z_{1}$, $\dots$, $z_{s_{n-1}}^{(n-1)}$ reduce to when we set
\[
x_{n}=a_{n},
\]
these functions reduce to known functions of $x_{1}$, $\dots$, $x_{n-2}$ when we set $x_{n-1}=a_{n-1}$.

To clarify all the preceding results by a very simple example, take the system formed by the single equation
\begin{equation}
  \label{eq:1.1}
  dz-p\,dx-q\,dy=0,
\end{equation}
where $x$, $y$, $z$, $p$, $q$ are five variables. Here there is one equation expressing that two linear integral elements are associated, which is
\begin{equation}
  \label{eq:1.2}
  dx\,\delta p-dp\,\delta x+dy\,\delta q-dq\,\delta y=0.
\end{equation}
Here $r=5$ and $r_{1}=3$. As for $r_{2}$, the equations defining the linear integral elements associated to a given linear element $(\delta x, \delta y, p\,\delta x+q\,\delta y,\delta p,\delta q)$ contain two independent ones, namely
\begin{gather*}
  dz-p\,dx-q\,dy=0,\\
  \delta p\,dx+\delta q\,dy-\delta x\,dp-\delta y\,dq=0,
\end{gather*}
then $r_{2}=1$. We therefore have
\[
s=1,\qquad s_{1}=1,\qquad s_{2}=1.
\]

A non-singular point $E_{0}$ is for example
\[
x=y=z=p=q=0.
\]
An integral element $E_{2}$ passing through this point is for example
\begin{equation}
  \label{eq:1.E2}\tag{$E_{2}$}
  dz=dp=dq=0,
\end{equation}
and a non-singular integral element $E_{1}$ contained in $E_{2}$ is for example
\begin{equation}
  \label{eq:1.E1}\tag{$E_{1}$}
  dz=dp=dq=dy=0.
\end{equation}

Here the element $(P_{0})$ is given by \eqref{eq:1.1} where we set $p=q=0$,
\begin{equation}
  \label{eq:1.P0}\tag{$P_{0}$}
  dz=0,
\end{equation}
the element $(P_{1})$ is given, according to \eqref{eq:1.2}, by
\begin{equation}
  \label{eq:1.P1}\tag{$P_{1}$}
  dz=dp=0.
\end{equation}

Therefore there exists one and only one integral formed by three functions $z$, $p$, $q$ in $x$ and $y$, holomorphic in a neighbourhood of $x=y=0$ such that
\begin{alignat*}{5}
  &q&&\text{ is identical to }&&f(x,y),\\
  &p&&\text{ reduces to }&&\phi(x)&&\text{ for }y=0,\\
  &z&&\text{ reduces to }&&c&&\text{ for }x=y=0,
\end{alignat*}
where $c$ is a rather small constant, $f$ and $\phi$ are arbitrary functions holomorphic in a neighbourhood of $x=0$, $y=0$ and together with their first order derivatives taking on $x=y=0$ rather small values.

Here there are two Kowalewski systems. The first gives the function $z$ of $x$ which reduces to $c$ on $x=0$, when $p=\phi(x)$ and $q=f(x,0)$. It is obviously given by
\[
\frac{dz}{dx}=p=\phi(x),
\]
from which
\[
z=c+\int_{0}^{r}\phi(x)dx.
\]

The second Kowalewski system gives the functions $p$ and $z$ in $x$ and $y$ which reduce to respectively $\phi(x)$ and $c+\int_{0}^{x}\phi(x)dx$ on $y=0$ when we set $q=f(x,y)$. This system is [\emph{see} the formulae \eqref{eq:II} of section IV]
\begin{align*}
  \frac{\pd z}{\pd y}-f(x,y)&=0,\\
  \frac{\pd p}{\pd y}-\frac{\pd f}{\pd x}&=0,
\end{align*}
and gives
\begin{align*}
  z&=c+\int_{0}^{x}\phi(x)dx+\int_{0}^{y}f(x,y)dy,\\
  p&=\phi(x)+\int_{0}^{y}\frac{\pd f}{\pd x}dy,\\
  q&=f(x,y).
\end{align*}

We will finish this section by giving some definitions. In the series
\[
s,\quad s_{1},\quad \dots,\quad s_{n}
\]
that measures the indeterminacy of the general integral $M_{n}$ of the system \eqref{eq:1} of genre $n$, the first number $s$ is none other than the number of independent equations in $dx_{1}$, $\dots$, $dx_{r}$ of the system \eqref{eq:1}, that is to say, using the notations of \textsection I, it is the degree of the principal minor of the matrix
\begin{equation}
  \label{eq:Delta}\tag{$\Delta$}
  \begin{Vmatrix}
    a_{1}&a_{2}&\dots&a_{r}\\
    b_{1}&b_{2}&\dots&b_{r}\\
    \hdotsfor{4}
  \end{Vmatrix}.
\end{equation}

We give the number $s_{1}$ a particular name: we call it the \emph{character} \footnote{This designation is due to, I think, H.~\textsc{von Webber}, \emph{Zur Invariantentheorie der Systeme Pfaff'scher Gleichungen} (\emph{Peipz.~Ber.}, p.~207--229; 1898).} of the system. Observe that $s+s_{1}$ is none other than the number of independent equations expressing that a linear element $(dx_{1},\dots,dx_{r})$ is integral and associated to an arbitrary linear integral $(\delta x_{1},\dots, \delta x_{r})$. We set
\[
a_{ik}=\frac{\pd a}{\pd x_{k}}-\frac{\pd a_{k}}{\pd x_{i}},\qquad\dots,\qquad l_{ik}=\frac{\pd l_{i}}{\pd x_{k}}-\frac{\pd l_{k}}{\pd x_{i}},
\]
theses equations are
\begin{align*}
  \label{2.1}\tag{1}
  &\left\{
    \begin{alignedat}{30}
      &a_{1}dx_{1}&{}+{}&a_{2}dx_{2}&{}+{}&\cdots&{}+{}&a_{r}&dx_{r}&{}={}&0,\\
      &&&&&&&&&\cdots\\
      &l_{1}dx_{1}&{}+{}&l_{2}dx_{2}&{}+{}&\cdots&{}+{}&l_{r}&dx_{r}&{}={}&0,      
    \end{alignedat}
  \right.\\
  \label{2.2}\tag{2}
  &\left\{
    \begin{alignedat}{20}
      &\sum_{i}a_{1i}\delta x_{i}dx_{1}&&{}+{}\dots&&{}+{}\sum_{i}a_{ri}\delta x_{i}dx_{r}&&{}={}0,\\
      &&&&&&&\cdots\\
      &\sum_{i}l_{1i}\delta x_{i}dx_{1}&&{}+{}\dots&&{}+{}\sum_{i}l_{ri}\delta x_{i}dx_{r}&&{}={}0,\\      
    \end{alignedat}
  \right.
\end{align*}

Therefore if we consider the matrix
\begin{equation}
  \label{eq:Delta1}\tag{$\Delta_{1}$}
  \begin{Vmatrix}
    a_{1}&a_{2}&\dots&a_{r}\\
    \hdotsfor{4}\\
    l_{1}&l_{2}&\dots&l_{r}\\
    \sum a_{1i}\delta x_{i}&\sum a_{2i}\delta x_{i}&\dots&\sum a_{ri}\delta x_{i}\\
    \hdotsfor{4}\\
    \sum l_{1i}\delta x_{i}&\sum l_{2i}\delta x_{i}&\dots&\sum l_{ri}\delta x_{i}
  \end{Vmatrix}
\end{equation}
where $\delta x_{1}$, $\dots$, $\delta x_{r}$ are arbitrary elements subject to the equations
\begin{alignat*}{6}
  &a_{1}\delta x_{1}&&{}+{}\dots&&{}+{}a_{r}\delta x_{r}&&=0,\\
  &&&&&&&\dots\\
  &l_{1}\delta x_{1}&&{}+{}\dots&&{}+{}l_{r}\delta x_{r}&&=0,
\end{alignat*}
\emph{the character $s_{1}$ of the system is the difference between the degree of the principal minor of the matrix \eqref{eq:Delta1} and the degree of the principal minor of the matrix \eqref{eq:Delta}.}

We can give the other numbers $s_{2}$, $s_{3}$, $\dots$, the names of second, third, $\dots$ \emph{characters} of the system \eqref{eq:1}. The are calculated by the degrees of principal minors just as $s$ and $s_{1}$ are. But \emph{instead of saying that a system of genre $n$ has its $n$-th character $s_{n}$, we say that the system is of the $(s_{n}+1)$-th kind.} A system of the first kind is therefore a system for which $s_{n}=0$, and it enjoys the property that through an integral variety $M_{n-1}$ there passes one \emph{and only one} integral variety $M_{n}$.

\section{}
\label{sec:7}

In this paragraph we are going to be concerned with systems of the first kind for which the $(n-1)$-th character $s_{n-1}$ is zero. Suppose in a general manner that $s_{\nu}$ is the first number that is zero in the series
\[
s_{1},\quad s_{2},\quad \dots,\quad s_{n},
\]
$\nu$ being smaller than $n$. In \textsection V we have seen some properties of these systems, which we now recall:

\somespace

\emph{Through a non-singular intergal element $E_{\nu-1}$ there passes one and only one integral element $E_{n}$. This element $E_{n}$ is the locus of the integral elements passing through $E_{\nu-1}$, and none of these elements are singular.}

\somespace

We have furthermore
\[
r_{n}=0,\quad r_{n-1}=1,\quad r_{n-2}=2,\quad\dots,\quad r_{\nu}=n-\nu,\quad r_{\nu-1}\le n-\nu-2.
\]

As a corollary to the property of integral elements passing through a non-singular integral element $E_{\nu-1}$, we are going to prove the following theorem:

\somespace

\emph{Through a non-singular integral variety $M_{\nu-1}$ there passes one and only one integral variety $M_{n}$.}

\somespace

For the proof, let us make an arbitrary variety $\mu_{r-r_{\nu}}$ pass through $M_{\nu-1}$, which is always possible, and we can ensure that the integral variety $M_{\nu-1}$ is not singular. If, in particular, $E_{\nu-1}$ is a non-singular integral element of $M_{\nu-1}$, the variety $\mu_{r-r_{\nu}}$ will admit one and only one integral element $E_{\nu}$ passing through $E_{\nu-1}$. Granted this, let $M_{n}$ be any integral variety passing through $M_{\nu-1}$. It naturally admits the \emph{unique} integral element $E_{n}$ passing through $E_{\nu-1}$. On the other hand, the sum of the dimensions of $M_{n}$ and $\mu_{r-r_{\nu}}$ is
\[
r+n-r_{\nu}=r+\nu,
\]
then these two varieties have in common an variety of dimension \emph{at least} $\nu$, and this variety is necessarily integral. But $\mu_{r-r_{\nu}}$ does not contain $\nu+1$ dimensional integral elements passing through $E_{\nu-1}$, and hence this integral variety common to $M_{n}$ and $\mu_{r-r_{\nu}}$ is of \emph{exactly} $\nu$ dimensions. Let us denote it by $M_{\nu}$.

Granted this, we know that through a non-singular integral variety $M_{\nu-1}$ there passes one and \emph{only one} $\nu$ dimensional integral variety contained in the arbitrary variety $\mu_{r-r_{\nu}}$: \emph{therefore the variety $M_{\nu}$ is determined in a unique manner when we specify $\mu_{r-r_{\nu}}$.} In other words, \emph{if through $M_{\nu-1}$ there passes two $n$ dimensional integral varieties $M_{n}$ and $M_{n}'$, these two varieties cut $\mu_{r-r_{\nu}}$ following the same variety $M_{\nu}$ regardless of the particular $\mu_{r-r_{\nu}}$ passing through $M_{\nu-1}$.}

From this it follows that the two varieties $M_{n}$ and $M_{n}'$ are identical. Since if $A$ is any point on the first variety, we can always make a variety $\mu_{r-r_{\nu}}$ pass through $A$ and $M_{\nu-1}$. To this variety corresponds an integral variety $M_{\nu}$ situated inside $M_{n}$ and passing through $A$, but it is also situated inside $M'_{n}$, and therefore the point $A$ belongs to $M'_{n}$ and the two varieties are coincidental.

In a more precise and rigorous manner, let us make an arbitrary variety $\mu_{r-r_{\nu}-1}$ pass through $M_{\nu-1}$, that is to say $\mu_{r-r_{\nu}-1}$ does not admit integral elements passing through $E_{\nu-1}$ other than $E_{\nu-1}$ itself, which can always be arranged. Let us then make a family of varieties $\mu_{r-r_{\nu}}$ depending on $r_{\nu}=n-\nu$ parameters and \emph{filling all of the space} pass through this determined variety $\mu_{r-r_{\nu}-1}$ \footnote{If
\[
f_{1}=f_{2}=\dots=f_{r_{\nu}+1}=0
\]
are the equations of $\mu_{r-r_{\nu}-1}$, it obviously suffices to take
\[
f_{1}-t_{1}f_{r_{\nu}+1}=f_{2}-t_{2}f_{r_{\nu}+1}=\dots=f_{r_{\nu}}-t_{r_{\nu}}f_{r_{\nu}+1}=0.
\]
}.
These varieties are all \emph{arbitrary}, since they obviously contain only one integral element $E_{\nu}$ passing through $E_{\nu-1}$, and we know that every integral element passing through $E_{\nu-1}$ is non-singular. Each of them therefore contains one and only one integral variety $M_{\nu}$ passing through $M_{\nu-1}$ and all the varieties $M_{\nu}$ belong to some integral variety $M_{n}$ passing through $M_{\nu-1}$. We can add that $M_{n}$ \emph{is the locus of these varieties $M_{\nu}$ when the $n-\nu$ parameters they depend on vary}, since each of them is contained in $M_{n}$ and, on the other hand, through any point of $M_{n}$ there passes one of the varieties $\mu_{r-r_{\nu}}$ (which fills up the space) and hence, the corresponding variety $M_{\nu}$. Hence $M_{n}$ is determined in a unique manner.

We summarise the results that we just obtained in the following manner:

\somespace

\emph{Through a non-singular integral variety $M_{\nu-1}$ there passes one and only one integral variety $M_{n}$. To obtain it we make an arbitrary variety $\mu_{r-r_{\nu}-1}$ pass through $M_{\nu-1}$ and through this latter variety a family of varieties $\mu_{r-r_{\nu}}$ depending on $r_{\nu}=n-\nu$ parameters and filling up the space. For each of these varieties $\mu_{r-r_{\nu}}$ we determine the integral variety $M_{\nu}$ passing through $M_{\nu-1}$ which is contained entirely in $\mu_{r-r_{\nu}}$. The geometrical locus of these varieties $M_{\nu}$, when we vary the $n-\nu$ parameters they depend on, is the integral variety $M_{n}$ we search for.}

\somespace

Furthermore, \emph{the variety $M_{\nu}$ is the integral of a system of equations in total differentials in $r-r_{\nu}$ variables of genre $\nu$, but whose coefficients depend on $n-\nu$ parameters.}

From this we deduce the following theorem which refers to the Cauchy problem itself:

\somespace

\emph{Consider a system of equations in total differentials of genre $n$ whose character $s_{\nu}$ is zero $(\nu<n)$. Given an arbitrary point $\mu_{0}$ and an arbitrary variety $\mu_{r-r_{1}}$ passing through this point, etc., an arbitrary variety $\mu_{r-r_{\nu-1}}$ passing through $\mu_{r-r_{\nu-2}}$, there exists one and only one integral variety $M_{n}$ passing through $\mu_{0}$ having in common with $\mu_{r-r_{1}}$ a $1$ dimensional variety, etc., with $\mu_{r-r_{\nu-1}}$ a $\nu-1$ dimensional variety. To obtain it we choose an arbitrary variety $\mu_{r-r_{\nu}-1}$ pass through $\mu_{r-r_{\nu-1}}$ and through this latter variety a family of varieties $\mu_{r-r_{\nu}}$ depending on $r_{\nu}=n-\nu$ parameters and filling up the space. Each of these varieties contains one and only one integral variety $M_{\nu}$ passing through $\mu_{0}$, having in common with $\mu_{r-r_{1}}$ a $1$ dimensional variety, etc., with $\mu_{r-r_{\nu-1}}$ a $\nu-1$ dimensional variety. The geometrical locus of these varieties $M_{\nu}$, when we vary the $n-\nu$ parameters that they depend on, is the integral variety $M_{n}$ we search for.}

\somespace

Indeed, it suffices to observe that the $\nu-1$ dimensional integral variety situated inside $\mu_{r-r_{\nu-1}}$ is the same for $M_{n}$ and all the $M_{\nu}$. Then we only have to apply the preceding theorem to this $\nu-1$ dimensional integral variety.

The last theorem shows that \emph{the Cauchy problem for the given system of genre $n$ amounts to a Cauchy problem for a new system of genre $\nu$, but the coefficients of the new system depend on $n-\nu$ parameters.} The numbers $s$, $s_{1}$, $s_{2}$, $\dots$, $s_{\nu}$ have, furthermore, the same values for the two systems.

We say that the integer $\nu$ is the \emph{true genre} of the system.

We are now going to translate the preceding results analytically. Let us use the notations of \textsection VI. Here a simplification arises due to the fact that $s_{n}$, $s_{n-1}$, $\dots$, $s_{\nu}$ are zero and hence there are no variables $z^{(n)}$, $z^{(n-1)}$, $\dots$, $z^{(\nu)}$.

The variety $\mu_{r-r_{\nu-1}}$ is defined by
\begin{gather}
  \label{eq:Anu1}\tag{$A_{\nu-1}$}
  \left\{
    \begin{aligned}
      z^{(\nu-1)}_{1}&=\phi^{(\nu-1)}_{1}(x_{1},x_{2},\dots,x_{\nu-1}),\\
      &\dots\\
      z^{(\nu-1)}_{s_{\nu-1}}&=\phi^{(\nu-1)}_{s_{\nu-1}}(x_{1},x_{2},\dots,x_{\nu-1}),
    \end{aligned}
  \right.\\
  \label{eq:Bnu}\tag{$B_{\nu}$}
  x_{n}=a_{n},\quad x_{n-1}=a_{n-1},\quad \dots,\quad x_{\nu}=a_{\nu}.
\end{gather}

The variety $\mu_{r-r_{\nu-2}}$ is defined by the preceding equations and also
\begin{gather}
  \label{eq:Anu2}\tag{$A_{\nu-2}$}
  \left\{
    \begin{aligned}
      z^{(\nu-1)}_{2}&=\phi^{(\nu-1)}_{2}(x_{1},x_{2},\dots,x_{\nu-2}),\\
      &\dots\\
      z^{(\nu-2)}_{s_{\nu-2}}&=\phi^{(\nu-2)}_{s_{\nu-2}}(x_{1},x_{2},\dots,x_{\nu-2}),
    \end{aligned}
  \right.\\
  \label{eq:Bnu1}\tag{$B_{\nu-1}$}
  x_{\nu-1}=a_{\nu-1},
\end{gather}
and so on, as in the general case.

We can now take the variety defined by the $n-\nu+1=r_{\nu}+1$ equations \eqref{eq:Bnu} 
\[
  x_{n}=a_{n},\quad x_{n-1}=a_{n-1},\quad \dots,\quad x_{\nu}=a_{\nu}.
\]
as the variety $\mu_{r-r_{n}-1}$, and take the varieties defined by
\begin{equation}
  \label{eq:murrnu}\tag{$\mu_{r-r_{\nu}}$}
  \left\{
    \begin{aligned}
      x_{\nu+1}-a_{\nu+1}&=t_{1}(x_{\nu}-a_{\nu}),\\
      x_{\nu+2}-a_{\nu+2}&=t_{2}(x_{\nu}-a_{\nu}),\\
      &\dots\\
      x_{n}-a_{n}&=t_{n-\nu}(x_{\nu}-a_{\nu}).
    \end{aligned}
  \right.
\end{equation}
as the varieties $\mu_{r-r_{\nu}}$.

The preceding results stated in a geometrical manner can be now expressed in the following manner:

\somespace

\emph{The given system admits one and only one integral for which $z_{1}$, $\dots$, $z_{s_{\nu-1}}^{(\nu-1)}$ are holomorphic functions in $x_1$, $x_{2}$, $\dots$, $x_{n}$ in a neighbourhood of}
\[
x_{1}=a_{1},\quad x_{2}=a_{2},\quad \dots,\quad x_{n}=a_{n},
\]
\emph{and respectively reduce}
\begin{align*}
  &\left.
    \begin{alignedat}{10}
      &z_{1}^{(\nu-1)}&&\text{ \emph{to the arbitrary function} }&&\phi_{1}^{(\nu-1)}(x_{1},x_{2},\dots,x_{\nu-1})\\
      &\dots&&&&\dots\\
      &z_{s_{\nu-1}}^{(\nu-1)}&&\text{ \emph{to the arbitrary function} }&&\phi_{s_{\nu-1}}^{(\nu-1)}(x_{1},x_{2},\dots,x_{\nu-1})
    \end{alignedat}
  \right\}
    \text{ for }\left\{
    \begin{aligned}
      x_{\nu}&=a_{\nu},\\
      x_{\nu+1}&=a_{\nu+1},\\
      &\dots\\
      x_{n}&=a_{n}
    \end{aligned}
  \right.
  \\
  &\left.
    \begin{alignedat}{10}
      &z_{1}^{(\nu-2)}&&\text{ \emph{to the arbitrary function} }&&\phi_{1}^{(\nu-2)}(x_{1},x_{2},\dots,x_{\nu-2})\\
      &\dots&&&&\dots\\
      &z_{s_{\nu-2}}^{(\nu-2)}&&\text{ \emph{to the arbitrary function} }&&\phi_{s_{\nu-2}}^{(\nu-2)}(x_{1},x_{2},\dots,x_{\nu-2})
    \end{alignedat}
  \right\}
    \text{ for }\left\{
    \begin{aligned}
      x_{\nu-1}&=a_{\nu-1},\\
      &\dots\\
      x_{n}&=a_{n}
    \end{aligned}\right.
  \\
  &\dots\\
  &\left.
    \begin{alignedat}{10}
      &z_{1}^{(1)}&&\text{ \emph{to the arbitrary function} }&&\phi_{1}^{(1)}(x_{1})\\
      &\dots&&&&\dots\\
      &z_{s_{1}}^{(1)}&&\text{ \emph{to the arbitrary function} }&&\phi_{s_{1}}^{(1)}(x_{1})
    \end{alignedat}
  \right\}  
    \text{ for }\left\{
    \begin{aligned}
      x_{2}&=a_{2},\\
      &\dots\\
      x_{n}&=a_{n}
    \end{aligned}
\right.
\\
  &\left.
    \begin{alignedat}{10}
      &z_{1}&&\text{ \emph{to the arbitrary constant} }&&\phi_{1}\\
      &\dots&&&&\dots\\
      &z_{s}&&\text{ \emph{to the arbitrary constant} }&&\phi_{s}
    \end{alignedat}
  \right\}  
    \text{ for }\left\{
    \begin{aligned}
      x_{1}&=a_{1},\\
      &\dots\\
      x_{n}&=a_{n}
    \end{aligned}
\right.
\end{align*}

\emph{To obtain these functions, we replace in the given equations of the differential system}
\begin{alignat*}{10}
  &x_{\nu+1}&&\text{ \emph{by} }&&a_{\nu+1}&&{}+{}&t_{1}(x_{\nu}-a_{\nu}),\\
  &x_{\nu+2}&&\text{ \emph{by} }&&a_{\nu+2}&&{}+{}&t_{2}(x_{\nu}-a_{\nu}),\\
  &\dots&&&&&&\dots\\
  &x_{n}&&\text{ \emph{by} }&&a_{n}&&{}+{}&t_{n-\nu}(x_{\nu}-a_{\nu}),\\
\end{alignat*}
\emph{where we regard $t$ as constants. The new system obtained then admits one and only one integral for which $z_{1}$, $\dots$, $z_{s_{\nu-1}}^{\nu-1}$ are holomorphic functions in $x_{1}$, $x_{2}$, $\dots$, $x_{\nu}$ in a neighbourhood of}
\[
x_{1}=a_{1},\quad x_{2}=a_{2},\quad \dots,\quad x_{\nu}=a_{\nu},
\]
\emph{and respectively reduce}
\begin{gather*}  
\begin{alignedat}{10}
  &z^{(\nu-1)}_{i}&&\text{ \emph{to} }\phi_{i}^{(\nu-1)}(x_{1},x_{2},\dots,x_{\nu-1})&&\text{ \emph{for} }&&x_{\nu}=a_{\nu},\\
  &z^{(\nu-2)}_{j}&&\text{ \emph{to} }\phi_{j}^{(\nu-2)}(x_{1},x_{2},\dots,x_{\nu-2})&&\text{ \emph{for} }&&x_{\nu-1}=a_{\nu-1}, x_{\nu}=a_{\nu}\\
  &\dots&&\dots&&&&\dots\\
  &z^{(1)}_{k}&&\text{ \emph{to} }\phi_{k}^{(1)}(x_{1})&&\text{ \emph{for} }&&x_{2}=a_{2},\dots,x_{\nu}=a_{\nu},\\
  &z_{h}&&\text{ \emph{to} }\phi_{h}&&\text{ \emph{for} }&&x_{1}=a_{1},\dots,x_{\nu}=a_{\nu},
\end{alignedat}\\
(i=1,2,\dots,s_{\nu-1};j=1,2,\dots,s_{\nu-2};k=1,2,\dots,s_{1};h=1,2,\dots,s).
\end{gather*}

\emph{If in the functions thus found we replace the $n-\nu$ parameters $t$ they the depend on by respectively}
\begin{align*}
  t_{1}&=\frac{x_{\nu+1}-a_{\nu+1}}{x_{\nu}-a_{\nu}},\\
  &\dots\\
  t_{n-\nu}&=\frac{x_{n}-a_{n}}{x_{\nu}-a_{\nu}},\\
\end{align*}
\emph{we obtain the integral of the primitive system that we search for.}

\somespace

In summary, we see that, \emph{if the integral variety $M_{n}$ of a system in involution (that is to say of genre greater or equal than $n$) depends on arbitrary functions of $\nu-1$ arguments but not on arbitrary functions of $\nu$ arguments, we can carry out the search for this integral variety as the search for the integral $M_{\nu}$ of a system of genre $\nu$ and consequently to a problem in $\nu$ independent variables, but the coefficients of the new system will depend on $n-\nu$ parameters.}

Indeed, it suffices to observe that as $M_{n}$ does not depend on arbitrary functions of $n$ arguments, we necessarily have $r_{n}=0$ and then the genre of the system is exactly $n$.

In particular, if the general integral $M_{n}$ of a system in involution depends only on \emph{arbitrary constants}, we have $\nu=1$, the \emph{character} $s_{1}$ of the system is hence zero and the system is completely integrable. We can make the search of its integral to that of a system of genre $1$, that is to say a system of ordinary differential equations. \emph{The method reduces to that of Lie-Mayer for integration completely integrable systems.} If the equations of the system are solvable with respect to $dz_{1}$, $dz_{2}$, $\dots$, $dz_{s}$, the other differentials being $dx_{1}$, $dx_{2}$, $\dots$, $dx_{n}$, we replace
\begin{alignat*}{10}
  &x_{2}&&\text{ by }&&a_{2}+t_{1}(x_{1}-a_{1}),\\
  &\dots&&&&\dots\\
  &x_{n}&&\text{ by }&&a_{n}+t_{n-1}(x_{1}-a_{1}),  
\end{alignat*}
and we look for the integral of the new system such that $z_{1}$, $z_{2}$, $\dots$, $z_{s}$ reduce on $x_{1}=a_{1}$ to given arbitrary constants $\phi_{1}$, $\phi_{2}$, $\dots$, $\phi_{s}$. We then replace in the functions obtained $t_{i}$ by $\frac{x_{i+1}-a_{i+1}}{x_{1}-a_{1}}$.

As an example, we take the simplest case possible where we do not have a completely integrale system. We choose
\[
\nu=2,\quad n=3,\quad s_{1}=1,\quad s=1.
\]
Then
\[
r_{3}=0,\quad r_{2}=1,\quad r_{1}=3,\quad r=5.
\]

The following equation corresponds to this case
\[
x_{4}dx_{1}-x_{4}x_{5}dx_{2}-(x_{2}x_{4}+x_{3}+x_{1}x_{5})dx_{5}=0.
\]
We will not verify the above and we will simply apply the generalised Lie-Mayer method to find the general integral of this equation. We see easily that the point
\[
x_{1}=0,\quad x_{2}=0,\quad x_{3}=0,\quad x_{4}=1,\quad x_{5}=0
\]
is not singular, that the linear element $E_{1}$ based on this point
\[
dx_{1}=dx_{2}=dx_{3}=dx_{4}=0
\]
is integral. Here $(P_{0})$ has equation
\begin{equation}
  \tag{$P_{0}$}
  dx_{1}=0,
\end{equation}
as for $(P_{1})$, we easily find that
\begin{equation}
  \tag{$P_{1}$}
  dx_{1}=dx_{3}=0
\end{equation}
and we can check that this element $E_{3}$ is integral. Moreover, $E_{1}$ is not singular.

We can therefore take the variables $x_{1}$, $x_{3}$, $x_{4}$, $x_{2}$, $x_{5}$ to be the variables denoted by $z$, $z^{(1)}$, $x_{3}$, $x_{2}$, $x_{1}$ in the general theory, respectively.

There is therefore one and only one integral, such that
\begin{alignat*}{10}
  &x_{3}&&\text{ reduce to }&&f(x_{5})&&\text{ for }&&x_{2}=0,x_{4}=1,\\
  &x_{1}&&\text{ reduce to }&&c&&\text{ for }&&x_{2}=0,x_{4}=1,x_{5}=0.
\end{alignat*}

To obtain it, it suffices to replaces in the equation
\[
x_{4}-1\quad\text{by}\quad tx_{2},
\]
which gives
\[
(tx_{2}+1)dx_{1}-(tx_{2}+1)x_{5}dx_{2}-(tx^{2}_{2}+x_{2}+x_{3}+x_{1}x_{5})dx_{5}=0.
\]

We must first search the function $x_{1}$ in $x_{5}$ which reduces to $c$ for $x_{5}=0$ when we set $x_{3}=f(x_{5})$, $x_{2}=0$. This function is given by
\[
\frac{dx_{1}}{dx_{5}}=f(x_{5})+x_{1}x_{5},
\]
from which we deduce
\[
x_{1}=ce^{x_{5}^{2}}+e^{x^{2}_{5}/2}\int_{0}^{x_{5}}e^{-x_{5}^{2}/2}f(x_{5})dx_{5}=\phi(x_{5}).
\]

We must then search for the two functions $x_{3}$ and $x_{1}$ in $x_{2}$, $x_{5}$ which reduce to $f(x_{5})$ and $\phi(x_{5})$ for $x_{2}=0$. They are given by
\begin{align*}
  \frac{\pd x_{1}}{\pd x_{2}}&=x_{5},\\
  1&=1+\frac{\pd}{\pd x_{2}}\frac{x_{3}+x_{1}x_{5}}{tx_{2}+1}.
\end{align*}

The second one gives
\[
x_{3}+x_{1}x_{5}=(tx_{2}+1)\left[f(x_{5})+cx_{5}e^{x^{2}_{5}/2}+x_{5}e^{x^{2}_{5}/2}\int_{0}^{x^{5}}e^{-x^{2}_{5}/2}f(x_{5})\right],
\]
and the first one
\[
x_{1}=x_{2}x_{5}+ce^{x^{2}_{5}/2}+e^{x_{5}^{2}/2}\int_{0}^{x_{5}}e^{-x_{5}^{2}/2}f(x_{5})dx_{5}.
\]

By replacing in the first formula $t x_{2}+1$ by $x_{4}$, we obtain the general integral that can be written as
\begin{align*}
  x_{1}-x_{2}x_{5}&=F(x_{5}),\\
  x_{3}+x_{1}x_{5}&=x_{4}F'(x_{5})
\end{align*}
by setting
\[
F(x_{5})=ce^{x^{2}_{5}}+e^{x_{5}^{2}/2}\int_{0}^{x_{5}}e^{-x_{5}^{2}/2}f(x_{5})dx_{5}.
\]

\section{}
\label{sec:8}

In this last section we are going to be concerned with certain systems for which the Kowalewski system determining the integral variety $M_{p+1}$ passing through a given integral variety presents certain simple properties that make this integration easy. Such a system, by using the notations of \textsection III, is, if we restrict ourselves to the case of $s_{p+1}=0$, solvable with respect to
\[
\frac{\pd z_{1}}{\pd x},\quad\frac{\pd z_{2}}{\pd x},\quad\dots,\quad\frac{\pd z_{m}}{\pd x},
\]
the right hand sides depending on the variables and the first order derivatives of the unknown functions $z$ with respect to the independent variables $x_{1}$, $x_{2}$, $\dots$, $x_{p}$ other than $x$.

If we solve the Cauchy problem for a first order partial differential equation in one unknown function, by a change of independent variables we are led precisely to a Kowalewski system \emph{where the right hand sides do not depend on the derivatives $\frac{\pd z_{i}}{\pd x_{k}}$}. Then we are actually led to a system of ordinary differential equations.

Let us find in what cases the same situation arises. As we have done in \textsection III, we denote by $\epsilon$, $\epsilon^{(1)}$, $\epsilon^{(2)}$, $\dots$, $\epsilon^{(p)}$ the $p+1$ linear elements
\begin{align*}
  \tag{$\epsilon$}
&  \frac{dx}{1}=\frac{dx_{1}}{0}=\dots=\frac{dx_{p}}{0}=\frac{dz_{1}}{\frac{\pd z_{1}}{\pd x}}=\dots=\frac{dz_{m}}{\frac{\pd z_{m}}{\pd x}},\\
  \tag{$[\epsilon^{(1)}]$}
&  \frac{dx}{0}=\frac{dx_{1}}{1}=\dots=\frac{dx_{p}}{0}=\frac{dz_{1}}{\frac{\pd z_{1}}{\pd x_{1}}}=\dots=\frac{dz_{m}}{\frac{\pd z_{m}}{\pd x_{1}}},\\
&  \cdots\\
  \tag{$[\epsilon^{(p)}]$}
&  \frac{dx}{0}=\frac{dx_{1}}{0}=\dots=\frac{dx_{p}}{1}=\frac{dz_{1}}{\frac{\pd z_{1}}{\pd x_{p}}}=\dots=\frac{dz_{m}}{\frac{\pd z_{m}}{\pd x_{p}}},
\end{align*}
\emph{the Kowalewski equations express that the element $\epsilon$ is integral and associated to the element $E_{p}$ $[\epsilon^{(1)}, \epsilon^{(2)}, \dots, \epsilon^{(p)}]$, subject to the condition that the element $E_{p}$ is integral.}

Granted this, suppose that the Kowalewski equations do not depend on $\frac{\pd z_{i}}{\pd x_{k}}$, i.e., a sum of $\epsilon^{(1)}$, $\dots$, $\epsilon^{(p)}$. Then the values of $\frac{\pd z_{1}}{\pd x}$, $\dots$, $\frac{\pd z_{m}}{\pd x}$ that they determine furnish a linear integral element $\epsilon$, depending only on the point where it is based at, \emph{which is associated to all the linear elements $E_{p}$ passing through the point}, since an arbitrary element $E_{p}$ can always be formed linearly by $\epsilon$ and an element of the form $[\epsilon^{(1)}, \epsilon^{(2)}, \dots, \epsilon^{(p)}]$.

In summary, \emph{there passes through each point of the space a linear integral element enjoying the property that it is associated to any linear integral element based on the same point.}

This linear element is necessarily \emph{singular}, since it belongs to $\infty^{r_{1}-1}$ integral elements $E_{2}$. We say that it is \emph{characteristic}.

In general, \emph{an integral element $E_{p}$ based on a non-singular point of the space is called \emph{characteristic} if it is associated to any linear integral element based on the same point.}

All linear elements contained in a characteristic element $E_{h}$ $(h>1)$ are themselves characteristic and the locus of the characteristic linear elements is necessarily a flat characteristic element, which is the largest characteristic element based on the point.

To obtain the linear characteristic elements based on a given non-singular point analytically, let us denote by
\[
\delta x_{1},\quad \delta x_{2},\quad \dots,\quad \delta x_{r}
\]
the coordinates of such an element and by
\[
dx_{1},\quad dx_{2},\quad \dots,\quad dx_{r}
\]
the coordinates of a variable integral element based on the same point. We have, to determine $\delta x_{i}$, the equations
\[
\left\{
  \begin{gathered}
    a_{1}\delta x_{1}+\dots+a_{r}\delta x_{r}=0,\\
    \cdots\\
    l_{1}\delta x_{1}+\dots+l_{r}\delta x_{r}=0,\\
    \sum a_{1i}dx_{i}\delta x_{1}+\dots+\sum a_{ri}dx_{i}\delta x_{r}=0,\\
    \cdots\\
    \sum l_{1i}dx_{i}\delta x_{1}+\dots+\sum l_{ri}dx_{i}\delta x_{r}=0,
  \end{gathered}
\right.
\]
where the notations are the same as in \textsection I \footnote{We have set simply
\[
a_{ik}=\frac{\pd a_{i}}{\pd x_{k}}-\frac{\pd a_{k}}{\pd x_{i}},\qquad\dots,\qquad
l_{ik}=\frac{\pd l_{i}}{\pd x_{k}}-\frac{\pd l_{k}}{\pd x_{i}}.
\]}. Moreover, these equations must hold whatever the values of
\[
dx_{1},\quad dx_{2},\quad \dots,\quad dx_{r},
\]
subject to the conditions that these quantities satisfy the $s$ equations \eqref{eq:1}:
\begin{equation}
  \tag{1}
  \left\{
    \begin{alignedat}{3}
       a_{1}dx_{1}+a_{2}dx_{2}+\dots+a_{r}dx_{r}&{}={}0,\\
      &\dots\\
      l_{1}dx_{1}+l_{2}dx_{2}+\dots+l_{r}dx_{r}&=0.
    \end{alignedat}
  \right.
\end{equation}

Then, the equation in $dx_{1}$, $\dots$, $dx_{r}$
\[
\sum a_{1i}\delta x_{i}dx_{1}+\dots+\sum a_{ri}\delta x_{i}dx_{r}=0
\]
must be a consequence of the equations \eqref{eq:1}. In other words, \emph{all the minors formed with $s+1$ columns of the matrix}
\begin{equation}
  \tag{$A$}
  \begin{Vmatrix}
    a_{1}&a_{2}&\dots&a_{r}\\
    \hdotsfor{4}\\
    l_{1}&l_{2}&\dots&l_{r}\\
    \sum a_{1i}\delta x_{i}&\sum a_{2i}\delta x_{i}&\dots&\sum a_{ri}\delta x_{i}
  \end{Vmatrix}
\end{equation}
\emph{must be zero}. The same holds if we replace in this matrix the last line by the $s-1$ analogous lines deduced from the last $s-1$ equations of \eqref{eq:1}, which gives the matrices $(B)$, $\dots$, $(L)$.

Ultimately, \emph{the equations determining the characteristic linear elements are of two sorts: first the $s$ equations}
\begin{equation}
  \tag{1$'$}\label{eq:1'}
  \left\{
    \begin{alignedat}{3}
       a_{1}\delta x_{1}+a_{2}\delta x_{2}+\dots+a_{r}\delta x_{r}&{}={}0,\\
      &\dots\\
      l_{1}\delta x_{1}+l_{2}\delta x_{2}+\dots+l_{r}\delta x_{r}&=0.
    \end{alignedat}
  \right.
\end{equation}
\emph{which expresses that this element is integral, and then the equations obtained by annihilating all the minors formed with $s+1$ columns of the $s$ matrices $(A)$, $\dots$, $(L)$,}
\begin{gather}
  \tag{$A$}
  \begin{Vmatrix}
    a_{1}&\dots&a_{r}\\
    \hdotsfor{3}\\
    l_{1}&\dots&l_{r}\\
    \sum a_{1i}\delta x_{i}&\dots&\sum a_{ri}\delta x_{i}
  \end{Vmatrix},\\
  \notag\dots,\\
  \tag{$L$}
  \begin{Vmatrix}
    a_{1}&\dots&a_{r}\\
    \hdotsfor{3}\\
    l_{1}&\dots&l_{r}\\
    \sum l_{1i}\delta x_{i}&\dots&\sum l_{ri}\delta x_{i}
  \end{Vmatrix}.  
\end{gather}

If among these equations there are less than $r$ independent ones, there exists characteristic linear elements and these equations determine their locus, that is to say the largest characteristic element based on the point.

If the given system is completely integral, any two linear integral elements are associated, and then, the equations of the characteristic elements reduce to the equations \eqref{eq:1'}. The principal minors of the matrices $(A)$, $\dots$, $(L)$ are of degree $s$ by taking \eqref{eq:1'} into account.

Here are now some simple fundamental properties of the characteristic elements:

\emph{Given a characteristic element $E_{p}$, every \emph{non-singular} integral element $E_{n}$ contains $E_{p}$}. Indeed, otherwise the smallest element containing $E_{n}$ and $E_{p}$ will be at least $n+1$ dimensional and it will necessarily be integral since $E_{n}$ and $E_{p}$ are associated. The integral element $E_{n}$ belonging to an integral element $E_{n+1}$ will therefore be singular. Obviously here $n$ denotes the genre of the given system.

\emph{If through every non-singular point of the space there passes a characteristic element, the given differential system is of the first kind}. Since if we consider a characteristic element $\epsilon$, then every non-singular integral element $E_{n}$ contains $\epsilon$,  and there certainly exists integral elements $E_{n-1}$ that does not contain $\epsilon$ and naturally, among these integral elements there are those that are not singular \footnote{Otherwise every non-singular integral element $E_{n-1}$ will be subject to an \emph{equality} condition: that which contains $\epsilon$.}. Let $E_{n-1}$ be one of them. Through $E_{n-1}$ there passes $\infty^{r_{n}}$ integral elements $E_{n}$ and at least one of them is non-singular, that is to say contains $\epsilon$. If $r_{n}$ is equal to or greater than $1$, there will be at least one integral element $E_{n}$ other than $(E_{n-1},\epsilon)$. Let us call it $(E_{n-1},\epsilon')$. But then the element $(E_{n-1},\epsilon,\epsilon')$ will be integral and the non-singular element $(E_{n-1},\epsilon)$ will belong to another integral element of $n+1$ dimensions, which is impossible. Therefore $r_{n}$ \emph{must be zero}, that is to say the given differential system is of the first kind. \emph{Therefore the systems of the first kind are the only ones that there can have characteristic elements.}

Similarly, we see that \emph{if there exists a characteristic integral element $E_{p}$, the true genre of the system is at most $n-p+1$}. Since there certainly exists a non-singular integral element $E_{n-p}$ having no common element with $E_{p}$ and every non-singular integral element $E_{n}$ passing through $E_{n-p}$ must contain $E_{p}$, therefore it is determined in a unique manner and we can denote it by $(E_{n-p}, E_{p})$. If $E_{n-p}$ belongs to another integral element $E_{n}$, the element $(E_{n},E_{p})$ will be integral and be at least $n+1$ dimensional. On the other hand it contains $(E_{n-p},E_{p})$ which will then be singular. Hence $E_{n-p}$ belongs to only one integral element $E_{n}$. Then, finally, the true genre of the system is at most $n-p+1$.

We can add that \emph{if there exists a non-singular integral element $E_{n-1}$ containing $E_{p}$, the true genre is at most $n-p$.} Since there always exists an integral element $E_{n-p-1}$ contained in $E_{n-1}$ and having no common element with $E_{p}$. If an $n$ dimensional integral element passing through $E_{n-p-1}$ contains $E_{p}$, it will also contain $E_{n-1}$, and then is completely and uniquely determined, since the non-singular integral element $E_{n-1}$ belongs to one $n$ dimensional integral element $E_{n}$ which is itself non-singular. If now there passes through $E_{n-p-1}$ another integral element $E_{n}'$, the element $(E'_{n},E_{p})$ will be at least $n+1$ dimensional and integral. On the other hand, it will contain $(E_{n-p-1},E_{p})$, that is to say $E_{n-1}$, which is impossible, since there does not pass through $E_{n-1}$ any integral element of more than $n$ dimensions. Therefore, through $E_{n-p-1}$ there passes a single $n$ dimensional integral element. Therefore, finally, the true genre of the system is at most $n-p$.

From these properties we can extract the following, for which only the statement is necessary since the proof is evident:

\somespace

\emph{If for a differential system of genre $n$ there passes through each non-singular point of the space a $p$ dimensional characteristic element, then all the non-singular integral varieties $M_{n}$ passing through a non-singular point have a $p$ dimensional element based on the point in common, and vice versa.}

\somespace

Let us now see what we can draw from the existence of characteristic elements for the determination of $n$ dimensional non-singular integral varieties.

First suppose that there exists a \emph{linear} characteristic element. Then this linear element associates every arbitrary point to a certain straight line $D$ passing through the point. As we know, there exists a family of curves (one dimensional varieties) such that at each of their points they are tangent to the straight line $D$ corresponding to this point. These curves depend on $r-1$ parameters and through each non-singular point of the space there passes one and only one such curve. We call them the \emph{characteristic curves} and they are obviously integral curves.

Granted this, consider a non-singular variety $M_{n}$. On each of its non-singular points it admits a non-singular integral element which then contains the characteristic element $\epsilon$ based on the point. In other words, at each of its points the variety $M_{n}$ has among its tangents the straight line $D$ corresponding to this point. On $M_{n}$ there therefore exists a family of curves tangent at each of their points to the corresponding straight line $D$. These curves depend on $n-1$ parameters and through each non-singular point of $M_{n}$ there passes one and only one such curve. But it is obvious that these curves are \emph{characteristic curves}. Therefore, we arrive at the following result:

\somespace

\emph{Every non-singular integral variety $M_{n}$ is generated by a family of characteristic curves depending on $n-1$ parameters. Through each non-singular point of $M_{n}$ there passes one and only one of these curves. If two non-singular integral varieties $M_{n}$ have a non-singular point in common, they have all the characteristics based on the point in common.}

\somespace

It follows from this that \emph{given a non-singular integral variety $M_{n-1}$ not generated by characteristic curves, we will have the integral variety $M_{n}$ passing through $M_{n-1}$ by making the characteristic curves passing through the point.}

We therefore have the solution of the Cauchy problem when $M_{n-1}$ is not generated by characteristic curves.

We are now going to show these results analytically, which will allow us to see clearly what the problem of integration reduces to when we know the characteristic curves.

In our present case, the characteristic curves are given by a system of $r-1$ equations in total differentials. They are the equations found previously that determine the characteristic element based on each point of the space. Let
\[
y_{1}=C_{1},\quad y_{2}=C_{2},\quad \dots,\quad y_{r-1}=C_{r-1}
\]
be $r-1$ independent first integrals of these equations. They determine the characteristic curves. Let us make a change of variables by taking $y_{1}$, $y_{2}$, $\dots$, $y_{r-1}$ and a quantity $y_{r}$ independent of the previous $r-1$ as the new variables. With these new variables, the system of linear integral elements and the associated linear elements do not change: then, the system of equations in total differentials determining the characteristics remain the same. They are therefore
\[
dy_{1}=dy_{2}=\dots=dy_{r-1}=0.
\]

The equations of the transformed system therefore must first be satisfied for $dy_{1}=\dots=dy_{r-1}=0$. Then, we can make this system under the form
\begin{equation}
  \label{eq:1_1}\tag{$1_{1}$}
  \left\{
    \begin{gathered}
      dy_{1}+b_{1,s+1}dy_{s+1}+\dots+b_{1,r-1}dy_{r-1}=0,\\
      \cdots\\
      dy_{s}+b_{s,s+1}dy_{s+1}+\dots+b_{s,r-1}dy_{r-1}=0,
    \end{gathered}
  \right.
\end{equation}
$b$ depending on $y_{1}$, $y_{2}$, $\dots$, $y_{r}$. Now express that the integral element
\[
\frac{dy_{1}}{0}=\dots=\frac{dy_{r-1}}{0}=\frac{dy_{r}}{1}
\]
is associated to every other integral element $(dy_{1},\dots,dy_{r})$. We first have
\[
\frac{\pd b_{1,s+1}}{\pd y_{r}}dy_{s+1}+\dots+\frac{\pd b_{1,r-1}}{\pd y_{r}}{dy_{r-1}}=0,
\]
under the condition that $dy$ satisfy \eqref{eq:1_1}, that is to say, we have
\[
\frac{\pd b_{1,s+1}}{\pd y_{r}}=\dots=\frac{\pd b_{1,r-1}}{\pd y_{r}}=0.
\]
In other words, \emph{all the coefficients $b$ are independent of $y_{r}$}.

\emph{The transformed system can therefore be made under a form such that in the coefficients and differentials there are only the $r-1$ variables}
\[
y_{1},\quad y_{2},\quad\dots,\quad y_{r-1}.
\]

We therefore see that the number of variables is reduced by one and, to find the varieties $M_{n}$ of the original system, it suffices to find the integral varieties $M_{n-1}$ of the new system. \emph{The genre of the new system is reduced by one, but the degree of indeterminacy does not change.} Only that the new system can no longer be of the first kind.

Thus, \emph{when we have integrated the differential equations of the characteristics, we are lead to a new differential system with one less variable, the genre having been reduced by one.} We have
\begin{gather*}
  s'=s,\quad s'_{1}=s_{1},\quad\dots,\quad s'_{n-1}=s_{n-1},\\
  n'=n-1,\\
  r'=r-1,\quad r'_{1}=r_{1}-1,\quad\dots,\quad r'_{n-1}=r_{n-1}-1.
\end{gather*}

Let us now pass to the case where \emph{there passes through each point of the space at least one characteristic element $E_{p}$ of dimensions at least two}. There are then at least $r-p$ independent linear equations in $dx_{1}$, $\dots$, $dx_{r}$ determining $E_{p}$. We may think that these equations do not in general determine a completely integrable differential system, but \emph{this is not true}. \emph{This differential system, which we will call the \emph{characteristic} differential system, is always completely integrable.}

To see this, it suffices to choose in each $E_{p}$ a particular linear element $\epsilon$, that is to say it suffices to adjoint to the differential system any $p-1$ determined linear equations. We then have a system of $r-1$ independent equations, which are then completely integrable and we denote by
\[
y_{1},\quad y_{2},\quad\dots,\quad y_{r-1}
\]
its system of $r-1$ independent first integrals. By a change of variables, the equations of the system, as we have just seen, depend only on $y_{1}$, $\dots$, $y_{r-1}$. The characteristic differential system therefore changes into a system of $r-p$ equations \emph{in $r-1$ variables.} We reason in this case as we have done above until we have reduced the variables to be no more than $r-p$ in number, which we call
\[
z_{1},\quad z_{2},\quad\dots,\quad z_{r-p}.
\]

Then it is clear that the characteristic differential system is none other than
\[
dz_{1}=dz_{2}=\dots=dz_{r-p}=0.
\] 

Therefore, \emph{the characteristic differential system is completely integrable and we can, by a change of variables, make the given system under a form such that its coefficients and differentials only depend on the $r-p$ first integrals of the characteristic system.}

We also see that \emph{there exists a family of $p$ dimensional integral varieties admitting at each of their points the characteristic element $E_{p}$. We call them \emph{characteristic varieties}. They depend on $r-p$ parameters and, at each non-singular point of the space, there passes one and only one such variety.}

\emph{Every non-singular integral variety $M_{n}$ is generated by a family of characteristic varieties depending on $n-p$ parameters. There passes one and only one of these varieties through every non-singular point of $M_{n}$. If two non-singular $n$-dimensional integral varieties have a non-singular point in common, they have the same characteristic variety at the point in common.}

If a non-singular integral variety $M_{n-p}$ does not have any curve in common at each of its points with the characteristic variety based on the point, to have the unique integral variety $M_{n}$ passing through $M_{n-p}$ it suffices to take the characteristic variety based on the points of $M_{n-p}$ pass through each point of $M_{n-p}$.

Finally, \emph{the general determination of the integral $M_{n}$ amounts to the integration of a new differential system whose genre as well as the number of variables are reduced by $p$, but who has the same degree of indeterminacy as the given system.}

To see this last point, it suffices to recall that the true genre of the given system is at most $n-p+1$. Then we have
\[
s_{n}=s_{n-1}=\dots=s_{n-p+1}=0.
\]

We then have
\begin{gather*}
  n'=n-p,\\
  s'_{n-p}=s_{n-p},\quad\dots,\quad s'_{1}=s_{1},\quad s'=s,\\
  r'_{n-p}=s_{n-p}=r_{n-p}-p,\quad\dots,\quad r'_{1}=r_{1}-p,\quad r'=r-p.
\end{gather*}

But we must not forget that the reduction to this new system presupposes the preliminary determination of the characteristic varieties. The generalised Lie-Mayer method allows us to arrive at a system of genre $n-p+1$ (instead of $n-p$) \emph{without prior integration}, but this system depends on the particular Cauchy problem that we want to solve.

Observe that if the number of variables of the given differential system can be reduced by $p$ units by a suitable change of variables, the characteristic differential system is necessarily formed, at most, by $r-p$ independent equations. We therefore have the following theorem, originally stated under a slightly different form by von Weber \footnote{\emph{Loc.~cit.}}, which is itself just a generalisation of a theorem due to Frobenius for the case of a single equation:

\somespace

\emph{The minimal number of variables that by a change of variables we can make the coefficients and differentials of a given system to depend on is equal to the number of linearly independent equations of its characteristic system. The integration of this characteristic system furnishes the variables.}

\somespace

Finally, to finish this subject, we are going to prove the existence of characteristic elements \emph{in differential systems of first kind whose character is equal to one.}

Take a differential system of genre $n$ for which we have $s_{1}=1$. Then the numbers $s_{2}$, $s_{3}$, $\dots$ cannot surpass $s_{1}$, that is to say $1$, and we have, to fix ideas,
\[
s_{1}=s_{2}=\dots=s_{\nu-1}=1,\qquad s_{\nu}=\dots=s_{n}=0,
\]
$\nu$ being the true genre (which can be equal to $n$).

Granted this, consider a non-singular point $E_{0}$ and the set of linear integral elements based on the point. They form an element $E_{r_{1}+1}$. In what follows we will only talk about the elements situated inside $E_{r_{1}+1}$, that is to say the elements formed with the linear integral elements. (We furthermore have $r_{1}+1=n+\nu-1$.)

Take an integral element $E_{n}$ and a linear element $\epsilon$ not contained in $E_{n}$. The locus of the (integral) linear elements associated with $\epsilon$ is a $r_{1}+1-s_{1}=r_{1}$ dimensional element. Therefore this element cut $E_{n}$ following an element $H_{n-1}$ (of $n+r_{1}-(r_{1}+1)=n-1$ dimensions). All the linear elements contained in $H_{n-1}$ are then associated with $E_{n}$ and $\epsilon$, that is to say with the element $E_{n+1}$: $(E_{n},\epsilon)$.

Now take a linear element $\epsilon'$ not contained in $E_{n+1}$. The locus of the linear elements associated to $\epsilon'$ is again a $r_{1}$ dimensional element cutting $H_{n-1}$ following at least a $n-2$ dimensional element $H_{n-2}$ and all the linear elements of $H_{n-2}$ are associated with $E_{n+1}$ and $\epsilon'$, that is to say the element $E_{n+2}$: $(E_{n+1},\epsilon')$. We can continue this step by step: we will have an element $H_{n-3}$ whose linear elements are associated with an element $E_{n+3}$ and so on, until we finally arrive at an element $H_{n-\nu+1}$ whose elements are associated to an element $E_{n+\nu+1}$, that is to say $E_{r_{1}+1}$. In other words, there exists an element  $H_{n-\nu+1}$ whose linear elements are integral and associated with \emph{any} linear integral element. This element $H_{n-\nu+1}$ is therefore \emph{characteristic}.

It follows from this that \emph{the given differential system of genre $n$, true genre $\nu$ and character $1$ admits characteristic varieties of $n-\nu+1$ dimensions. It then leads to, according to the determination of these characteristics, a system of genre $\nu-1$.}

This result applies to a single Pfaffian equation (provided that it is of first kind). We hence rediscover the characteristic varieties of systems of first order partial differential equations of a single unknown function.

In particular, \emph{if the general integral of a differential system depends on a single arbitrary function of a single argument (and of arbitrary constants), the integration leads to that of the characteristic system, which is completely integrable, and to that of a system of ordinary differential equations \footnote{Beudon has proved this result for a system of partial differential equations in one unknown function. He is, in a series of notes and articles, concerned with partial differential equations with the property that they admit characteristic varieties in the sense given to this word in the text. \emph{See}, in particular, \emph{Sur les systèmes d'équations aux dérivées partielles dont les caractéristiques dépendent d'un nombre fini de constantes arbitraires} (\emph{Annales de l'École Normale}, vol.~\textsc{xiii}, supplement, p.~3--51; 1896)}.}

If the general integral of a system of first kind depends on one arbitrary function of $1$, $2$, $\dots$, $\nu-1$ arguments (and on arbitrary constants), $\nu-1$ being at least equal to $2$, we can prove \footnote{\emph{See}, in particular, \textsc{von Weber}, \emph{loc.~cit.}} that the system can, without integration, be made under the following form: first, a system of $s-1$ completely integrable equations, then, a $s$-th equation which can be made under the form
\[
dz-p_{1}dx_{1}-\dots-p_{\nu-1}dx_{\nu-1}=0,
\]
which by a suitable integration leads to the characteristic differential system.

\emph{The problem of integrating the characteristic differential system is hence not an arbitrary integration problem of a completely integrable system in total differentials.} To see this, imagine that we have found a first integral $y_{1}$ and let us focus on the variety $y_{1}=C$, where $C$ is an arbitrary constant.

Now consider, at an arbitrary point $A$ in this variety, the element $E_{r-1}$: $dy_{1}=0$. The characteristic element $E_{p}$ on $A$ is necessarily contained in the element $E_{r-1}$, but if we find the linear integral elements of $E_{r-1}$ which are characteristics \emph{with respect to only the elements of $E_{r-1}$}, we can, in certain cases, find those elements that are not contained in $E_{p}$, such that we obtain an characteristic element $E_{q}$ containing $E_{p}$ $(q>p)$, but which is characteristic only when we do not go out of the element $E_{r-1}$. In other words, the characteristic differential system of the given system where we set $y_{1}=C$, $dy_{1}=0$ can contain at least one less equation than the original characteristic system. We find a first integral $y_{2}$ of this system, and so on. We will arrive at a certain number of first integrals $y_{1}$, $y_{2}$, $\dots$, $y_{h}$, such that when we set $y_{1}=C_{1}$, $\dots$, $y_{h}=C_{h}$, the differential system obtained has all of its characteristic equations satisfied.

It is then clear that the equations of the given system can all be put under the form
\[
\alpha_{1}dy_{1}+\dots+\alpha_{h}dy_{h}=0
\]
and we arrange that, by a suitable choice of $s$ linearly independent equations defining the system, the coefficients $\alpha$ that are independent among themselves and with $y$ define the different integrals of $y$ of the characteristic system.

This is how we precede in the case of a single Pfaffian equation. Take, for fixing the ideas, an equation in five variables with unspecified coefficients. If we represent a linear element by a point in three dimensional space $R_{3}$, the linear integral elements are represented by the points in a certain plane $(P)$ of this space, and the images of two associated linear integral elements are such that the straight line joining them belongs to a certain linear complex. But in ordinar space, the straight lines of a linear complex situated in a plane $(P)$ all pass through a fixed point $A$ of the plane. The point $A$ is therefore the image of a linear characteristic element. The characteristic differential system therefore admits three independent first integrals. We find from them a $y_{1}$, which determines in the space $R_{3}$ a plane $(Q)$. The linear integral elements satisfying $dy_{1}=0$ also have images in $R_{3}$ that are points belonging at the same time to $(P)$ and $(Q)$, that is to say the straight line $(D)$ of the intersection of these two planes. But now \emph{two arbitrary points of this straight line are associated}, such that we have a second characteristic differential system formed with a single equation [the equation of the straight line $(D)$ in the plane $(Q)$]. Let $y_{2}$ be its first integral. Then
\[
dy_{1}=dy_{2}=0
\]
are, if we would like, the equations of the straight line $(D)$. The equation of the plane $(P)$, which is none other than the given Pfaffian equation, is then of the form
\[
dy_{2}-y_{3}dy_{1}=0,
\]
and $y_{3}$ is the third first integral we search for, since it is obvious that the characteristic system of the equation put into its new form can be none other than
\[
dy_{1}=dy_{2}=dy_{3}=0.
\]

To take another example, consider the case of two equations in six variables. The genre of the system is, in the general case, equal to $2=\frac{6}{2+1}$. We can represent a linear element by a point in a space $R_{5}$ of five variables. The images of linear integral elements are then situated in a space $R_{3}$ of three dimensions, and in this space the straight lines joining two associated points belong to two linear complexes. We have seen, in \textsection II, that three cases can arise. Take the last, the one where the straight lines of the complex are the straight lines passing through a fixed point $A$ of $R_{3}$ and, moreover, the straight lines are situated inside a certain plane $(P)$ passing through $A$. Here therefore there is a linear characteristic element whose image is $A$.

The characteristic differential system will admit five independent first integrals. We will find first a $y_{1}$. By replacing $y_{1}$ by $C$, we will have in $R_{5}$ a space $R_{4}$ cutting $R_{3}$ following the plane $(Q)$. In $R_{4}$, the images of the linear integral elements are situated in the plane $(Q)$, which naturally passes through $A$ and, in the plane $(Q)$, the lines joining two associated points are the lines based on $A$. Therefore there is here again a single linear characteristic element. The new characteristic system is formed with five equations defining the point $A$ in $R_{4}$. Let $y_{2}$ be a first integral of this new system. It defines in $R_{4}$ a space $R'_{3}$ cutting $(Q)$ following a straight line $(D)$ passing through $A$, but then all the points of $(D)$ are associated among themselves. The new characteristic system is therefore formed with \emph{two} equations defining $(D)$ in $R'_{3}$. We only have to search the two independent first integrals $y_{3}$ and $y_{4}$ of this system.

We have hence four integrals to search for, by operations of order respectively $5$, $4$, $2$ and $1$.

In reality, we can again simplify this integration after the first operation and restrict ourselves to three integrals given by the operations of orders $5$, $3$ and $1$. But, for this, we need to take into consideration certain covariant equations, which are beyond the scope of this article.

There is also a case where the integration simplifies: the one where the first integral $y_{1}$ gives a space $R_{4}$ containing the plane $(P)$, that is to say the case \emph{where the three equations defining $(P)$ admit an integrable combination}. In this case, the images of the linear integral elements of the new system are the points of $(P)$ and \emph{these points are all associated with each other}. The new characteristic system is formed by the \emph{two} equations defining $(P)$ in $R_{4}$. By integrating them, we will have two first integrals $y_{2}$ and $y_{3}$, and the equations of $(P)$ in $R_{5}$ are then
\[
dy_{1}=dy_{2}=dy_{3}=0.
\]

The space $R_{2}$, which is the locus of the images of the linear integral elements, passes through $(P)$, and hence the two equations defining it, that is to say the given equations, are of the form
\begin{gather*}
  dy_{2}-y_{4}dy_{1}=0,\\
  dy_{3}-y_{5}dy_{1}=0,
\end{gather*}
 $y_{4}$ and $y_{5}$ being two first integrals other than $y_{1}$, $y_{2}$ and $y_{3}$. Here we have, by the same occasion, a \emph{canonical form} of the system.

The operations to apply, in this particular case, is of order $3$, $2$ and $1$, since it suffices, in sum, to integrate the three equations defining the plane $(P)$, these three equations forming a completely integrable system.

\chapter*{Differential systems\\in involution \footnote{Chapter 1 of \emph{Sur la structure des groupes infinis de transformations} (Annales École Normale, 3rd series, 21, 1904).}}
\label{cha:diff-syst-invol}

\setcounter{equation}{0}
\paragraph{}
\label{sec:p1}
Given a Pfaffian system in $n$ variables
\begin{equation}
  \label{eq:p1}
  \omega_{d}=a_{1}dx_{1}+a_{2}dx_{2}+\dots+a_{n}dx_{n},
\end{equation}
we know that we can adjoin to it a covariant expression that is bilinear with respect to two systems of differentials denoted by the symbols $d$ and $\delta$:
\begin{align}
  \label{eq:p2}
  \omega_{d\delta}=d\omega_{\delta}-\delta\omega_{d}&=da_{1}\delta x_{1}-\delta a_{1}dx_{1}+\dots+da_{n}\delta x_{n}-\delta a_{n}dx_{n}\\
  &=\sum_{(i,k)}\left(\frac{\pd a_{k}}{\pd x_{i}}-\frac{\pd a_{i}}{\pd x_{k}}\right)(dx_{i}\delta x_{k}-dx_{k}\delta x_{i}).\notag
\end{align}

The coefficients of the bilinear covariant of a Pfaffian system are not arbitrary functions of variables. They satisfy the relations given by the following considerations:

If we consider any alternating bilinear differential expression:
\begin{equation}
  \label{eq:p3}
  \Omega_{d\delta}=\sum_{(i,k)}a_{ik}(dx_{i}\delta x_{k}-dx_{k}\delta x_{i})\qquad (a_{ik}=-a_{ki},a_{ii=0}),
\end{equation}
we can adjoin to it a covariant expression that is trilinear with respect to three systems of differentials denoted by the symbols $d$, $\delta$ and $D$,
\begin{equation}
  \label{eq:p4}
  \Omega_{d\delta D}=d\Omega_{\delta D}+\delta\Omega_{Dd}+D\Omega_{d\delta}=\sum{a_{ijk}}
  \begin{pmatrix}
    dx_{i}&dx_{j}&dx_{k}\\
    \delta x_{i}&\delta x_{j}&\delta x_{k}\\
    Dx_{i}&Dx_{j}&Dx_{k}
  \end{pmatrix},
\end{equation}
where we have
\[
a_{ijk}=\frac{\pd a_{ij}}{\pd x_{k}}+\frac{\pd a_{jk}}{\pd x_{i}}+\frac{\pd a_{ki}}{\pd x_{j}}.
\]

\somespace

\emph{If $\Omega_{d\delta}$ is the bilinear covariant of a Pfaffian expression $\omega$, we can verify without difficulty that $\Omega_{d\delta D}$ is identically zero, and conversely, if the trilinear covariant of $\Delta_{d\delta}$ is identically zero, we can show that there exists a Pfaffian expression (defined uniquely up to an exact differential of a function) whose bilinear covariant is $\Omega_{d\delta}$.}

\somespace

The identity expressed by the preceding theorem is the analogue, or rather the dual, of Jacobi's identity in the theory of complete systems. We will use it frequently in the following and we will give it the name \emph{fundamental identity}.

\paragraph{}
\label{sec:p2}
We will use symbolic notations devised to simply calculations. If $\omega$ and $\vp$ are two Pfaffian expressions, we denote, symbolically,
\begin{equation}
  \label{eq:p5}
  \omega\vp=\omega_{d}\vp_{\delta}-\omega_{\delta}\vp_{d}.
\end{equation}
Similarly, if $\omega$, $\vp$ and $\chi$ are three Pfaffian expressions, we set
\begin{equation}
  \label{eq:p6}
  \omega\vp\chi=
  \begin{vmatrix}
    \omega_{d}&\vp_{d}&\chi_{d}\\
    \omega_{\delta}&\vp_{\delta}&\chi_{\delta}\\
    \omega_{D}&\vp_{D}&\chi_{D}\\
  \end{vmatrix}.
\end{equation}

With these notations, we have
\begin{gather*}
  \omega\vp=-\vp\omega,\qquad\omega\omega=0,\\
  \omega\vp\chi=\vp\chi\omega=\chi\omega\vp=-\vp\omega\chi=-\chi\vp\omega=-\omega\chi\vp.
\end{gather*}

We denote the bilinear covariant of a Pfaffian expression $\omega$ simply by $\omega'$, such that we have
\[
\omega'=\sum\left(\frac{\pd a_{k}}{\pd x_{i}}-\frac{\pd a_{i}}{\pd x_{k}}\right)dx_{i}dx_{k}.
\]

If $A$ denotes a function in $x$, the bilinear covariant of $A\omega$ is
\[
dA\omega+A\omega'
\]
and the trilinear covariant of the bilinear expression $A\omega\vp$ is
\begin{equation}
  \label{eq:p7}
  dA\omega\vp+A\omega'\vp-a\omega\vp'.
\end{equation}

Finally, if we consider $n$ independent Pfaffian expressions in $dx_{1}$, $dx_{2}$, $\dots$, $dx_{n}$, which we write as
\[
\omega_{1},\quad\omega_{2},\quad\dots\quad\omega_{n},
\]
then every Pfaffian expression can be written under the form
\[
a_{1}\omega_{1}+a_{2}\omega_{2}+\dots+a_{n}\omega_{n},
\]
every bilinear expression under the form
\[
\sum_{(i,k)}a_{ik}\omega_{i}\omega_{k},
\]
and every trilinear under the form
\[
\sum_{ijk}a_{ijk}\omega_{i}\omega_{j}\omega_{k}.
\]

\paragraph{}
\label{sec:p3}
Given a system of Pfaffian equations, the theory on the existence and the degree of indeterminacy of the \emph{general} integral varieties of the system can be summarised as follows:

Let us call the set of a point $(x_{1}, x_{2}, \dots, x_{n})$ and a straight line (of direction parameters $dx_{1}$, $dx_{2}$, $\dots$, $dx_{n}$) passing through the point a \emph{linear element}, and similar the set of a point and a $p$ dimensional plane passing through this point a \emph{$p$ dimensional element}. A linear element is said to be \emph{integral} when its coordinates satisfy the equations of the Pfaffian system. Two linear integral elements, based on the same point, are said to be \emph{in involution} when their coordinates
\[
dx_{1},\quad\dots\quad dx_{n}\qquad\text{and}\qquad\delta x_{1},\quad\dots\quad\delta x_{n}
\]
annihilate all the bilinear covariants of the left hand sides of the equations of the system. Finally a $p$-th order element is said to be \emph{integral} when all its linear elements are integral and any two of them are in involution.

Granted this, let $s$ be the number of linearly independent equations expressing that a linear element, based on an \emph{arbitrary} point, is integral (this is the number of independent equations of the system). We obviously have
\[
s\le n.
\]
If $s$ is equal to $n$, there are no linear integral element and the system does not admit any \emph{general} integral variety. If $s$ is less than $n$, through each point there passes at least one linear integral element.

Let $E$ be an arbitrary linear integral element and let $s+s_{1}$ be the number of linearly independent equations expressing that a linear element is integral and in involution with $E$. We obviously have
\[
s+s_{1}\le n-1.
\]
If $s+s_{1}$ is equal to $n-1$, through $E$ there does not pass any integral element of order $2$ and at most the system can admit only one dimensional integral varieties. If $s+s_{1}$ is less than $n-1$, through $E$ there passes at least one second order integral element.

Let $E'$ be an arbitrary second order integral element and let $s+s_{1}+s_{2}$ be the number of linearly independent equations expressing that a linear element is integral and in involution with $E'$. We obviously have
\[
s+s_{1}+s_{2}\le n-2
\]
and so on.

Finally we arrive at a certain integer $m$ which indicates the maximum number of dimensions of the general integral varieties of the system, and we have the $m+1$ integers
\[
s,\quad s_{1},\quad s_{2},\quad\dots\quad s_{m}
\]
\emph{which cannot increase} and which indicate the degree of indeterminacy of the general $m$ dimensional integral variety. It depends on
\[
\begin{matrix*}[l]
  s_{m}&\text{arbitrary functions in}&m&\text{arguments,}\\
  s_{m-1}&\text{arbitrary functions in}&m-1&\text{arguments,}\\
  \hdotsfor{4}\\
  s_{1}&\text{arbitrary functions in}&1&\text{arguments,}\\
  s&\text{arbitrary constants.}&&
\end{matrix*}
\]

Finally, we have
\[
s+s_{1}+\dots+s_{m}=n-m.
\]

If $p$ is any integer not greater than $m$, we say that the system, considered as of $p$ independent variables, is in involution. We have
\begin{equation}
  \label{eq:p8}
  s+s_{1}+\dots+s_{p}\le n-p
\end{equation}
and the non-singular $p$ dimensional integral elements based on an arbitrary point depend on
\[
Q=p(n-p)-ps-(p-1)s_{1}-(p-2)s_{2}-\dots-2s_{p-2}-s_{p-1}
\]
parameters.

Observe that, if we suppose the equations of the system to be solved with respect to the differentials of $s$ of the variables, the number of the other \emph{dependent} variables is precisely $n-p-s$. Denoting this number by $q$, the number $Q$ is then
\begin{equation}
  \label{eq:p9}
  Q=pq-(p-1)s_{1}-(p-2)s_{2}-\dots-s_{p-1}.
\end{equation}

\paragraph{}
\label{sec:p4}
The theory we just summarised must be further developed to resolve the following question whose practical importance is evident.

\somespace

\emph{Determine the integral varieties of a given dimension $p$ of a given Pfaffian system, under the condition that these integral varieties must not imply any algebraic relations among $p$ specified variables of the given variables, or more generally, they must not imply any linear relations among $p$ Pfaffian forms specified in advance}
\[
\omega_{1},\quad\omega_{2},\quad\dots\quad\omega_{p}
\]
\emph{(independent among themselves and with the left hand sides of the equations of the system).}

\somespace

In particular, it is necessary to have all these varieties as general integral varieties of a new Pfaffian system \emph{in involution}.

The left hand sides
\[
\theta_{1},\quad\theta_{2},\quad\dots\quad\theta_{s}
\]
of the equations of the system and the $p$ given expressions
\[
\omega_{1},\quad\omega_{2},\quad\dots\quad\omega_{p}
\]
form $s+p$ linearly independent expressions. We can adjoin to them $q=n-s-p$ other expressions, independent among themselves and with respect to the old ones, which we write as
\[
\vp_{1},\quad\vp_{2},\quad\dots\quad\vp_{q}.
\]

Then, \emph{using the equations of the systems}, the bilinear covariants of $\theta$ are the bilinear covariants with respect to $\omega$ and $\vp$. We are first going to show that we can always assume it to be of the form
\begin{equation}
  \label{eq:p10}
  \theta_{k}'=\sum_{ij}c_{ijk}\omega_{i}\omega_{j}+\sum_{i,\rho}a_{i\rho k}\omega_{i}\vp_{\rho}\qquad(k=1,2,\dots,s).
\end{equation}

Indeed, every $p$ dimensional integral varieties satisfies not only the given equations, but also equations of the form
\begin{equation}
  \label{eq:p11}
  \vp_{k}=l_{k1}\omega_{1}+\dots+l_{kp}\omega_{p}\qquad(k=1,2,\dots,q),
\end{equation}
$l_{ki}$ being functions of the variables such that all the $\theta'_{k}$ are zero if we replace in them $\vp$ by the preceding values. It may arise that the compatibility of these equations that $l$ must satisfy requires particular relations among the given variables. If these relations do not leave the $\omega$s independent, the problem is unsolvable. Otherwise they effectively reduce the number $q$. We then need to start again with the new system obtained, until we arrive at either a stage where the problem is unsolvable, or at a system of compatible equations for $l$. Then we can express all of the coefficients of $l$ as functions of the given variables and a certain number of auxiliary variables $y_{1}$, $y_{2}$, $\dots$. The bilinear covariants of the Pfaffian system obtained by adjoining to the old system the equations \eqref{eq:p11} will then be, using the equations of the system, of the form
\[
\sum\gamma_{ij}\omega_{i}\omega_{j}+\sum a_{ik}\omega_{i}dy_{k},
\]
which proves the proposition \footnote{Indeed, the covariants $\theta'$ all vanish if we use \eqref{eq:p11}. As for the equations \eqref{eq:p11} themselves, they give rise to the covariants such that
\[
\vp'_{k}-l_{k1}\omega'_{1}-\dots-l_{kp}\omega'_{p}+\omega_{1}dl_{k1}+\dots+\omega_{p}dl_{kp},
\]
and it suffices to replace, after expanding $\omega'$ and $\vp'$, $\vp$ by their values \eqref{eq:p11}.
}.

We henceforth assume that $\theta_{k}'$ are of the form \eqref{eq:p10}.

\paragraph{}
\label{sec:p5}
We are first going to search for the necessary and sufficient conditions for \emph{a Pfaffian system, considered as of $p$ independent variables, to be in involution, such that arbitrary integral elements of order less than or equal to $p$ do not introduce any linear relations among the $\omega$.} If this is the case, the varieties we look for will be just the \emph{general} integral varieties of the given system.

To this end, first, it is obviously necessary that there are integral elements of order $p$ defined by equations of the form \eqref{eq:p11}. If this is the case, we can, by adjoining to $\vp$ certain linear combinations of $\omega$, ensure that
\[
\vp_{1}=\vp_{2}=\dots=\vp_{q}=0
\]
defines an integral element. Consequently, \emph{we can suppose the coefficients $c_{ijk}$ to be all zero.}

Granted this, consider the integers $s_{1}$, $s_{2}$, $\dots$, $s_{p}$ defined in \textsection\textbf{3}. Since every linear integral element is defined by a system of equations
\begin{equation}
  \label{eq:p12}
  \frac{\omega_{1}}{u_{1}}=\frac{\omega_{2}}{u_{2}}=\dots=\frac{\omega_{p}}{u_{p}}=\frac{\vp_{1}}{v_{1}}=\dots=\frac{\vp_{1}}{v_{q}},
\end{equation}
the number $s_{1}$ indicates the number of independent equations of the system
\begin{equation}
  \label{eq:p13}
  \sum_{i,\rho}a_{i\rho k}u_{i}\vp_{\rho}-\sum_{i,\rho}a_{i\rho k}v_{\rho}\omega_{i}=0,\qquad(k=1,2,\dots,s),
\end{equation}
where $u_{i}$ and $v_{\rho}$ are arbitrary constants and $\omega_{i}$, $\vp_{\rho}$ are the variables. \emph{As these equations must not entail any relations among $\omega$}, the number $s_{1}$ is the rank (degree of the principal determinant) of the matrix of $s$ rows
\[
\begin{Vmatrix}
  \sum a_{i11}u_{i}&\sum a_{i21}u_{i}&\dots&\sum a_{iq1}u_{i}\\
  \hdotsfor{4}\\
  \sum a_{i1s}u_{i}&\sum a_{i2s}u_{i}&\dots&\sum a_{iqs}u_{i}  
\end{Vmatrix}.
\]

For $s_{2}$, $\dots$, $s_{p}$, consider the matrix of $ps$ rows
\begin{equation}
  \label{eq:p14}
\begin{Vmatrix}
  \sum a_{i11}u_{i}&\sum a_{i21}u_{i}&\dots&\sum a_{iq1}u_{i}\\
  \hdotsfor{4}\\
  \sum a_{i1s}u_{i}&\sum a_{i2s}u_{i}&\dots&\sum a_{iqs}u_{i}\\
  \sum a_{i11}u'_{i}&\sum a_{i21}u'_{i}&\dots&\sum a_{iq1}u'_{i}\\
  \hdotsfor{4}\\
  \sum a_{i1s}u'_{i}&\sum a_{i2s}u'_{i}&\dots&\sum a_{iqs}u'_{i}\\
  \hdotsfor{4}\\
  \sum a_{i1s}u^{(p-1)}_{i}&\sum a_{i2s}u^{(p-1)}_{i}&\dots&\sum a_{iqs}u^{(p-1)}_{i}  
\end{Vmatrix} 
\end{equation}
where $u_{i}$, $u_{i}'$, $\dots$, $u_{i}^{(p-1)}$ are $p^{2}$ arbitrary values. The number $s_{1}+s_{2}$ is the rank of the matrix by taking the first $2s$ rows, $s_{1}+s_{2}+s_{3}$ the rank of the matrix obtained by taking the first $3s$ rows, and so on.

Granted this, the formulae \eqref{eq:p8} and \eqref{eq:p9} show that we have
\[
s_{1}+s_{2}+\dots+s_{p}\le q
\]
and the number of arbitrary parameters that the most general $p$-th order integral element of the form \eqref{eq:p11} depends on is
\[
pq-(p-1)s_{1}-(p-2)s_{2}-\dots-s_{p-1}.
\]

\paragraph{}
\label{sec:p6}
Conversely, \emph{given a Pfaffian system whose covariants $\theta'_{k}$ has the form \eqref{eq:p10}, let us form, by means of the coefficients $a_{i\rho k}$, the matrix \eqref{eq:p14} and consider the integers}
\[
\sigma_{1},\quad\sigma_{2},\quad\dots\quad\sigma_{p}
\]
\emph{which are the ranks of the matrices obtained by taking in \eqref{eq:p14} successively the first}
\[
s,\quad 2s,\quad\dots\quad ps
\]
\emph{rows. The number of arbitrary parameters that the most general $p$-th order integral element which does not introduce any linear relations among the $\omega$ depends on can never exceed the integer}
\[
pq-(p-1)\sigma_{1}-(p-2)\sigma_{2}-\dots-\sigma_{p-1}.
\]
\emph{If this value is attained, the system is in involution and its general $p$ dimensional integral varieties do not introduce any linear relations among $\omega$.}

\somespace

First, since according to the statement itself, assume that there exists $p$-th order integral elements of the form \eqref{eq:p11}, and we can suppose all $c_{ijk}$ in the formulae \eqref{eq:p10} to be zero.

Furthermore, we can, by means of a suitable linear transformation on $\omega$, suppose that the rank of the $p$ matrices considered do not decrease if we take
\[
u^{(i)}_{i+1}=1,\qquad u^{(i)}_{j}=0\quad\text{for}\quad j\neq i+1.
\]
Finally we can always set
\begin{equation}
  \label{eq:p15}
  \theta'_{\rho}=\omega_{1}\vp_{\rho 1}+\omega_{2}\vp_{\rho 2}+\dots+\omega_{p}\vp_{\rho p},\qquad(\rho=1,2,\dots,s),
\end{equation}
$\vp_{\rho i}$ being linear combinations of $\vp$.

From the hypothesis it then follows that among $\vp_{\rho 1}$ there are exactly $\sigma_{1}$ independent ones, which we write as
\[
\vp_{11},\quad\vp_{21},\quad\dots\quad\vp_{\sigma_{1}1},
\]
the $\vp_{\rho 1}$ for which $\rho$ is greater than $\sigma_{1}$ depend on the preceding ones. Similarly among $\vp_{\rho 2}$ $(\rho\le \sigma_{1})$ there are $\sigma_{2}$ independent ones, which we write as
\[
\vp_{12},\quad\vp_{22},\quad\dots\quad\vp_{\sigma_{2}2},
\]
the $\vp_{\rho i}$ for which $\rho$ is greater than $\sigma_{2}$ depend on the $\sigma_{1}+\sigma_{2}$ preceding ones, and so on.

In other words, the $sp$ combinations $\vp_{\rho i}$ are independent when we have
\[
\rho\le \sigma_{i}.
\]
These are said to be \emph{principal}. There are in total
\[
\sigma_{1}+\sigma_{2}+\dots+\sigma_{p}
\]
of them, and the other $\vp_{\rho i}$ are expressed linearly in terms of the principal ones for which the second index does not exceed $i$. Finally, it may happen that among $\vp_{k}$ there are some that cannot be expressed in the principal $\vp_{\rho i}$, and there are in total
\[
q-(\sigma_{1}+\sigma_{2}+\dots+\sigma_{p})
\]
of them.

Granted this, we can first, in every case, express the last ones in arbitrary ways in terms of $\omega$, which already gives
\begin{equation}
  \label{eq:p16}
  p(q-\sigma_{1}-\sigma_{2}-\dots-\sigma_{p})
\end{equation}
arbitrary parameters. As for the expressions $\vp_{\rho i}$, if we set
\[
\vp_{\rho i}=l_{\rho i1}\omega_{1}+l_{\rho i2}\omega_{2}+\dots+l_{\rho i p}\omega_{p},
\]
the condition that $\theta'_{\rho}$ vanishes gives
\[
l_{\rho ij}=l_{\rho ji},
\]
such that $l_{\rho ij}$ satisfy the two following conditions:

\somespace

1. \emph{If we give the last index $j$ any specified value, every linear relation among $\vp_{\rho i}$ also holds among the corresponding $l_{\rho ij}$;}

2. \emph{We have}
  \begin{equation}
    \label{eq:p17}
    l_{\rho ij}=l_{\rho ji}.
  \end{equation}

\somespace

It follows that the only coefficients $l_{\rho ij}$ that can be taken arbitrarily are \emph{at most} those that have
\begin{equation}
  \label{eq:p18}
  \rho\le \sigma_{i},\qquad\rho\le \sigma_{j}.
\end{equation}
We call these the \emph{principal} coefficients $l$. They have
\begin{equation}
  \label{eq:p.19}
  \sigma_{1}+2\sigma_{2}+\dots+p\sigma_{p}
\end{equation}
in number. By adding to it the number \eqref{eq:p16} we obtain the maximum number of parameters that a $p$-th order integral element depends on
\[
pq-(p-1)\sigma_{1}-(p-2)\sigma_{2}-\dots-\sigma_{p-1}.
\]
The first part of the theorem is hence proved.

Now suppose that this number is attained, that is to say we can satisfy the two conditions stated above by taking the \emph{principal} coefficients $l_{\rho ij}$ arbitrarily. We are going to show that the system is in involution and the corresponding numbers $s_{i}$ are equal to the numbers $\sigma_{i}$.

Consider an \emph{arbitrary} linear integral element $E_{1}$. We can always, by means of a linear transformation on $\omega$, suppose it to be defined by the relations
\[
\frac{\omega_{1}}{1}=\frac{\omega_{2}}{0}=\dots=\frac{\omega_{p}}{0}=\frac{\vp_{\rho i}}{v_{\rho i1}},
\]
the $v_{\rho i1}$ being arbitrary quantities that satisfy the same relations as the corresponding $\vp_{\rho i}$, in other words they are all expressible in terms of those that have
\[
\rho\le \sigma_{i}.
\]
The equations expressing that a linear integral element is in involution with $E_{1}$ is then
\begin{equation}
  \label{eq:p20}
  \vp_{\rho 1}-v_{\rho 11}\omega_{1}-v_{\rho 21}\omega_{2}-\dots-v_{\rho p1}\omega_{p}=0.
\end{equation}
These equations do not entail any relations among $\omega$, otherwise, there will be a certain index $i$ such that there is among $\vp_{\rho 1}$ a relation that cannot be satisfied by the corresponding $v_{\rho i1}$. Then it would be impossible to find a system of quantities $v_{\rho ij}$, that the given $v_{\rho i1}$ is part of such that the two conditions stated above are satisfied without there being any relations between the \emph{principal} $v_{\rho i1}$, since there would be among the $v_{\rho 1i}$ a relation that cannot be satisfied by the quantities $v_{\rho i1}$.

Hence we see that $s_{1}$ is equal to $\sigma_{1}$ and then the integer $m$ is equal or greater than $2$.

Similarly an \emph{arbitrary} second order integral element $E_{2}$ can always be assumed to be defined by the two elements
\[
(1,0,\dots,0;v_{\rho i1})\quad\text{and}\quad(0,1,\dots,0;v_{\rho i2}).
\]
As the involution condition for these two elements gives
\[
v_{\rho 12}=v_{\rho 21},
\]
$v_{\rho i1}$ as well as $v_{\rho i2}$ being, from now on, subject to the condition that they satisfy among themselves the same relations as $\vp_{\rho i}$, we can arbitrarily take $v_{\rho 12}=v_{\rho 21}$ for which $\rho$ does not exceed $\sigma_{2}$, and take the other $v_{\rho i1}$ and $v_{\rho i2}$ for which $\rho$ does not exceed $\sigma_{i}$ arbitrarily. The system expressing that a linear integral element is in involution with $E_{2}$ is then
\begin{equation}
  \label{eq:p21}
  \left\{
    \begin{aligned}
      \vp_{\rho 1}-v_{\rho 11}\omega_{1}-v_{\rho 21}\omega_{2}-\dots-v_{\rho p1}\omega_{p}&=0,\\
      \vp_{\rho 2}-v_{\rho 12}\omega_{1}-v_{\rho 22}\omega_{2}-\dots-v_{\rho p2}\omega_{p}&=0,      
    \end{aligned}
  \right.
\qquad(\rho=1,2,\dots,s).
\end{equation}
It contains $\sigma_{1}+\sigma_{2}$ independent equations and does not introduce any relations among $\omega$, otherwise there will be a certain index $i$ such that there is among $\vp_{\rho 2}$ and $\vp_{\rho 1}$ a relation that cannot be satisfied by the corresponding $v_{\rho i2}$ and $v_{\rho i1}$. Then, it would be impossible to find a system of quantities $v_{\rho ij}$, which the given $v_{\rho i1}$ and $v_{\rho i2}$ are a part of such that the conditions stated above are satisfied without there being any relations among the \emph{principal} $v_{\rho i1}$ and $v_{\rho i2}$, since there would be among $v_{\rho 1i}$ and $v_{\rho 2i}$ a relation (the same one as among $\vp_{\rho 1}$ and $\vp_{\rho 2}$) that cannot be satisfied by the quantities $v_{\rho i1}$ and $v_{\rho i2}$. We hence see that $s_{2}$ is equal to $\sigma_{2}$ and that, if $p$ is greater than $2$, there passes through each arbitrary integral element $E_{2}$ at least one integral element $E_{3}$.

We can continue in this way and we find that
\[
s_{1}=\sigma_{1},\quad s_{2}=\sigma_{2},\quad\dots\quad s_{p}=\sigma_{p},
\]
which proves the theorem.

\paragraph{}
\label{sec:p7}
Whenever we have a system of $pqr$ quantities
\[
a_{i\rho k}\qquad(i=1,2,\dots,p;\rho=1,2,\dots,q;k=1,2,\dots, s)
\]
satisfying the conditions of the theorem in \textsection\textbf{6}, we say that it constitute an \emph{involutive} system. It is useful, for the following, to study some remarkable properties of these systems.

Let us continue to use the notations of the preceding section
\begin{equation}
  \label{eq:p22}
  \sum_{i,k}a_{ik\rho}\omega_{i}\vp_{k}=\omega_{1}\vp_{\rho 1}+\omega_{2}\vp_{\rho 2}+\dots+\omega_{p}\vp_{\rho p},\qquad(\rho=1,2,\dots,s),
\end{equation}
$\vp_{\rho i}$ being linear combinations of $\vp$ that can all be expressed by means of
\[
\sigma_{1}+\sigma_{2}+\dots+\sigma_{p}
\]
variables among them, which we have called \emph{principal}, and which satisfy
\[
\rho\le \sigma_{i}.
\]

It is possible to find a system of quantities $l_{\rho ij}$ having the following three properties:

1. Every relation among the $\vp_{\rho i}$ holds for the corresponding $l_{\rho ij}$, $j$ denoting any given index;

2. We have, whatever the values $\rho$, $i$ and $j$ are,
\[
l_{\rho ij}=l_{\rho ji};
\]

3. The \emph{principal} quantities $l_{\rho ij}$, i.e., those that have
\[
\rho \le \sigma_{i},\qquad \rho\le \sigma_{j}
\]
can be chosen \emph{arbitrarily.}

Note that, according to this, if we denote by
\[
X_{\rho i}=0,\qquad(\rho >\sigma_{i})
\]
the equation determining the non-principal expression $\vp_{\rho i}$ in terms of the \emph{principal} $\vp$ whose second index is less than or equal to $i$ and denote by
\[
X^{j}_{\rho i}=0,\qquad(j\le i,\rho >\sigma_{i})
\]
the equation that we deduce from it by replacing all the $\vp_{\rho'i'}$ by the corresponding $l_{\rho'i'j}$, \emph{we then obtain a system of equations defining the non-principal $l_{\rho ij}$ in terms of the principal $l_{\rho ij}$ completely.} It suffices to take, step by step, the equations
\[
X^{1}_{\rho 1}=0,\quad
X^{1}_{\rho 2}=0,\quad
X^{2}_{\rho 2}=0,\quad
X^{1}_{\rho 3}=0,\quad
X^{2}_{\rho 3}=0,\quad
X^{3}_{\rho 3}=0,\quad
\dots
\]

Granted this, we can \emph{prolong} the involutive system by \emph{defining}, using $\sigma_{1}+2\sigma_{2}+\dots+p\sigma_{p}$ new variables, the bilinear expressions
\begin{equation}
  \label{eq:p23}
  \omega_{1}\vp_{\rho i1}+\omega_{2}\vp_{\rho i2}+\dots+\omega_{p}\vp_{\rho ip},\qquad(\rho =1,2,\dots,s;i=1,2,\dots,p),
\end{equation}
which here play the same role as the expressions \eqref{eq:p22} for the given system and $\vp_{\rho ij}=\vp_{\rho ji}$ are linked by exactly the same relations as $l_{\rho ij}$. For this new system, we have
\begin{alignat*}{10}
  &\sigma'_{1}&&{}={}&&\sigma_{1}{}+{}&&\sigma_{2}{}+{}&&\cdots{}+{}&&\sigma_{p},\\
  &\sigma'_{2}&&{}={}&&&&\sigma_{2}{}+{}&&\cdots{}+{}&&\sigma_{p},\\
  &&&\cdots\\
  &\sigma'_{p}&&{}={}&&&&&&&&\sigma_{p},
\end{alignat*}
we claim that \emph{it is also involutive}.

Indeed, we are going to determine in the following manner a system of $\frac{sp(p+1)(p+2)}{6}$ quantities
\[
l_{\rho ijk}=l_{\rho jik}=l_{\rho ikj}=l_{\rho kij}=l_{\rho jki}=l_{\rho kji}.
\]

We take the following quantities arbitrarily
\[
l_{\rho ijk},\qquad(i\ge j\ge k,\rho\le \sigma_{i})
\]
which we name \emph{principal}. As for the rest, they are completely determined in terms of the preceding ones by the equations
\[
X_{\rho i}^{jk}=0,\qquad(k\le j\le i,\rho>\sigma_{i})
\]
obtained by replacing in $X_{\rho i}$ the $\vp_{\rho'i'}$ by the corresponding $l_{\rho'i'jk}$. We arrange these equations in the order of increasing $i$, and those corresponding to the same $i$ are arranged in increasing order of $j$ (from $1$ to $i$) and those with the same values of $i$ and $j$ are arranged in increasing order of $k$ (from $1$ to $j$).

Granted this, we can show without difficulty that \emph{every relation among $\vp_{\rho i}$ holds for the corresponding $l_{\rho i\alpha\beta}$, regardless of the indices $\alpha$ and $\beta$}. Similarly, every relation among $\vp_{\rho ij}$ holds for the corresponding $l_{\rho ij\alpha}$, regardless of the index $\alpha$.

The $l_{\rho ijk}$ therefore play the same role for $\vp_{\rho ij}$ as $l_{\rho ij}$ for $\vp_{\rho i}$. But the number of these quantities that are arbitrary is precisely
\[
\sigma'_{1}+2\sigma'_{2}+\dots+p\sigma'_{p},
\]
and then, the system considered is really involutive.

\paragraph{}
\label{sec:p8}
The involutive system of quantities $a_{ik\rho}$ also enjoys another property which will be useful for us. \emph{If we try to determine the most general bilinear expression $\Pi_{\rho i}$ annihilating the following trilinear expressions identically}
\begin{equation}
  \label{eq:p24}
  \omega_{1}\Pi_{\rho 1}+\omega_{2}\Pi_{\rho 2}+\dots+\omega_{p}\Pi_{\rho p},\qquad(\rho=1,2,\dots,s),
\end{equation}
\emph{and satisfying the same relations as $\vp_{\rho i}$ do, we find}
\begin{equation}
  \label{eq:p25}
  \Pi_{\rho i}=\omega_{1}\chi_{\rho i1}+\omega_{2}\chi_{\rho i2}+\dots+\omega_{p}\chi_{\rho ip},
\end{equation}
\emph{where $\chi_{\rho ij}=\chi_{\rho ji}$ are arbitrary Pfaffian expressions satisfying the same relations as $l_{\rho ij}$.}

In the statement, we suppose that $\Pi_{\rho i}$ are bilinear expressions with respect to $\omega$ and a number of other independent Pfaffian expressions.

First, it is evident that, if we take $\Pi_{\rho i}$ to be the expressions of the form \eqref{eq:p25}, they satisfy the question. It is the converse that we need to prove.

As it is easy to see, the $\Pi_{\rho i}$, which are annihilated by multiplying with $\omega$, can always be made into the form \eqref{eq:p25}, the $\chi_{\rho ij}$ being for the moment arbitrary. Furthermore, we can suppose that every relation among $\Pi_{\rho i}$ holds also for $\chi_{\rho i\alpha}$ regardless of the index $\alpha$. Granted this, suppose we have already shown that there is an integer $h<p$ such that we have
\[
\chi_{\rho \alpha\beta}=\chi_{\rho\beta\alpha},\qquad(\alpha,\beta=1,2,\dots,h).
\]

We claim that this property also holds for $h+1$.  Omitting the terms in
\[
\omega_{h+2},\quad\omega_{h+3},\quad\dots\quad\omega_{p},
\]
the expression \eqref{eq:p24} takes the form
\[
\omega_{1}\omega_{h+1}(\chi_{\rho,1,h+1}-\chi_{\rho,h+1,1})+\dots+\omega_{h}\omega_{h+1}(\chi_{\rho,h,h+1}-\chi_{\rho,h+1,h}).
\]

It follows that we have, \emph{by also omitting $\omega_{h+1}$},
\begin{equation}
  \label{eq:p26}
  \left\{
    \begin{aligned}
      \chi_{\rho,1,h+1}&=\chi_{\rho,h+1,1}+\lambda_{\rho11}\omega_{1}+\dots+\lambda_{\rho 1 h}\omega_{h},\\
      &\dots\\
      \chi_{\rho,h,h+1}&=\chi_{\rho,h+1,h}+\lambda_{\rho h1}\omega_{1}+\dots+\lambda_{\rho h h}\omega_{h},
    \end{aligned}
  \right.
\end{equation}
$\lambda_{\rho ij}$ being finite quantities satisfying
\[
\lambda_{\rho ij}=\lambda_{\rho ji},\qquad(i,j=1,2,\dots,h).
\]

Then, we can set, by omitting $\omega_{h+2}$, $\dots$, $\omega_{p}$
\begin{align*}
  \Pi_{\rho 1}&=\omega_{1}\chi_{\rho 11}+\dots+\omega_{h}\chi_{\rho 1 h}+\omega_{h+1}\chi_{\rho,h+1,1}-\lambda_{\rho 11}\omega_{1}\omega_{h+1}-\dots-\lambda_{\rho 1 h}\omega_{h}\omega_{h+1},\\
  &\dots\\
  \Pi_{\rho h}&=\omega_{1}\chi_{\rho h1}+\dots+\omega_{h}\chi_{\rho h h}+\omega_{h+1}\chi_{\rho,h+1,h}-\lambda_{\rho h1}\omega_{1}\omega_{h+1}-\dots-\lambda_{\rho h h}\omega_{h}\omega_{h+1}.
\end{align*}

By adding to the \emph{principal} $\chi_{\rho ij}$ expressions of the form $\mu_{\rho ij}\omega_{h+1}$ as necessary, we can manifestly make them such that we have
\[
\lambda_{\rho ij}=0,\qquad(i,j=1,2,\dots,h;\rho\le\sigma_{i},\rho\le\sigma_{j}),
\]
this modification necessarily entails analogous modifications for the non-principal $\chi_{\rho ij}$ as well as for $\chi_{\rho,h+1,i}$, but as for the latter they always enter the expressions of $\Pi_{\rho 1}$, $\dots$, $\Pi_{\rho h}$ multiplied by $\omega_{h+1}$, this has no importance for them. We therefore finally see that $\Pi_{\rho i}$ are now presented in the form desired, up to bilinear expressions such as
\[
\Psi_{\rho i}=\lambda_{\rho i 1}\omega_{1}\omega_{h+1}+\dots+\lambda_{\rho i h}\omega_{h}\omega_{h+1},\qquad(i=1,2,\dots,p)
\]
with
\begin{align*}
  \lambda_{\rho ij}&=\lambda_{\rho ji},&&(i,j=1,2,\dots,h),\\
  \lambda_{\rho ij}&=0,&&(\rho\le \sigma_{i},\rho\le\sigma_{j};i=1,2,\dots,p;j=1,2,\dots,h).
\end{align*}

By expressing these necessary relations for $\Pi_{\rho i}$, we see that these relations must also hold for $\Psi_{\rho i}$. Then, $\lambda_{\rho ij}$ satisfy the fundamental property of $l_{\rho ij}$, and as \emph{the principal ones among them are zero}, the rest are also zero. The theorem is hence proved.

\paragraph{}
\label{sec:p9}
With the two preceding theorems, we can, \emph{by using only the fundamental identity}, show that if we prolong a system in involution we obtain a system in involution again, a property that we can easily deduce \emph{a priori} for the existence and indeterminacy of integral varieties of the given system.

If to the equations of the system we adjoin the new equations
\begin{equation}
  \label{eq:p27}
  \bar\vp_{\rho i}=\vp_{\rho i}-l_{\rho i1}\omega_{1}-l_{\rho i2}\omega_{2}-\dots-l_{\rho ip}\omega_{p}=0,\qquad
  \left(\begin{aligned}
    \rho&=1,2,\dots,s\\
    i&=1,2,\dots,p
  \end{aligned}\right),
\end{equation}
the covariants of the left hand sides of the new equations of the system are manifestly, after using those equations themselves and the old equations, under the form
\begin{equation}
  \label{eq:p28}
  \bar\vp'_{\rho i}=\omega_{1}\chi_{\rho i1}+\omega_{2}\chi_{\rho i 2}+\dots+\omega_{p}\chi_{\rho ip}+\cdots,
\end{equation}
the terms not written out depend only on $\omega$, and $\chi_{\rho ij}$ being are just the differentials $dl_{\rho ij}$ up to terms in $\omega_{i}$. By applying the fundamental identity to the covariants
\[
\theta'_{\rho}=\omega_{1}\bar\vp_{\rho 1}+\omega_{2}\bar\vp_{\rho 2}+\dots+\omega_{p}\bar\vp_{\rho p}\pmod{\theta_{1},\dots,\theta_{s}},
\]
we obviously obtain
\[
0=\omega_{1}\bar\vp'_{\rho 1}+\omega_{2}\bar\vp'_{\rho 2}+\dots+\omega_{p}\bar\vp'_{\rho p}\pmod{\theta_{1},\dots,\theta_{s};\bar\vp_{\sigma 1},\dots,\bar\vp_{\sigma p}},
\]
and then, according to the theorem of \textsection\textbf{8}, we have
\begin{equation}
  \label{eq:p29}
  \bar\vp'_{\rho i}=\omega_{1}\chi_{\rho i1}+\dots+\omega_{p}\chi_{\rho ip}\pmod{\theta_{1},\dots,\theta_{s};\bar\vp_{\sigma 1},\dots,\bar\omega_{\sigma p}},
\end{equation}
$\chi_{\rho ij}=\chi_{\rho ji}$ being linked by the same relations as $l_{\rho ij}$.

Since according to the formula \eqref{eq:p28} the principal $\chi_{\rho ij}$ are necessarily independent among themselves and with respect to $\omega$, we see that, by applying the theorem of \textsection\textbf{7}, the prolonged system is in involution.

\somespace

\textsc{Remark.} \emph{This theorem may fail to hold if we only apply a partial prolongation of the given system, that is to say if we adjoin to this system only some of the equations \eqref{eq:p27}}. As an example, this happens if we prolong the system in involution
\begin{align*}
  \theta'_{1}&=\omega_{1}\vp_{1},\\
  \theta'_{2}&=\omega_{2}\vp_{2}
\end{align*}
by adjoining the single equation
\[
\bar\vp=\vp_{1}+\vp_{2}-u\omega_{1}-v\omega_{2}=0.
\]

\paragraph{}
\label{sec:p10}
After studying systems in involution, we are going to consider a Pfaffian system for which the bilinear covariants have been reduced to the form \eqref{eq:p10} and we assume that the number of arbitrary parameters that the most general $p$-th order integral element depends on is \emph{less} than the integer
\[
\sigma_{1}+2\sigma_{2}+\dots+p\sigma_{p}+p(q-\sigma_{1}-\sigma_{2}-\dots-\sigma_{p}),
\]
where $\sigma$ are numbers defined by means of the matrix \eqref{eq:p14}. We are going to show that the Pfaffian system can be \emph{prolonged} in a way to satisfy the conditions of the theorem in \textsection\textbf{6}.

We say that the bilinear covariants of the system is made into \emph{normal} form when, using the equations of the system and writing only the terms containing $\vp$, we can divide the covariants into a certain number of groups having the following property. To each group is associated an integer $N$ such that it contains as many covariants $\Pi_{\alpha_{1},\alpha_{2},\dots,\alpha_{p}}$ as there are combinations of positive or zero integers $\alpha$ satisfying
\[
\alpha_{1}+\alpha_{2}+\dots+\alpha_{p}=N
\]
with
\[
\Pi_{\alpha_{1},\alpha_{2},\dots,\alpha_{p}}=\omega_{1}\vp_{\alpha_{1}+1,\alpha_{2},\dots,\alpha_{p}}+\omega_{2}\vp_{\alpha_{1},\alpha_{2}+1,\dots,\alpha_{p}}+\dots+\omega_{p}\vp_{\alpha}\vp_{\alpha_{1},\alpha_{2},\dots,\alpha_{p}+1}.
\]

We also assume that we can associate to each of these groups another integer $h$ between $0$ and $p$ such that if
\[
h,\quad h',\quad h'',\quad\dots
\]
are the integers associated with the first, second, third, $\dots$ groups, the $\vp$ of the first group which have the last $p-h$ indices are zero, the $\vp'$ of the second group which have the last $p-h'$ indices zero, etc., are independent among themselves and moreover all the other $\vp$, $\vp'$, $\dots$ depend on the preceding. We call these last expressions the \emph{principal expressions $\vp$.}

If we apply an \emph{arbitrary} linear transformation on $\omega$, the covariants will not cease to be under the normal form, and the $\vp$ in the same group undergo a linear transformation.

If we establish a relation among the variables, this will translates into a linear relation in $\vp$, $\vp'$, $\dots$, and $\omega$. Suppose that it effectively contains the principal expressions $\vp$ of the first group and the integer $h^{(i)}$ associated to the groups whose principal expressions enter wholly or partly into the relations considered are all greater than or equal to $h$. Then we can, by a linear transformation on $\omega_{1}$, $\dots$, $\omega_{h}$ make them under a form such that the relation effectively contains
\[
\vp_{00\dots N+1,0\dots0}\qquad(\alpha_{h}=N+1).
\]
If this is the case, all of $\vp$, $\vp'$, $\dots$ are expressed in terms of the principal expressions of the second, third, $\dots$ groups \emph{and the coefficients of $\omega_{1}$, $\dots$, $\omega_{h-1}$ in the first group.} We can then replace the first group by a certain number of other groups \emph{for which the integer $h$ is diminished by one.}

Finally, observe that if we can prolong the system by the procedure of \textsection\textbf{4}, the covariants of the new system are again under a canonical form, with the same number of groups, the same integers $h$, $h'$, $\dots$, and the integers $N$ are increased by one and the necessary linear relations hold among the new principal expressions. Indeed, by omitting combinations of $\omega_{1}$, $\dots$, $\omega_{p}$ whose coefficients depend only on the old variables, if necessary, we have formulae of the following form
\[
\vp_{\alpha_{1},\alpha_{2},\dots,\alpha_{p}}=t_{\alpha_{1}+1,\alpha_{2},\dots,\alpha_{p}}\omega_{1}+t_{\alpha_{1},\alpha_{2}+1,\dots,\alpha_{p}}\omega_{2}+\dots+t_{\alpha_{1},\alpha_{2},\dots,\alpha_{p}+1}\omega_{p},
\]
and $t$, $t'$, $\dots$ depend only on those of the first group for which the $p-h$ last indices are zero, etc. It suffices to take as principal expressions of the prolonged system the differentials of these coefficients $t$, only that, if these $t$ are not really independent, the new principal expressions must be linked by the relations, each of which dissolves a group of covariants by decreasing the associated integer $h$ by one unit, as we have just seen.

\paragraph{}
\label{sec:p11}
Granted this, let us denote by
\[
v_{0},\quad v_{1},\quad \dots \quad v_{p}
\]
the total number of the groups of covariants of the old system for which the integer $h$ is equal to, respectively
\[
0,\quad 1,\quad \dots\quad p.
\]

Suppose that we never arrive at a prolongation leaving the integers $v$ invariant. Then the integer $v_{p}$ cannot be increased, and we necessarily arrive at a stage where it no longer changes. We can then reason successively for all the integers $v$ and prove that after a certain prolongation none of these integers can change.

To say that none of the integers $v$ changes is the same as saying that in the prolongation all the $t$ for which the $p-h$ last indices are zero, all the $t'$ for which the last $p-h'$ indices are zero, etc., are arbitrary. If we use

\somespace

$\tau_{1}$ to denote the number of principal expressions for which the first index is at least equal to 1;

$\tau_{2}$ to denote the number of principal expressions for which the first index is zero without the second being zero as well;

$\tau_{3}$ to denote the number of principal expressions for which the first two indices are zero without the third being zero, etc.;

\somespace

the numbers of arbitrary $t$, $t'$, $\dots$ is, as it is easy to see, equal to
\begin{equation}
  \label{eq:p30}
  \tau_{1}+2\tau_{2}+3\tau_{3}+\dots+p\tau_{p},
\end{equation}
and moreover the number of independent $\vp$, $vp'$, $\dots$ is
\[
\tau_{1}+\tau_{2}+\dots+\tau_{p}.
\]

For the system considered, we manifestly have
\begin{equation}
  \label{eq:p31}
  \left\{
    \begin{aligned}
      \sigma_{1}&\ge \tau_{1},\\
      \sigma_{1}+\sigma_{2}&\ge \tau_{1}+\tau_{2},\\
      &\dots\\
      \sigma_{1}+\sigma_{2}+\dots+\sigma_{p-1}&\ge \tau_{1}+\tau_{2}+\dots+\tau_{p-1},\\
      \sigma_{1}+\sigma_{2}+\dots+\sigma_{p-1}+\sigma_{p}&= \tau_{1}+\tau_{2}+\dots+\tau_{p-1}+\tau_{p}.
    \end{aligned}
  \right.
\end{equation}

On the last line we have equality, each of the two sides being at least equal to the number of independent $\vp$, $\vp'$, $\dots$. From the inequalities \eqref{eq:p21} we deduce the following:
\begin{equation}
  \label{eq:p32}
  \left\{
    \begin{aligned}
      \sigma_{p}&\le \tau_{p},\\
      \sigma_{p-1}+\sigma_{p}&\le \tau_{p-1}+\tau_{p},\\
      &\dots\\
      \sigma_{2}+\dots+\sigma_{p-1}+\sigma_{p}&\le\tau_{2}+\dots+ \tau_{p-1}+\tau_{p},\\
      \sigma_{1}+\sigma_{2}+\dots+\sigma_{p-1}+\sigma_{p}&=\tau_{1}+\tau_{2}+\dots+ \tau_{p-1}+\tau_{p},\\
    \end{aligned}
  \right.
\end{equation}
and also, by adding them together,
\begin{equation}
  \label{eq:p33}
  \sigma_{1}+2\sigma_{2}+\dots+p\sigma_{p}\le \tau_{1}+2\tau_{2}+\dots+p\tau_{p}.
\end{equation}

The number of arbitrary parameters the most general $p$-th order integral element depends on is therefore, according to \eqref{eq:p33} \emph{at least} equal to the integer
\[
\sigma_{1}+2\sigma_{2}+\dots+p\sigma_{p}.
\]
On the other hand, according to our theorem (\textsection\textbf{6}), it is \emph{at most} equal to it. Therefore they are equal and the system is in involution. Furthermore the indeterminacy is defined by the numbers 
\[
s_{1}=\tau_{1},\quad s_{2}=\tau_{2},\quad \dots \quad s_{p}=\tau_{p}.
\]

\paragraph{}
\label{sec:p12}
As we can see, the preceding proof is analogous to several known proofs on the possibility of making a system of partial differential equations into a system in involution. Despite of this, we would like to emphasise the practical importance of the theorem of \textsection{\textbf{6}}: to make a given Pfaffian system into one in involution, we calculate, after each prolongation is effected, the values of the integers $\sigma_{1}$, $\sigma_{2}$, $\dots$, $\sigma_{p}$ and we stop when the number of new variables the prolongation provides attains the integer value $\sigma_{1}+2\sigma_{2}+\dots+ p\sigma_{p}$. Unce this system is in involution, one more prolongation would give the new values
\begin{equation}
  \label{eq:p34}
  \left\{
    \begin{alignedat}{10}
      \sigma'_{1}&{}={}&\sigma_{1}+\sigma_{2}+\dots+\sigma_{p},\\
      \sigma'_{2}&{}={}&\sigma_{2}+\dots+\sigma_{p},\\
      &\dots\\
      \sigma'_{p}&{}={}&\sigma_{p}.
    \end{alignedat}
  \right.
\end{equation}

Also observe that if a system is in involution with a value of the integer $\sigma_{p}$ equal to at least $1$, an \emph{arbitrary} relation among the variables will keep the system in involution, and $\sigma_{p}$ decreases simply by one. Instead of one relation we can take any number, less or equal to $\sigma_{p}$, of relations, then $\sigma_{p}$ will decrease by this number. Without wanting to elaborate on this point, this observation can nonetheless show that an \emph{arbitrary} system of $m$ equations in partial differential equations (not necessarily of the same order) of $m$ unknown functions is always in involution when we have derived from the equations of the system of order less than the maximum order the system with all the orders maximum.


\end{document}
